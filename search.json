[{"path":"https://floschuberth.github.io/cSEM/CONTRIBUTING.html","id":"notes-to-contributors","dir":"","previous_headings":"","what":"Notes to contributors","title":"NA","text":"Stick structure, design choices style conventions described . questions: please contact author.","code":""},{"path":"https://floschuberth.github.io/cSEM/CONTRIBUTING.html","id":"general-design-choices","dir":"","previous_headings":"Notes to contributors","what":"General design choices","title":"NA","text":"OO system used S3 system. S4 classes allowed! Whenever subset matrix using [ use: [..., ..., drop = FALSE] avoid accidentally dropping dim attributes. Generally avoid using attributes (sometimes meaningful though) Whenever output consists 1 element use named list!","code":""},{"path":"https://floschuberth.github.io/cSEM/CONTRIBUTING.html","id":"stylenaming","dir":"","previous_headings":"Notes to contributors","what":"Style/Naming","title":"NA","text":"Stick styleguide following exceptions/additions: Function class names always CamelCase. Function names contain verb followed noun like: processData(), calculateValue(). Verbs function names consistent across whole package. Avoid mixing synonyms. Example: computeValue() vs. calculateValue(). package always uses calculate instead compute. Similarly, method vs e.g. approach. package always uses approach instead method. Use plural function/object names main output one element, like scaleWeights(), calculateComposites(), handleArgs() etc. stick singular cases like parseModel(). Strive meaningful argument names even bit longer usual. People much better remembering arguments like respect_structural_model compared something like resp_sm. Naming also consistent possible. example: argument describes method approach named .approach_*. Argument names always start dot distinguish objects. Indentation: OK align function arguments indented two spaces function name instead function starts help readability.","code":"## Both ok but second is prefered in this case calculateInnerWeightsPLS <- function(.S                           = NULL,                                      .W                           = NULL,                                      .csem_model                  = NULL,                                      .PLS_weight_scheme_inner     = c(\"centroid\",                                                                       \"factorial\",                                                                        \"path\"),                                      .PLS_ignore_structural_model = NULL                                      ) { }  calculateInnerWeightsPLS <- function(   .S                            = NULL,   .W                            = NULL,   .csem_model                   = NULL,   .PLS_weight_scheme_inner      = c(\"centroid\",\"factorial\", \"path\"),   .PLS_ignore_structural_model  = NULL   ) { }"},{"path":"https://floschuberth.github.io/cSEM/CONTRIBUTING.html","id":"matrices","dir":"","previous_headings":"Notes to contributors","what":"Matrices","title":"NA","text":"Whenever possible: variables belong columns, observations belong rows. implies: whenever matrix contains observations, variables columns, matter indicators, proxies, errors anything else. Covariance matrices: indicators always belong columns proxies rows, .e., matrix weights W PLS therefore (J × K) J number proxies K number indicators. Naming: matrices within package named according naming schemes related SEM literature.","code":""},{"path":"https://floschuberth.github.io/cSEM/CONTRIBUTING.html","id":"arguments","dir":"","previous_headings":"Notes to contributors","what":"Arguments","title":"NA","text":"arguments used functions package (including internal functions) centrally collected file zz_arguments.R. Whenever new argument introduced: Add new argument name + description cSEMArguments list alphabetical order writing @param <argument> \"description\". \"Defaults xxx\". Arguments args_dotdotdot_csem: arguments can used calling csem() cca() . Practically comprises formal arguments foreman() formal arguments csem(). Arguments args: arguments. Add argument function want use . Order arguments according importance (.e. .data .model always come first). one otherwise use alphabetical order.","code":""},{"path":"https://floschuberth.github.io/cSEM/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"GNU GENERAL PUBLIC LICENSE","title":"GNU GENERAL PUBLIC LICENSE","text":"Version 3, 29 June 2007 Copyright (C) 2007 Free Software Foundation, Inc. https://fsf.org/ Everyone permitted copy distribute verbatim copies license document, changing allowed.","code":""},{"path":"https://floschuberth.github.io/cSEM/LICENSE.html","id":"preamble","dir":"","previous_headings":"","what":"Preamble","title":"GNU GENERAL PUBLIC LICENSE","text":"GNU General Public License free, copyleft license software kinds works. licenses software practical works designed take away freedom share change works. contrast, GNU General Public License intended guarantee freedom share change versions program–make sure remains free software users. , Free Software Foundation, use GNU General Public License software; applies also work released way authors. can apply programs, . speak free software, referring freedom, price. General Public Licenses designed make sure freedom distribute copies free software (charge wish), receive source code can get want , can change software use pieces new free programs, know can things. protect rights, need prevent others denying rights asking surrender rights. Therefore, certain responsibilities distribute copies software, modify : responsibilities respect freedom others. example, distribute copies program, whether gratis fee, must pass recipients freedoms received. must make sure , , receive can get source code. must show terms know rights. Developers use GNU GPL protect rights two steps: (1) assert copyright software, (2) offer License giving legal permission copy, distribute /modify . developers’ authors’ protection, GPL clearly explains warranty free software. users’ authors’ sake, GPL requires modified versions marked changed, problems attributed erroneously authors previous versions. devices designed deny users access install run modified versions software inside , although manufacturer can . fundamentally incompatible aim protecting users’ freedom change software. systematic pattern abuse occurs area products individuals use, precisely unacceptable. Therefore, designed version GPL prohibit practice products. problems arise substantially domains, stand ready extend provision domains future versions GPL, needed protect freedom users. Finally, every program threatened constantly software patents. States allow patents restrict development use software general-purpose computers, , wish avoid special danger patents applied free program make effectively proprietary. prevent , GPL assures patents used render program non-free. precise terms conditions copying, distribution modification follow.","code":""},{"path":[]},{"path":"https://floschuberth.github.io/cSEM/LICENSE.html","id":"id_0-definitions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"0. Definitions.","title":"GNU GENERAL PUBLIC LICENSE","text":"“License” refers version 3 GNU General Public License. “Copyright” also means copyright-like laws apply kinds works, semiconductor masks. “Program” refers copyrightable work licensed License. licensee addressed “”. “Licensees” “recipients” may individuals organizations. “modify” work means copy adapt part work fashion requiring copyright permission, making exact copy. resulting work called “modified version” earlier work work “based ” earlier work. “covered work” means either unmodified Program work based Program. “propagate” work means anything , without permission, make directly secondarily liable infringement applicable copyright law, except executing computer modifying private copy. Propagation includes copying, distribution (without modification), making available public, countries activities well. “convey” work means kind propagation enables parties make receive copies. Mere interaction user computer network, transfer copy, conveying. interactive user interface displays “Appropriate Legal Notices” extent includes convenient prominently visible feature (1) displays appropriate copyright notice, (2) tells user warranty work (except extent warranties provided), licensees may convey work License, view copy License. interface presents list user commands options, menu, prominent item list meets criterion.","code":""},{"path":"https://floschuberth.github.io/cSEM/LICENSE.html","id":"id_1-source-code","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"1. Source Code.","title":"GNU GENERAL PUBLIC LICENSE","text":"“source code” work means preferred form work making modifications . “Object code” means non-source form work. “Standard Interface” means interface either official standard defined recognized standards body, , case interfaces specified particular programming language, one widely used among developers working language. “System Libraries” executable work include anything, work whole, () included normal form packaging Major Component, part Major Component, (b) serves enable use work Major Component, implement Standard Interface implementation available public source code form. “Major Component”, context, means major essential component (kernel, window system, ) specific operating system () executable work runs, compiler used produce work, object code interpreter used run . “Corresponding Source” work object code form means source code needed generate, install, (executable work) run object code modify work, including scripts control activities. However, include work’s System Libraries, general-purpose tools generally available free programs used unmodified performing activities part work. example, Corresponding Source includes interface definition files associated source files work, source code shared libraries dynamically linked subprograms work specifically designed require, intimate data communication control flow subprograms parts work. Corresponding Source need include anything users can regenerate automatically parts Corresponding Source. Corresponding Source work source code form work.","code":""},{"path":"https://floschuberth.github.io/cSEM/LICENSE.html","id":"id_2-basic-permissions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"2. Basic Permissions.","title":"GNU GENERAL PUBLIC LICENSE","text":"rights granted License granted term copyright Program, irrevocable provided stated conditions met. License explicitly affirms unlimited permission run unmodified Program. output running covered work covered License output, given content, constitutes covered work. License acknowledges rights fair use equivalent, provided copyright law. may make, run propagate covered works convey, without conditions long license otherwise remains force. may convey covered works others sole purpose make modifications exclusively , provide facilities running works, provided comply terms License conveying material control copyright. thus making running covered works must exclusively behalf, direction control, terms prohibit making copies copyrighted material outside relationship . Conveying circumstances permitted solely conditions stated . Sublicensing allowed; section 10 makes unnecessary.","code":""},{"path":"https://floschuberth.github.io/cSEM/LICENSE.html","id":"id_3-protecting-users-legal-rights-from-anti-circumvention-law","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"3. Protecting Users’ Legal Rights From Anti-Circumvention Law.","title":"GNU GENERAL PUBLIC LICENSE","text":"covered work shall deemed part effective technological measure applicable law fulfilling obligations article 11 WIPO copyright treaty adopted 20 December 1996, similar laws prohibiting restricting circumvention measures. convey covered work, waive legal power forbid circumvention technological measures extent circumvention effected exercising rights License respect covered work, disclaim intention limit operation modification work means enforcing, work’s users, third parties’ legal rights forbid circumvention technological measures.","code":""},{"path":"https://floschuberth.github.io/cSEM/LICENSE.html","id":"id_4-conveying-verbatim-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"4. Conveying Verbatim Copies.","title":"GNU GENERAL PUBLIC LICENSE","text":"may convey verbatim copies Program’s source code receive , medium, provided conspicuously appropriately publish copy appropriate copyright notice; keep intact notices stating License non-permissive terms added accord section 7 apply code; keep intact notices absence warranty; give recipients copy License along Program. may charge price price copy convey, may offer support warranty protection fee.","code":""},{"path":"https://floschuberth.github.io/cSEM/LICENSE.html","id":"id_5-conveying-modified-source-versions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"5. Conveying Modified Source Versions.","title":"GNU GENERAL PUBLIC LICENSE","text":"may convey work based Program, modifications produce Program, form source code terms section 4, provided also meet conditions: work must carry prominent notices stating modified , giving relevant date. work must carry prominent notices stating released License conditions added section 7. requirement modifies requirement section 4 “keep intact notices”. must license entire work, whole, License anyone comes possession copy. License therefore apply, along applicable section 7 additional terms, whole work, parts, regardless packaged. License gives permission license work way, invalidate permission separately received . work interactive user interfaces, must display Appropriate Legal Notices; however, Program interactive interfaces display Appropriate Legal Notices, work need make . compilation covered work separate independent works, nature extensions covered work, combined form larger program, volume storage distribution medium, called “aggregate” compilation resulting copyright used limit access legal rights compilation’s users beyond individual works permit. Inclusion covered work aggregate cause License apply parts aggregate.","code":""},{"path":"https://floschuberth.github.io/cSEM/LICENSE.html","id":"id_6-conveying-non-source-forms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"6. Conveying Non-Source Forms.","title":"GNU GENERAL PUBLIC LICENSE","text":"may convey covered work object code form terms sections 4 5, provided also convey machine-readable Corresponding Source terms License, one ways: Convey object code , embodied , physical product (including physical distribution medium), accompanied Corresponding Source fixed durable physical medium customarily used software interchange. Convey object code , embodied , physical product (including physical distribution medium), accompanied written offer, valid least three years valid long offer spare parts customer support product model, give anyone possesses object code either (1) copy Corresponding Source software product covered License, durable physical medium customarily used software interchange, price reasonable cost physically performing conveying source, (2) access copy Corresponding Source network server charge. Convey individual copies object code copy written offer provide Corresponding Source. alternative allowed occasionally noncommercially, received object code offer, accord subsection 6b. Convey object code offering access designated place (gratis charge), offer equivalent access Corresponding Source way place charge. need require recipients copy Corresponding Source along object code. place copy object code network server, Corresponding Source may different server (operated third party) supports equivalent copying facilities, provided maintain clear directions next object code saying find Corresponding Source. Regardless server hosts Corresponding Source, remain obligated ensure available long needed satisfy requirements. Convey object code using peer--peer transmission, provided inform peers object code Corresponding Source work offered general public charge subsection 6d. separable portion object code, whose source code excluded Corresponding Source System Library, need included conveying object code work. “User Product” either (1) “consumer product”, means tangible personal property normally used personal, family, household purposes, (2) anything designed sold incorporation dwelling. determining whether product consumer product, doubtful cases shall resolved favor coverage. particular product received particular user, “normally used” refers typical common use class product, regardless status particular user way particular user actually uses, expects expected use, product. product consumer product regardless whether product substantial commercial, industrial non-consumer uses, unless uses represent significant mode use product. “Installation Information” User Product means methods, procedures, authorization keys, information required install execute modified versions covered work User Product modified version Corresponding Source. information must suffice ensure continued functioning modified object code case prevented interfered solely modification made. convey object code work section , , specifically use , User Product, conveying occurs part transaction right possession use User Product transferred recipient perpetuity fixed term (regardless transaction characterized), Corresponding Source conveyed section must accompanied Installation Information. requirement apply neither third party retains ability install modified object code User Product (example, work installed ROM). requirement provide Installation Information include requirement continue provide support service, warranty, updates work modified installed recipient, User Product modified installed. Access network may denied modification materially adversely affects operation network violates rules protocols communication across network. Corresponding Source conveyed, Installation Information provided, accord section must format publicly documented (implementation available public source code form), must require special password key unpacking, reading copying.","code":""},{"path":"https://floschuberth.github.io/cSEM/LICENSE.html","id":"id_7-additional-terms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"7. Additional Terms.","title":"GNU GENERAL PUBLIC LICENSE","text":"“Additional permissions” terms supplement terms License making exceptions one conditions. Additional permissions applicable entire Program shall treated though included License, extent valid applicable law. additional permissions apply part Program, part may used separately permissions, entire Program remains governed License without regard additional permissions. convey copy covered work, may option remove additional permissions copy, part . (Additional permissions may written require removal certain cases modify work.) may place additional permissions material, added covered work, can give appropriate copyright permission. Notwithstanding provision License, material add covered work, may (authorized copyright holders material) supplement terms License terms: Disclaiming warranty limiting liability differently terms sections 15 16 License; Requiring preservation specified reasonable legal notices author attributions material Appropriate Legal Notices displayed works containing ; Prohibiting misrepresentation origin material, requiring modified versions material marked reasonable ways different original version; Limiting use publicity purposes names licensors authors material; Declining grant rights trademark law use trade names, trademarks, service marks; Requiring indemnification licensors authors material anyone conveys material (modified versions ) contractual assumptions liability recipient, liability contractual assumptions directly impose licensors authors. non-permissive additional terms considered “restrictions” within meaning section 10. Program received , part , contains notice stating governed License along term restriction, may remove term. license document contains restriction permits relicensing conveying License, may add covered work material governed terms license document, provided restriction survive relicensing conveying. add terms covered work accord section, must place, relevant source files, statement additional terms apply files, notice indicating find applicable terms. Additional terms, permissive non-permissive, may stated form separately written license, stated exceptions; requirements apply either way.","code":""},{"path":"https://floschuberth.github.io/cSEM/LICENSE.html","id":"id_8-termination","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"8. Termination.","title":"GNU GENERAL PUBLIC LICENSE","text":"may propagate modify covered work except expressly provided License. attempt otherwise propagate modify void, automatically terminate rights License (including patent licenses granted third paragraph section 11). However, cease violation License, license particular copyright holder reinstated () provisionally, unless copyright holder explicitly finally terminates license, (b) permanently, copyright holder fails notify violation reasonable means prior 60 days cessation. Moreover, license particular copyright holder reinstated permanently copyright holder notifies violation reasonable means, first time received notice violation License (work) copyright holder, cure violation prior 30 days receipt notice. Termination rights section terminate licenses parties received copies rights License. rights terminated permanently reinstated, qualify receive new licenses material section 10.","code":""},{"path":"https://floschuberth.github.io/cSEM/LICENSE.html","id":"id_9-acceptance-not-required-for-having-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"9. Acceptance Not Required for Having Copies.","title":"GNU GENERAL PUBLIC LICENSE","text":"required accept License order receive run copy Program. Ancillary propagation covered work occurring solely consequence using peer--peer transmission receive copy likewise require acceptance. However, nothing License grants permission propagate modify covered work. actions infringe copyright accept License. Therefore, modifying propagating covered work, indicate acceptance License .","code":""},{"path":"https://floschuberth.github.io/cSEM/LICENSE.html","id":"id_10-automatic-licensing-of-downstream-recipients","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"10. Automatic Licensing of Downstream Recipients.","title":"GNU GENERAL PUBLIC LICENSE","text":"time convey covered work, recipient automatically receives license original licensors, run, modify propagate work, subject License. responsible enforcing compliance third parties License. “entity transaction” transaction transferring control organization, substantially assets one, subdividing organization, merging organizations. propagation covered work results entity transaction, party transaction receives copy work also receives whatever licenses work party’s predecessor interest give previous paragraph, plus right possession Corresponding Source work predecessor interest, predecessor can get reasonable efforts. may impose restrictions exercise rights granted affirmed License. example, may impose license fee, royalty, charge exercise rights granted License, may initiate litigation (including cross-claim counterclaim lawsuit) alleging patent claim infringed making, using, selling, offering sale, importing Program portion .","code":""},{"path":"https://floschuberth.github.io/cSEM/LICENSE.html","id":"id_11-patents","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"11. Patents.","title":"GNU GENERAL PUBLIC LICENSE","text":"“contributor” copyright holder authorizes use License Program work Program based. work thus licensed called contributor’s “contributor version”. contributor’s “essential patent claims” patent claims owned controlled contributor, whether already acquired hereafter acquired, infringed manner, permitted License, making, using, selling contributor version, include claims infringed consequence modification contributor version. purposes definition, “control” includes right grant patent sublicenses manner consistent requirements License. contributor grants non-exclusive, worldwide, royalty-free patent license contributor’s essential patent claims, make, use, sell, offer sale, import otherwise run, modify propagate contents contributor version. following three paragraphs, “patent license” express agreement commitment, however denominated, enforce patent (express permission practice patent covenant sue patent infringement). “grant” patent license party means make agreement commitment enforce patent party. convey covered work, knowingly relying patent license, Corresponding Source work available anyone copy, free charge terms License, publicly available network server readily accessible means, must either (1) cause Corresponding Source available, (2) arrange deprive benefit patent license particular work, (3) arrange, manner consistent requirements License, extend patent license downstream recipients. “Knowingly relying” means actual knowledge , patent license, conveying covered work country, recipient’s use covered work country, infringe one identifiable patents country reason believe valid. , pursuant connection single transaction arrangement, convey, propagate procuring conveyance , covered work, grant patent license parties receiving covered work authorizing use, propagate, modify convey specific copy covered work, patent license grant automatically extended recipients covered work works based . patent license “discriminatory” include within scope coverage, prohibits exercise , conditioned non-exercise one rights specifically granted License. may convey covered work party arrangement third party business distributing software, make payment third party based extent activity conveying work, third party grants, parties receive covered work , discriminatory patent license () connection copies covered work conveyed (copies made copies), (b) primarily connection specific products compilations contain covered work, unless entered arrangement, patent license granted, prior 28 March 2007. Nothing License shall construed excluding limiting implied license defenses infringement may otherwise available applicable patent law.","code":""},{"path":"https://floschuberth.github.io/cSEM/LICENSE.html","id":"id_12-no-surrender-of-others-freedom","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"12. No Surrender of Others’ Freedom.","title":"GNU GENERAL PUBLIC LICENSE","text":"conditions imposed (whether court order, agreement otherwise) contradict conditions License, excuse conditions License. convey covered work satisfy simultaneously obligations License pertinent obligations, consequence may convey . example, agree terms obligate collect royalty conveying convey Program, way satisfy terms License refrain entirely conveying Program.","code":""},{"path":"https://floschuberth.github.io/cSEM/LICENSE.html","id":"id_13-use-with-the-gnu-affero-general-public-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"13. Use with the GNU Affero General Public License.","title":"GNU GENERAL PUBLIC LICENSE","text":"Notwithstanding provision License, permission link combine covered work work licensed version 3 GNU Affero General Public License single combined work, convey resulting work. terms License continue apply part covered work, special requirements GNU Affero General Public License, section 13, concerning interaction network apply combination .","code":""},{"path":"https://floschuberth.github.io/cSEM/LICENSE.html","id":"id_14-revised-versions-of-this-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"14. Revised Versions of this License.","title":"GNU GENERAL PUBLIC LICENSE","text":"Free Software Foundation may publish revised /new versions GNU General Public License time time. new versions similar spirit present version, may differ detail address new problems concerns. version given distinguishing version number. Program specifies certain numbered version GNU General Public License “later version” applies , option following terms conditions either numbered version later version published Free Software Foundation. Program specify version number GNU General Public License, may choose version ever published Free Software Foundation. Program specifies proxy can decide future versions GNU General Public License can used, proxy’s public statement acceptance version permanently authorizes choose version Program. Later license versions may give additional different permissions. However, additional obligations imposed author copyright holder result choosing follow later version.","code":""},{"path":"https://floschuberth.github.io/cSEM/LICENSE.html","id":"id_15-disclaimer-of-warranty","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"15. Disclaimer of Warranty.","title":"GNU GENERAL PUBLIC LICENSE","text":"WARRANTY PROGRAM, EXTENT PERMITTED APPLICABLE LAW. EXCEPT OTHERWISE STATED WRITING COPYRIGHT HOLDERS /PARTIES PROVIDE PROGRAM “” WITHOUT WARRANTY KIND, EITHER EXPRESSED IMPLIED, INCLUDING, LIMITED , IMPLIED WARRANTIES MERCHANTABILITY FITNESS PARTICULAR PURPOSE. ENTIRE RISK QUALITY PERFORMANCE PROGRAM . PROGRAM PROVE DEFECTIVE, ASSUME COST NECESSARY SERVICING, REPAIR CORRECTION.","code":""},{"path":"https://floschuberth.github.io/cSEM/LICENSE.html","id":"id_16-limitation-of-liability","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"16. Limitation of Liability.","title":"GNU GENERAL PUBLIC LICENSE","text":"EVENT UNLESS REQUIRED APPLICABLE LAW AGREED WRITING COPYRIGHT HOLDER, PARTY MODIFIES /CONVEYS PROGRAM PERMITTED , LIABLE DAMAGES, INCLUDING GENERAL, SPECIAL, INCIDENTAL CONSEQUENTIAL DAMAGES ARISING USE INABILITY USE PROGRAM (INCLUDING LIMITED LOSS DATA DATA RENDERED INACCURATE LOSSES SUSTAINED THIRD PARTIES FAILURE PROGRAM OPERATE PROGRAMS), EVEN HOLDER PARTY ADVISED POSSIBILITY DAMAGES.","code":""},{"path":"https://floschuberth.github.io/cSEM/LICENSE.html","id":"id_17-interpretation-of-sections-15-and-16","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"17. Interpretation of Sections 15 and 16.","title":"GNU GENERAL PUBLIC LICENSE","text":"disclaimer warranty limitation liability provided given local legal effect according terms, reviewing courts shall apply local law closely approximates absolute waiver civil liability connection Program, unless warranty assumption liability accompanies copy Program return fee. END TERMS CONDITIONS","code":""},{"path":"https://floschuberth.github.io/cSEM/LICENSE.html","id":"how-to-apply-these-terms-to-your-new-programs","dir":"","previous_headings":"","what":"How to Apply These Terms to Your New Programs","title":"GNU GENERAL PUBLIC LICENSE","text":"develop new program, want greatest possible use public, best way achieve make free software everyone can redistribute change terms. , attach following notices program. safest attach start source file effectively state exclusion warranty; file least “copyright” line pointer full notice found. Also add information contact electronic paper mail. program terminal interaction, make output short notice like starts interactive mode: hypothetical commands `show w’ `show c’ show appropriate parts General Public License. course, program’s commands might different; GUI interface, use “box”. also get employer (work programmer) school, , sign “copyright disclaimer” program, necessary. information , apply follow GNU GPL, see https://www.gnu.org/licenses/. GNU General Public License permit incorporating program proprietary programs. program subroutine library, may consider useful permit linking proprietary applications library. want , use GNU Lesser General Public License instead License. first, please read https://www.gnu.org/licenses/--lgpl.html.","code":"<one line to give the program's name and a brief idea of what it does.>     Copyright (C) <year>  <name of author>      This program is free software: you can redistribute it and/or modify     it under the terms of the GNU General Public License as published by     the Free Software Foundation, either version 3 of the License, or     (at your option) any later version.      This program is distributed in the hope that it will be useful,     but WITHOUT ANY WARRANTY; without even the implied warranty of     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the     GNU General Public License for more details.      You should have received a copy of the GNU General Public License     along with this program.  If not, see <https://www.gnu.org/licenses/>. <program>  Copyright (C) <year>  <name of author>     This program comes with ABSOLUTELY NO WARRANTY; for details type `show w'.     This is free software, and you are welcome to redistribute it     under certain conditions; type `show c' for details."},{"path":"https://floschuberth.github.io/cSEM/articles/Notation.html","id":"the-structural-model","dir":"Articles","previous_headings":"","what":"The structural model","title":"Notation","text":"structural model specifies relationships constructs (.e., statistical representation concept) via paths (arrows) associated path coefficients. path coefficients - sometimes also called structural coefficients - express magnitude influence exerted construct start arrow variable arrow’s end. composite-based SEM constructs always operationalized (modeled!!) composites, .e., weighted linear combinations respective indicators. Consequently, depending given construct modeled, composite may either serve proxy underlying latent variable (common factor) composite right. Despite crucial difference, stick common - although somewhat ambivalent - notation represent construct latent variable (possible construct) η\\eta. Let xkjx_{kj}(k=1,…,Kj)(k = 1,\\dots, K_j) indicator (observable) belonging construct ηj\\eta_j(j=1…,J)(j = 1\\dots, J) wkjw_{kj} weight. composite definied : η̂j=∑k=1Kjwkjxkj\\hat{\\eta}_j = \\sum^{K_j}_{k = 1} w_{kj} x_{kj}  , η̂j\\hat{\\eta}_j may represent latent variable ηj\\eta_j may also serve composite right case essentially say thatη̂j=ηj\\hat{\\eta}_j = \\eta_j refer ηj\\eta_j construct instead latent variable. Since η̂j\\hat{\\eta}_j generally natural scale, weights usually chosen η̂j\\hat{\\eta}_j standardized. Therefore, unless otherwise stated: E(η̂j)=0andVar(η̂j)=E(η̂j2)=1E(\\hat\\eta_j) = 0\\quad\\quad \\text{}\\quad\\quad Var(\\hat\\eta_j) = E(\\hat\\eta^2_j) = 1 Since relations concepts(statistical sibling constructs) product researcher’s theory assumptions analyzed, constructs typically directly connected path. Technically implies restriction path construct  path call structural model saturated. least one path restricted zero, structural model called non-saturated.","code":""},{"path":"https://floschuberth.github.io/cSEM/articles/Notation.html","id":"the-reflective-measurement-model","dir":"Articles","previous_headings":"","what":"The reflective measurement model","title":"Notation","text":"Define general reflective (congeneric) measurement model : xkj=ηkj+εkj=λkjηj+εkjfork=1,…,Kjandj=1,…,J x_{kj} = \\eta_{kj} + \\varepsilon_{kj} = \\lambda_{kj}\\eta_j +  \\varepsilon_{kj}\\quad\\text{}\\quad k = 1, \\dots, K_j\\quad\\text{}\\quad j = 1, \\dots, J Call ηkj=λkjηj\\eta_{kj} = \\lambda_{kj}\\eta_j (indicator) true/population score ηj\\eta_j underlying latent variable supposed common factor cause KjK_j indicators connected latent variable ηj\\eta_j. Call λkj\\lambda_{kj} loading direct effect latent variable indicator. Let xkjx_{kj} indicator (observable), εkj\\varepsilon_{kj} measurement error andη̂j=∑k=1Kjwkjxkj=∑k=1Kjwkjηkj+∑k=1Kjwkjεkj=η‾j+ε‾j=ηj∑k=1KJwkjλkj+ε‾kj,\\hat{\\eta}_j = \\sum^{K_j}_{k = 1} w_{kj} x_{kj} = \\sum^{K_j}_{k = 1} w_{kj} \\eta_{kj} + \\sum^{K_j}_{k = 1} w_{kj} \\varepsilon_{kj} = \\bar\\eta_{j} + \\bar\\varepsilon_{j} = \\eta_j\\sum_{k=1}^{K_J}w_{kj}\\lambda_{kj} + \\bar\\varepsilon_{kj},  proxy/test score/composite/stand-/ηj\\eta_j based weighted sum observables, wkjw_{kj} weight determined η‾j\\bar\\eta_j proxy true score, .e., weighted sum (indicator) true scores. Note distinction refer indicator true score ηkj\\eta_{kj} proxy true score true score η̂j\\hat\\eta_j (.e, true score score fact linear combination (indicator) scores!). usually refer η̂j\\hat\\eta_j proxy ηj\\eta_j stresses fact η̂j\\hat\\eta_j generally ηj\\eta_j unless ε‾j=0\\bar\\varepsilon_{j} = 0 ∑k=1KJwkjλkj=1\\sum_{k=1}^{K_J}w_{kj}\\lambda_{kj} = 1. Assume E(εkj)=E(ηj)=Cov(ηj,εkj)=0E(\\varepsilon_{kj}) = E(\\eta_j) = Cov(\\eta_j, \\varepsilon_{kj}) = 0. assume Var(ηj)=E(ηj2)=1Var(\\eta_j) = E(\\eta^2_j) = 1 determine scale. often suffices look generic test score/latent variable. sake clarity index jj therefore dropped unless necessary avoid confusion. Note classical literature quality criteria reliability centered around idea proxy η̂\\hat\\eta fact simple sum score implies weighs set one. Treatment general since η̂\\hat{\\eta} allowed weighted sum related indicators. Readers familiar “classical treatment” may simply set weights one (unit weights) “translate” results known formulae. Based assumptions definitions following quantities necessarily follow: $$ Cov(xk,η)=λkVar(ηk)=λk2Var(xk)=λk2+Var(εk)Cor(xk,η)=ρxk,η=λkVar(xk)Cov(ηk,ηl)=Cor(ηk,ηl)=E(ηkηl)=λkλlE(η2)=λkλlCov(xk,xl)=λkλlE(η2)+λkE(ηεk)+λlE(ηεl)+E(εkεl)=λkλl+δklCor(xk,xl)=λkλl+δklVar(xk)Var(xl)Var(η‾)=E(η‾2)=∑wk2λk2+2∑k<lwkwlλkλl=(∑wkλk)2=(𝐰′𝛌)2Var(ε‾)=E(ε‾2)=∑wk2E(εk2)+2∑k<lwkwlE(εkεl)Var(η̂)=E(η̂2)=∑wk2(λk2+Var(εk))+2∑k<lwkwl(λkλl+δkl)=∑wk2λk2+2∑k<lwkwlλkλl+∑wk2Var(εk)+2∑k<lwkwlδkl=Var(η‾)+Var(ε‾)=(𝐰′𝛌)2+Var(ε‾)=𝐰′𝚺𝐰Cov(η,η̂)=E(∑wkλkη2)=∑wkλk=𝐰′𝛌=Var(η‾)\\begin{align} Cov(x_k, \\eta) &= \\lambda_k \\\\ Var(\\eta_k) &= \\lambda^2_k \\\\ Var(x_k)    &= \\lambda^2_k + Var(\\varepsilon_k) \\\\ Cor(x_k, \\eta) &= \\rho_{x_k, \\eta} = \\frac{\\lambda_k}{\\sqrt{Var(x_k)}} \\\\  Cov(\\eta_k, \\eta_l) &= Cor(\\eta_k, \\eta_l) = E(\\eta_k\\eta_l) = \\lambda_k\\lambda_lE(\\eta^2) = \\lambda_k\\lambda_l \\\\  Cov(x_k, x_l) &= \\lambda_k\\lambda_lE(\\eta^2) + \\lambda_kE(\\eta\\varepsilon_k) + \\lambda_lE(\\eta\\varepsilon_l) + E(\\varepsilon_k\\varepsilon_l) = \\lambda_k\\lambda_l + \\delta_{kl} \\\\  Cor(x_k, x_l) &= \\frac{\\lambda_k\\lambda_l + \\delta_{kl}}{\\sqrt{Var(x_k)Var(x_l)}} \\\\  Var(\\bar\\eta) &= E(\\bar\\eta^2) = \\sum w_k^2\\lambda^2_k + 2\\sum_{k < l} w_k w_l \\lambda_k\\lambda_l = \\left(\\sum w_k\\lambda_k \\right)^2 = (\\boldsymbol{\\mathbf{w}}'\\boldsymbol{\\mathbf{\\lambda}})^2 \\\\  Var(\\bar\\varepsilon) &= E(\\bar\\varepsilon^2) = \\sum w_k^2E(\\varepsilon_k^2) + 2\\sum_{k < l} w_k w_lE(\\varepsilon_k\\varepsilon_l)\\\\  Var(\\hat\\eta) &= E(\\hat\\eta^2) = \\sum w_k^2(\\lambda^2_k + Var(\\varepsilon_k)) + 2\\sum_{k < l} w_k w_l (\\lambda_k\\lambda_l + \\delta_{kl}) \\\\ &= \\sum w_k^2\\lambda^2_k + 2\\sum_{k < l} w_k w_l \\lambda_k\\lambda_l + \\sum w_k^2Var(\\varepsilon_k)  + 2\\sum_{k < l} w_k w_l \\delta_{kl} \\\\ &=Var(\\bar\\eta) + Var(\\bar\\varepsilon) = (\\boldsymbol{\\mathbf{w}}'\\boldsymbol{\\mathbf{\\lambda}})^2 + Var(\\bar\\varepsilon) = \\boldsymbol{\\mathbf{w}}'\\boldsymbol{\\mathbf{\\Sigma}}\\boldsymbol{\\mathbf{w}} \\\\  Cov(\\eta, \\hat\\eta) &= E\\left(\\sum w_k \\lambda_k \\eta^2\\right) = \\sum w_k\\lambda_k = \\boldsymbol{\\mathbf{w}}'\\boldsymbol{\\mathbf{\\lambda}}= \\sqrt{Var(\\bar\\eta)} \\end{align} $$ δkl=Cov(εk,εl)\\delta_{kl} = Cov(\\varepsilon_{k}, \\varepsilon_{l}) k≠lk \\neq l measurement error covariance 𝚺\\boldsymbol{\\mathbf{\\Sigma}} indicator variance-covariance matrix implied measurement model: 𝚺=(λ12+Var(ε1)λ1λ2+δ12…λ1λK+δ1Kλ2λ1+δ21λ22+Var(ε2)…λ2λK+δ1K⋮⋮⋱⋮λKλ1+δK1λKλ2+δK2…λK2+Var(εK)) \\boldsymbol{\\mathbf{\\Sigma }}= \\begin{pmatrix} \\lambda^2_1 + Var(\\varepsilon_1) & \\lambda_1\\lambda_2 + \\delta_{12}  & \\dots & \\lambda_1\\lambda_K + \\delta_{1K} \\\\ \\lambda_2\\lambda_ 1 + \\delta_{21} & \\lambda^2_2 + Var(\\varepsilon_2) & \\dots & \\lambda_2\\lambda_K +\\delta_{1K} \\\\  \\vdots & \\vdots & \\ddots & \\vdots \\\\ \\lambda_{K}\\lambda_1 + \\delta_{K1} & \\lambda_K\\lambda_2 + \\delta_{K2} &\\dots &\\lambda^2_K + Var(\\varepsilon_K) \\end{pmatrix} cSEM indicators always standardized weights always appropriately scaled variance η̂\\hat\\eta equal one. Furthermore, unless explicitly specified measurement error covariance restricted zero. consequence, necessarily follows : Var(xk)=1Cov(xk,η)=Cor(xk,η)Cov(xk,xl)=Cor(xk,xl)Var(η̂)=𝐰′𝚺𝐰=1Var(εk)=1−Var(ηk)=1−λk2Cov(εk,εl)=0Var(ε‾)=∑wk2(1−λk2) \\begin{align} Var(x_k) &= 1 \\\\ Cov(x_k, \\eta) &= Cor(x_k, \\eta) \\\\ Cov(x_k, x_l) &= Cor(x_k, x_l) \\\\ Var(\\hat\\eta) &= \\boldsymbol{\\mathbf{w}}'\\boldsymbol{\\mathbf{\\Sigma}}\\boldsymbol{\\mathbf{w}} = 1 \\\\ Var(\\varepsilon_k) &= 1 - Var(\\eta_k) = 1 - \\lambda^2_k \\\\ Cov(\\varepsilon_k, \\varepsilon_l) &= 0 \\\\ Var(\\bar\\varepsilon) &= \\sum w_k^2 (1 - \\lambda_k^2) \\end{align}  formulae implies significant simplification, however, ease comparison extant literature formulae stick “general form” mention “simplified form” “cSEM form” Methods Formula sections.","code":""},{"path":[]},{"path":"https://floschuberth.github.io/cSEM/articles/Terminology.html","id":"commonfactor","dir":"Articles","previous_headings":"","what":"Common factor","title":"Terminology","text":"common factor latent variable type construct. name common factor motivated theorized relationship indicators. relation commonly referred measurement model. Two kinds measurement models exist: reflective (causal-)formative measurement model. defining feature common factor reflective measurement model idea common factor common underlying (latent) cause realizations set indicators said measure common factor. idea reflective measurement model closely related true score theory. Accordingly, indicators related common factor modeled measurement error-prone manifestations common variable, cause factor. Although subtle conceptional differences, terms common factor, true score, latent variable mostly used synonymously cSEM. common factor also central entity causal-formative measurement model. indicators modeled causing /one common factor. type measurement looks similar composite (measurement) model, however, models , fact, quite different. causal-formative measurement model assumes common factor imperfectly measured indicators (.e., error term non-zero variance) composite composite model build/defined indicators, .e., error-free definition.","code":""},{"path":"https://floschuberth.github.io/cSEM/articles/Terminology.html","id":"composite","dir":"Articles","previous_headings":"","what":"Composite","title":"Terminology","text":"composite weighted sum indicators. Composites may either serve constructs right proxies latent variable , turn, serves “statistical proxy” concept study. nature composite therefore defined type (measurement) model. composites error-free representations concept refer measurement model composite (measurement) model. composites used stand-ins latent variable, measurement model called causal-formative (Henseler 2017). Note , although sometimes use way well, term “measurement” actually rather inadequate composite model since composite model construct build/formed related indicators. Hence measurement actual sense word takes place.","code":""},{"path":"https://floschuberth.github.io/cSEM/articles/Terminology.html","id":"cbased","dir":"Articles","previous_headings":"","what":"Composite-based methods","title":"Terminology","text":"Composite-based methods composite-based SEM refers entirety methods centered around use composites (linear compounds observables) stand-ins error-free representations concepts investigation. Composite-based methods often also called variance-based methods focal parameters usually retrieved explained variance dependent constructs structural model maximized.","code":""},{"path":"https://floschuberth.github.io/cSEM/articles/Terminology.html","id":"cbasedsem","dir":"Articles","previous_headings":"","what":"Composite-based SEM","title":"Terminology","text":"See: Composite-based methods","code":""},{"path":"https://floschuberth.github.io/cSEM/articles/Terminology.html","id":"concept","dir":"Articles","previous_headings":"","what":"Concept","title":"Terminology","text":"entity defined conceptual/theoretical definition. line Rigdon (2016) variables representing subsuming concept called conceptual variables. precise nature/meaning conceptual variable depends “different assumptions, philosophies worldviews [researcher]” (Rigdon 2016, 2). Unless otherwise stated, cSEM, sufficient think concepts entities exist simply defined. Hence, abstract terms “loyalty” “depression” well designed entities (artifacts) “OECD Better Life Index” covered definition.","code":""},{"path":"https://floschuberth.github.io/cSEM/articles/Terminology.html","id":"construct","dir":"Articles","previous_headings":"","what":"Construct","title":"Terminology","text":"Construct refers representation concept within given statistical model. concept defined conceptual (theoretical) definition, construct concept defined/created researcher’s operationalization concept within statistical model. Concepts either modeled common factors/latent variables composites. operationalizations - common factor composite - called constructs cSEM. opposed concepts, constructs therefore exist arise result act modeling relation observable variables (indicators) based specific set assumptions. Constructs may therefore best understood stand-ins, .e. statistical proxies concepts. Consequently, constructs necessarily represent concept seek represent, .e., may validity gap.","code":""},{"path":"https://floschuberth.github.io/cSEM/articles/Terminology.html","id":"covariance-based-sem","dir":"Articles","previous_headings":"","what":"Covariance-based SEM","title":"Terminology","text":"See: Factor-based methods","code":""},{"path":"https://floschuberth.github.io/cSEM/articles/Terminology.html","id":"fbmethods","dir":"Articles","previous_headings":"","what":"Factor-based methods","title":"Terminology","text":"Factor-based methods factor-based SEM refers entirety methods centered around use common factors statistical proxies concepts investigation. Factor-based methods also called covariance-based methods focal parameters retrieved difference model-implied 𝚺(θ)\\boldsymbol{\\mathbf{\\Sigma}}(\\theta) empirical indicator covariance matrix 𝐒\\boldsymbol{\\mathbf{S}} minimized.","code":""},{"path":"https://floschuberth.github.io/cSEM/articles/Terminology.html","id":"indicator","dir":"Articles","previous_headings":"","what":"Indicator","title":"Terminology","text":"observable variable. cSEM observable variables generally referred indicators, however, terms item, manifest variable, observable (variable) sometimes used synonymously.","code":""},{"path":"https://floschuberth.github.io/cSEM/articles/Terminology.html","id":"latentvariable","dir":"Articles","previous_headings":"","what":"Latent variable","title":"Terminology","text":"See: Common factor","code":""},{"path":"https://floschuberth.github.io/cSEM/articles/Terminology.html","id":"mm","dir":"Articles","previous_headings":"","what":"Measurement model","title":"Terminology","text":"measurement model statistical model relating indicators constructs (statistical representation concept). concept study modeled common factor two measurement models exist: reflective measurement model causal-formative measurement model concept study modeled composite call measurement model: composite (measurement) model Note , although sometimes use way well, term “measurement” actually rather inadequate composite model since composite model construct build/formed related indicators. Hence measurement actual sense word takes place.","code":""},{"path":"https://floschuberth.github.io/cSEM/articles/Terminology.html","id":"model","dir":"Articles","previous_headings":"","what":"Model","title":"Terminology","text":"many ways define term “model”. cSEM use term model refer theoretical statistical model. Simply speaking theoretical models formalized set hypotheses stating entities (observable unobservable) related. Since theoretical models definition theoretical statistical analysis inevitably mandates statistical model. statistical model typically defined set (testable) restrictions. Statistical models best understood operationalized version theoretical model. Note act operationalizing given theoretical model always entails possibility error. Using construct modeled composite common factor, instance, attempt map theoretical entity (concept) theoretical space statistical space. mapping one--one construct imperfect representation concept. Consequently, validity gap. NOTE: Note try refrain using term “model” describing estimation approach algorithm partial least squares (PLS) helps clearly distinguish model approach used estimate given model.","code":""},{"path":"https://floschuberth.github.io/cSEM/articles/Terminology.html","id":"testscore","dir":"Articles","previous_headings":"","what":"Test score","title":"Terminology","text":"proxy true score. Usually, test score simple (unweighted) sum score observables/indicators, .e. unit weights assumed building test score. generally, test score can weighted sum observables (.e. composite), however, term “test score” historically closely tied idea indeed simple sum score. Hence, whenever important distinguish true score representing sum score true score representing weighted sum indicators (indicator weights necessarily one) explicitly state kind test score mean.","code":""},{"path":"https://floschuberth.github.io/cSEM/articles/Terminology.html","id":"truescore","dir":"Articles","previous_headings":"","what":"True score","title":"Terminology","text":"term true score derives true score theory theorizes/models indicator outcome sum true score error score. term closely linked latent variable/common factor model true score set indicators linear functions underlying common factor. Mathematically speaking, correspondence ηjk=λjkηj\\eta_{jk} = \\lambda_{jk}\\eta_j ηjk\\eta_{jk} true score, ηj\\eta_j underlying latent variable λjk\\lambda_{jk} loading. Despite differences, term true score can generally used synonymously terms common factor latent variable cSEM without risking misunderstanding.","code":""},{"path":"https://floschuberth.github.io/cSEM/articles/Terminology.html","id":"proxy","dir":"Articles","previous_headings":"","what":"Proxy","title":"Terminology","text":"quantity functions representation quantity. Prominent proxies test score - serves stand-/proxy true score - composite - serves stand-/proxy common factor used composite right. Proxies usually - necessarily - error-prone representations quantity seek represent.","code":""},{"path":"https://floschuberth.github.io/cSEM/articles/Terminology.html","id":"saturated-and-non-saturated-models","dir":"Articles","previous_headings":"","what":"Saturated and non-saturated models","title":"Terminology","text":"structural model called “saturated” constructs model allowed freely covary. equivalent saying none path structural model restricted zero. saturated model zero degrees freedom hence carries testable restrictions. least one path restricted zero, structural model called “non-saturated”.","code":""},{"path":"https://floschuberth.github.io/cSEM/articles/Terminology.html","id":"standin","dir":"Articles","previous_headings":"","what":"Stand-in","title":"Terminology","text":"See: Proxy","code":""},{"path":"https://floschuberth.github.io/cSEM/articles/Terminology.html","id":"structural-equation-modeling-sem","dir":"Articles","previous_headings":"","what":"Structural Equation Modeling (SEM)","title":"Terminology","text":"entirety set related theories, mathematical models, methods, algorithms terminologies related analyzing relationships concepts /observables.","code":""},{"path":"https://floschuberth.github.io/cSEM/articles/Terminology.html","id":"vbmethods","dir":"Articles","previous_headings":"","what":"Variance-based methods","title":"Terminology","text":"See: Composite-based methods","code":""},{"path":[]},{"path":"https://floschuberth.github.io/cSEM/articles/Using-assess.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Postestimation: Assessing a model","text":"indicated name, assess() used assess model estimated using csem() function. cSEM model assessment considered task way another seeks assess quality estimated model without conducting statistical test (tests covered test_* family functions). Quality case taken catch-term common aspects model assessment. mainly comprises fit indices, model selection criteria, reliability estimates, common validity assessment criteria, effect sizes, related quality measures/indices rely formal test procedure. Hereinafter, refer generic (fit) index, quality assessment measure quality criterion. Currently following quality criteria implemented: average variance extracted (AVE) Fornell-Larcker criterion heterotrait-monotrait ratio correlations (HTMT) Congeneric reliability (ρC\\rho_C), also known e.g.: composite reliability, construct reliability, (unidimensional) omega, Jöreskog’s ρ\\rho, ρA\\rho_A, ρB\\rho_B. Tau-equivalent reliability (ρT\\rho_T), also known e.g.: Cronbach alpha, alpha, α\\alpha, coefficient alpha, Guttman’s λ3\\lambda_3, KR-20. standardized root mean square residual (SRMR) geodesic distance (DG) squared Euclidian distance (DL) maximum-likelihood distance (DML) χ2\\chi^2-statistic χ2/df\\chi^2/df-statistic comparative fit index (CFI) goodness--fit index (GFI) standardized root mean square residual (SRMR) root mean square error approximation (RMSEA) normed fit index (NFI) non-normed fit index (NNFI) comparative fit index (CFI) incremental fit index (IFI) root mean square outer residual covariance (RMSθ\\text{RMS}_{\\theta}) Goodness--Fit (GoF) proposed Tenenhaus, Amanto, Vinzi (2004). variance inflation factors (VIF) structural equations well Mode B regression equations (.approach_weights = \"PLS-PM\"). coefficient determination adjusted coefficient determination (R2R^2 Radj2R^2_{adj}) measure effect size (Cohen’s f2f^2). Direct, indirect total effect assessment. Several model selection criteria described Sharma et al. (2019). implementation details see Methods & Formulae section.","code":""},{"path":"https://floschuberth.github.io/cSEM/articles/Using-assess.html","id":"syntax-options","dir":"Articles","previous_headings":"","what":"Syntax & Options","title":"Postestimation: Assessing a model","text":".object object class cSEMResults resulting call csem(). .quality_criterion character string vector character strings naming quality criterion compute. default quality criteria computed (\"\"). See assess() list possible candidates. .only_common_factors Logical. concepts modeled common factors included calculating one following quality criteria: AVE, Fornell-Larcker criterion, HTMT, reliability estimates. Defaults TRUE. ... arguments passed functions called assess(). See args_assess_dotdotdot complete list available arguments. Like postestimation functions assess() can called object class cSEMResults. output named list quality criteria given .quality_criterion. default possible quality criteria calculated (.quality_criterion = \"\").","code":"assess(   .object              = NULL,    .only_common_factors = TRUE,    .quality_criterion   = c(\"all\", \"aic\", \"aicc\", \"aicu\", \"bic\", \"fpe\", \"gm\", \"hq\",                            \"hqc\", \"mallows_cp\", \"ave\",                            \"rho_C\", \"rho_C_mm\", \"rho_C_weighted\",                             \"rho_C_weighted_mm\", \"dg\", \"dl\", \"dml\", \"df\",                            \"effects\", \"f2\", \"fl_criterion\", \"chi_square\", \"chi_square_df\",                            \"cfi\", \"gfi\", \"ifi\", \"nfi\", \"nnfi\",                             \"reliability\",                            \"rmsea\", \"rms_theta\", \"srmr\",                            \"gof\", \"htmt\", \"r2\", \"r2_adj\",                            \"rho_T\", \"rho_T_weighted\", \"vif\",                             \"vifmodeB\"),   ... )"},{"path":"https://floschuberth.github.io/cSEM/articles/Using-assess.html","id":"details","dir":"Articles","previous_headings":"Syntax & Options","what":"Details","title":"Postestimation: Assessing a model","text":"line cSEM’s postestimation functions, assess() generic function methods objects class cSEMResults_default, cSEMResults_multi, cSEMResults_2ndorder. cSEM every cSEMResults_* object must also class cSEMResults internal reasons. using one major postestimation functions, method dispatch therefore technically done one cSEMResults_* class attributes, ignoring cSEMResults class attribute. long assess() used directly, method dispatch practical concern end-users.","code":""},{"path":"https://floschuberth.github.io/cSEM/articles/Using-assess.html","id":"composite-models-vs--common-factor-models","dir":"Articles","previous_headings":"Syntax & Options > Details","what":"Composite models vs. common factor models","title":"Postestimation: Assessing a model","text":"assessment measures inherently tied common factor model. therefore unclear interpret results context composite model. Consequently, computation suppressed default constructs modeled composites. Currently, applies following quality criteria: AVE validity assessment based thereon (.e., Fornell-Larcker criterion) HTMT validity assessment based thereon reliability measures possible force computation quality criteria constructs modeled composites using .only_common_factors = FALSE, however, explicitly warn interpret results, may even conceptual meaning. quality criteria assume estimated loadings, construct correlations path coefficients involved computation specific quality measure consistent estimates theoretical population counterpart. user deliberately chooses approach yields inconsistent estimates (setting .disattenuate = FALSE csem() estimated model contains constructs modeled common factors) assess() still estimate quantities, however, quantities AVE congeneric reliability ρC\\rho_C inherit inconsistency.","code":""},{"path":"https://floschuberth.github.io/cSEM/articles/Using-assess.html","id":"methods","dir":"Articles","previous_headings":"","what":"Methods & Formulae","title":"Postestimation: Assessing a model","text":"section provides technical details relevant formulae. relevant notation terminology used section, see Notation Termionology help files.","code":""},{"path":[]},{"path":"https://floschuberth.github.io/cSEM/articles/Using-assess.html","id":"definition","dir":"Articles","previous_headings":"Methods & Formulae > Average Variance Extracted (AVE)","what":"Definition","title":"Postestimation: Assessing a model","text":"average variance extracted (AVE) first proposed Fornell Larcker (1981). Several definitions exist. ease comparison extant literature common definitions given : AVE generic construct/latent variable η\\eta estimate much variation indicators due assumed latent variable. Consequently, share unexplained, .e. error variation 1 - AVE. AVE generic construct/latent variable η\\eta share total indicator variance (.e., sum indicator variances indicators connected construct), captured (indicator) true scores. AVE generic construct/latent variable η\\eta ratio sum (indicator) true score variances (explained variation) relative sum total indicator variances (total variation, .e., sum indicator variances indicators connected construct). Since regression xkx_k ηk\\eta_k, R squared (Rk2)R^2_k) equal share variation xkx_k explained ηk\\eta_k relative total variation xkx_k, AVE generic construct/latent variable η\\eta equal average Rk2R^2_k. AVE generic construct/latent variable η\\eta sum squared correlation indicator xkx_k (indicator) true score ηk\\eta_k relative sum indicator variances indicators connected construct question. important stress , although different wording, definitions synonymous! AVE inherently tied common factor model. therefore unclear interpret AVE constructs modeled composites. Consequently, computation suppressed default constructs modeled common factors. possible force computation AVE constructs modeled composites using .only_common_factors = FALSE, however, explicitly warn interpret results, may even conceptual meaning.","code":""},{"path":"https://floschuberth.github.io/cSEM/articles/Using-assess.html","id":"formulae","dir":"Articles","previous_headings":"Methods & Formulae > Average Variance Extracted (AVE)","what":"Formulae","title":"Postestimation: Assessing a model","text":"Using results notation derived defined Notation help file, AVE generic construct : AVE=Sum indicator true score variancesSum indicator variances=∑Var(ηk)∑Var(xk)=∑λk2∑(λk2+Var(εk)) AVE = \\frac{\\text{Sum indicator true score variances}}{\\text{Sum indicator variances}} =  \\frac{\\sum Var(\\eta_k)}{\\sum Var(x_k)} = \\frac{\\sum\\lambda^2_k}{\\sum(\\lambda^2_k + Var(\\varepsilon_k))} xkx_k standardized (.e., Var(xk)=1Var(x_k) = 1) denominator reduces KK AVE generic construct : AVE=1K∑λk2=1K∑ρxk,η2 AVE = \\frac{1}{K}\\sum \\lambda^2_k = \\frac{1}{K}\\sum \\rho_{x_k, \\eta}^2 important consequence, AVE closely tied communality. Communality (COMkCOM_k) definied proportion variation indicator explained common factor. Empirically, square standardized loading kk’th indicator (λk2\\lambda^2_k). Since indicators, scores/proxies subsequently loadings always standardized cSEM, squared loading simply squared correlation indicator related construct/common factor. AVE also directly related indicator reliability, defined squared correlation indicator kk related proxy true score (see section Reliability ), simply λk2\\lambda^2_k. Therefore cSEM always : AVE=1K∑COMk=1K∑Indicator reliabilityk=1K∑λk2=1K∑Rk2 AVE = \\frac{1}{K}\\sum COM_k = \\frac{1}{K}\\sum \\text{Indicator reliability}_k = \\frac{1}{K}\\sum\\lambda^2_k =  \\frac{1}{K}\\sum R^2_k","code":""},{"path":"https://floschuberth.github.io/cSEM/articles/Using-assess.html","id":"implementation","dir":"Articles","previous_headings":"Methods & Formulae > Average Variance Extracted (AVE)","what":"Implementation","title":"Postestimation: Assessing a model","text":"function implemented : calculateAVE().","code":""},{"path":"https://floschuberth.github.io/cSEM/articles/Using-assess.html","id":"see-also","dir":"Articles","previous_headings":"Methods & Formulae > Average Variance Extracted (AVE)","what":"See also","title":"Postestimation: Assessing a model","text":"AVE basis Fornell-Larcker criterion.","code":""},{"path":[]},{"path":"https://floschuberth.github.io/cSEM/articles/Using-assess.html","id":"definition-1","dir":"Articles","previous_headings":"Methods & Formulae > Degrees of freedom","what":"Definition","title":"Postestimation: Assessing a model","text":"Degrees freedom calculated difference number non-redundant free elements empirical indicator correlation matrix 𝐒\\boldsymbol{\\mathbf{S}} model parameters. Although, composite-based estimators retrieve parameters postulated models forming composites, involves estimation weights computation degrees freedom eventually depends postulated model parameters implied model. notably, common factor model estimated composite-based approach PLS degrees freedom compared e.g., classical maximum likelihood estimation model.","code":""},{"path":"https://floschuberth.github.io/cSEM/articles/Using-assess.html","id":"formulae-1","dir":"Articles","previous_headings":"Methods & Formulae > Degrees of freedom","what":"Formulae","title":"Postestimation: Assessing a model","text":"df=# non-redundant -diagonal elements empirical indicator correlation matrix 𝐒−# model parameters  \\begin{align}  \\text{df} &= \\text{# non-redundant -diagonal elements empirical indicator correlation matrix $\\boldsymbol{\\mathbf{S}}$} \\\\       &- \\text{# model parameters} \\end{align} model contains linear terms model parameters : # free correlations exogenous constructs # specified correlations endogenous constructs # structural parameters addition, construct ηj\\eta_j: # loadings ηj\\eta_j modeled common factor # specified measurement error correlations items constructs ηj\\eta_j ηj\\eta_j modeled common factor # weights ηj\\eta_jminus 1 ηj\\eta_j modeled composite. One weight per block fixed hence counted model parameter since variance composite scaled unity. # non-redundant -diagonal elements 𝚺j\\boldsymbol{\\mathbf{\\Sigma}}_j ηj\\eta_j modeled composite. model contains second-order terms model parameters similar: # free correlations exogenous constructs # specified correlations endogenous constructs # structural parameters. Note: relations constructs measuring/forming second-order construct path! addition, construct ηj\\eta_j (including second-order constructs): # loadings ηj\\eta_j modeled common factor # specified measurement error correlations items constructs ηj\\eta_j ηj\\eta_j modeled common factor # weights ηj\\eta_jminus 1 ηj\\eta_j modeled composite. One weight per block fixed hence counted model parameter since variance composite scaled unity. # non-redundant -diagonal elements 𝚺j\\boldsymbol{\\mathbf{\\Sigma}}_j ηj\\eta_j modeled composite.","code":""},{"path":"https://floschuberth.github.io/cSEM/articles/Using-assess.html","id":"notes","dir":"Articles","previous_headings":"Methods & Formulae > Degrees of freedom > Formulae","what":"Notes","title":"Postestimation: Assessing a model","text":"constructs allowed freely covary, .e., structural model structural parameters, constructs considered exogenous. structural model contains nonlinear terms (e.g., η12\\eta^2_1 η1η2\\eta_1\\eta_2), degrees freedom computation currently unclear (least us). warning printed inform user calculation may correct.","code":""},{"path":"https://floschuberth.github.io/cSEM/articles/Using-assess.html","id":"implementation-1","dir":"Articles","previous_headings":"Methods & Formulae > Degrees of freedom","what":"Implementation","title":"Postestimation: Assessing a model","text":"function implemented calculateDf().","code":""},{"path":"https://floschuberth.github.io/cSEM/articles/Using-assess.html","id":"see-also-1","dir":"Articles","previous_headings":"Methods & Formulae > Degrees of freedom","what":"See also:","title":"Postestimation: Assessing a model","text":"Degrees freedom required several fit measures.","code":""},{"path":[]},{"path":"https://floschuberth.github.io/cSEM/articles/Using-assess.html","id":"definition-2","dir":"Articles","previous_headings":"Methods & Formulae > Fit Indices","what":"Definition","title":"Postestimation: Assessing a model","text":"Fit indices confirmatory factor analysis (CFA) first introduced Bentler Bonett (1980). Since large number indices defined. Contrary exact tests model fit, purpose fit indices measure fit structural equation model continuous scale. normed fit indices scale 0 1. Fit indices can divided two classes: ‘badness fit’ (resp. ‘lack fit’) indices; smaller value indicates better fit. ‘goodness fit’ indices; higher value represents better fit. Several studies analyzed empirical theoretical properties fit indices context CFA concepts expressed latent variables. little known properties performance fit indices composite models models estimated using composite-based approach. cSEM offers number fit indices known factor-based SEM. However, applied users aware little known applicability, intuition, interpretability context models containing constructs modeled composites models estimated using composite-based approach. Independent approach model used, particularly controversial issue cutoff values fit indices (e.g., Marsh, Hau, Wen 2004). factor-based SEM cutoff values rather popular. basis numerous simulation studies, notably Hu Bentler (1999). contrast composite models - better worse - cutoff values suggested.1 Using assess() calculate fit indices, user always keep mind value fit index just indication good bad fit. aspects related model fit must considered well. unreasonable make binary decision rejection non-rejection model solely comparing value fit index (less) arbitrary cutoff value. definitions fit indices calculated assess() given following: χ2\\chi^2-statistic value fitting function times sample size minus 1. χ2/df\\chi^2/df-ratio χ2\\chi^2-statistic divided degrees freedom. goodness--fit index (GFI) measures relative increase fit specified model compared model . standardized root mean square residual (SRMR) square root mean squared residual correlations. root mean square error approximation (RMSEA) square root discrepancy due approximation per degree freedom. normed fit index (NFI) measures increase fit specifying model consideration relative fit certain baseline model called “null model”. non-normed fit index (NNFI) accounts degrees freedom involved models. ratio distance fit baseline model fit specified model (per degree freedom) distance fit baseline model expected fit specified model (per degree freedom). comparative fit index (CFI) estimates relative decrease non-centrality specifying model consideration instead baseline model. incremental fit index (IFI) ratio distance fit baseline model fit specified model distance fit baseline model expected fit specified model. definition differs marginally definition NNFI. root mean square outer residual covariance (RMSθ\\text{RMS}_{\\theta}) defined square root mean squared covariances residuals outer model. calculation indicator’s residual covariance matrix involves calculation construct’s covariance matrix. See Lohmöller (1989). stressed (possible exception RMSθ\\text{RMS}_{\\theta}) none mentioned fit indices originally designed composite models. indices RMSEA CFI non-centrality based require specific assumptions model data typically made CFA. applies IFI NNFI since calculation relies properties (primarily expectation) test statistic data follows normal distribution. general, assumptions made composite models composite-based estimators, respectively. reason, intuition behind indices hold composite-based SEM. Nevertheless, calculation indices also possible case. Whether values indices still meaningful sense can used assessment model fit open question. Furthermore, values fit indices composite-based estimators factor-based estimators may compared. Users always keep aspect general limitations fit indices mind.","code":""},{"path":"https://floschuberth.github.io/cSEM/articles/Using-assess.html","id":"formulae-2","dir":"Articles","previous_headings":"Methods & Formulae > Fit Indices","what":"Formulae","title":"Postestimation: Assessing a model","text":"exact formulae fit indices implemented cSEM given following. term F=F(𝐒,𝚺(𝛉̂))=F(𝐒,𝚺̂)F = F(\\boldsymbol{\\mathbf{S}}, \\boldsymbol{\\mathbf{\\Sigma}}(\\hat{\\boldsymbol{\\mathbf{\\theta}}})) = F(\\boldsymbol{\\mathbf{S}}, \\hat{\\boldsymbol{\\mathbf{\\Sigma}}}) stands value maximum likelihood fitting function evaluated 𝐒\\boldsymbol{\\mathbf{S}} (empirical covariance matrix indicators) 𝚺̂\\hat{\\boldsymbol{\\mathbf{\\Sigma}}} (estimated model-implied covariance matrix indicators). value maximum likelihood fitting function computed calculateDML().","code":""},{"path":"https://floschuberth.github.io/cSEM/articles/Using-assess.html","id":"the-chi2-statistic","dir":"Articles","previous_headings":"Methods & Formulae > Fit Indices > Formulae","what":"The χ2\\chi^2-statistic","title":"Postestimation: Assessing a model","text":"χ2\\chi^2-statistic defined : χ2=(N−1)⋅F \\chi^2 = (N-1)\\cdot F NN sample size. Main reference: K. G. Jöreskog (1969)","code":""},{"path":"https://floschuberth.github.io/cSEM/articles/Using-assess.html","id":"the-chi2textdf-ratio","dir":"Articles","previous_headings":"Methods & Formulae > Fit Indices > Formulae","what":"The χ2/df\\chi^2/\\text{df}-ratio","title":"Postestimation: Assessing a model","text":"χ2/df\\chi^2/\\text{df}-statistic defined : χ2=(N−1)⋅F/dfM \\chi^2 = (N-1)\\cdot F/\\text{df}_M NN sample size dfM\\text{df}_M degrees freedom estimated model. Main reference: K. G. Jöreskog (1969)","code":""},{"path":"https://floschuberth.github.io/cSEM/articles/Using-assess.html","id":"the-goodness-of-fit-index-gfi","dir":"Articles","previous_headings":"Methods & Formulae > Fit Indices > Formulae","what":"The goodness-of-fit index (GFI)","title":"Postestimation: Assessing a model","text":"GFI generally defined analogy coefficient determination (R2R^2) known regression analysis 1 minus share weighted unexplained variance (SSE; difference 𝐒\\boldsymbol{\\mathbf{S}} 𝚺̂\\hat{\\boldsymbol{\\mathbf{\\Sigma}}}) relative weighted total variance (SST; variance 𝐒\\boldsymbol{\\mathbf{S}}): GFI=1−trace{(𝐖−12[𝐒−𝚺̂]𝐖−12)2}trace{(𝐖−12𝐒𝐖−12)2} GFI = 1 - \\frac{\\text{trace}\\left\\{\\left(\\boldsymbol{\\mathbf{W}}^{-\\frac{1}{2}}\\lbrack\\boldsymbol{\\mathbf{S}} - \\hat{\\boldsymbol{\\mathbf{\\Sigma}}}\\rbrack\\boldsymbol{\\mathbf{W}}^{-\\frac{1}{2}}\\right)^2\\right\\}}{\\text{trace}\\left\\{\\left(\\boldsymbol{\\mathbf{W}}^{-\\frac{1}{2}}\\boldsymbol{\\mathbf{S}}\\boldsymbol{\\mathbf{W}}^{-\\frac{1}{2}}\\right)^2\\right\\}}  matrix 𝐖\\boldsymbol{\\mathbf{W}} weight matrix. Depending estimation technique used obtain 𝛉̂\\hat{\\boldsymbol{\\mathbf{\\theta}}} different types GFI may computed choosing particular weight. 𝐖=𝚺̂\\boldsymbol{\\mathbf{W}} = \\hat{\\boldsymbol{\\mathbf{\\Sigma}}}, GFI based SSE SST maximum likelihood estimation. 𝐖=𝐒̂\\boldsymbol{\\mathbf{W}} = \\hat{\\boldsymbol{\\mathbf{S}}}, GFI based SSE SST generalized least squares (GLS) estimation. 𝐖=𝐈̂\\boldsymbol{\\mathbf{W}} = \\hat{\\boldsymbol{\\mathbf{}}}, GFI based SSE SST unweighted least squares (ULS) estimation. Note quadratic matrix , : trace(𝐗2)=∑,jxi2\\text{trace}(\\boldsymbol{\\mathbf{X}}^2) = \\sum_{,j} x^2_i. Main references: Karl G. Jöreskog Sörbom (1982), Mulaik et al. (1989) Tanaka Huba (1985)","code":""},{"path":"https://floschuberth.github.io/cSEM/articles/Using-assess.html","id":"the-standardized-root-mean-square-residual-srmr","dir":"Articles","previous_headings":"Methods & Formulae > Fit Indices > Formulae","what":"The standardized root mean square residual (SRMR)","title":"Postestimation: Assessing a model","text":"SRMR defined SRMR=2∑j=1K∑=1j[(sij−σ̂ij)/(siisjj)1/2]2K(K+1)  \\text{SRMR} = \\sqrt{2 \\sum_{j=1}^{K} \\sum_{=1}^{j} \\frac{ \\lbrack (s_{ij} - \\hat{\\sigma}_{ij})/(s_{ii} s_{jj})^{1/2} \\rbrack^{2}}{K (K+1)}}  KK stands number indicators, sijs_{ij} empirical covariance indicators ii jj, σ̂ij\\hat{\\sigma}_{ij} estimated model-implied counterpart. SRMR describes distance observed correlations reproduced average model. Therefore, smaller values associated better fit. data standardized, sii=sjj=1s_{ii} = s_{jj} = 1 holds, formula reduces : SRMR=2∑j=1K∑=1j(sij−σ̂ij)2K(K+1)  \\text{SRMR} = \\sqrt{2 \\sum_{j=1}^{K} \\sum_{=1}^{j} \\frac{(s_{ij} - \\hat{\\sigma}_{ij})^2}{K(K+1)}} Main reference: Bentler (2006)","code":""},{"path":"https://floschuberth.github.io/cSEM/articles/Using-assess.html","id":"the-root-mean-square-error-of-approximation-rmsea","dir":"Articles","previous_headings":"Methods & Formulae > Fit Indices > Formulae","what":"The root mean square error of approximation (RMSEA)","title":"Postestimation: Assessing a model","text":"RMSEA defined $$ \\hat{\\epsilon} = \\sqrt{\\frac{\\hat{F}_0}{\\text{df}_{M}}} \\quad \\text{} \\quad \\hat{F}_{0} = \\max \\Bigl( 0, F - \\frac{\\text{df}_{M}}{N-1} \\Bigr) $$ formula, dfM\\text{df}_{M} stands degrees freedom specified model (see Degrees Freedom section details degrees freedom calculated). term F̂0\\hat{F}_{0} estimator discrepancy due approximation. Thus, RMSEA measures discrepancy due approximation per degree freedom. Main reference: Browne Cudeck (1992)","code":""},{"path":"https://floschuberth.github.io/cSEM/articles/Using-assess.html","id":"the-normed-and-non-normed-fit-index-nfi-and-nnfi","dir":"Articles","previous_headings":"Methods & Formulae > Fit Indices > Formulae","what":"The normed and non-normed fit index (NFI and NNFI)","title":"Postestimation: Assessing a model","text":"fit indices NFI NNFI among first fit indices introduced (Bentler Bonett 1980). defined : NFI=FB−FMFBandNNFI=FB/dfB−FM/dfMFB/dfB−1/(N−1) \\text{NFI} = \\frac{F_{B} - F_{M}}{F_{B}} \\quad \\text{} \\quad \\text{NNFI} = \\frac{F_{B}/\\text{df}_{B} - F_{M}/\\text{df}_{M}}{F_{B}/\\text{df}_{B} - 1/(N-1)}  term FBF_{B} refers value fitting function null model, FMF_{M} value fitting function model consideration. Thus, NFI measures increase fit relative fit null model specifying model. intuition NNFI (factor-based methods) expectation FM/dfMF_{M}/\\text{df}_{M} equal 1/N−11/N-1. automatically hold composite-based estimators. NNFI measures relative departure numerator’s term ’s expectation (denominator). , NNFI normed can take values larger 11. Main reference: Bentler Bonett (1980)","code":""},{"path":"https://floschuberth.github.io/cSEM/articles/Using-assess.html","id":"the-comparative-fit-index-cfi","dir":"Articles","previous_headings":"Methods & Formulae > Fit Indices > Formulae","what":"The comparative fit index (CFI)","title":"Postestimation: Assessing a model","text":"CFI defined : CFI=1−max(0,(N−1)FM−dfM)max(0,(N−1)FM−dfM,(N−1)FB−dfB) \\text{CFI} = 1 - \\frac{\\max(0, (N-1) F_{M}-\\text{df}_{M})}{\\max(0, (N-1) F_{M}-\\text{df}_{M}, (N-1)F_{B}-\\text{df}_{B})}  Like RMSEA, CFI non-centrality based index. measures increase fit (say reduction non-centrality) specifying model consideration relative fit null model. CFI normed index value 11 indicating best fit. Since makes use assumptions factor-based methods, intuition apply composite-based estimators. Main reference: Bentler (1990).","code":""},{"path":"https://floschuberth.github.io/cSEM/articles/Using-assess.html","id":"the-incremental-fit-index-ifi","dir":"Articles","previous_headings":"Methods & Formulae > Fit Indices > Formulae","what":"The incremental fit index (IFI)","title":"Postestimation: Assessing a model","text":"IFI defined : IFI=FB−FMFB−dfM/(N−1) \\text{IFI} = \\frac{F_{B} - F_{M}}{F_{B} - df_{M}/(N-1)}  rationale underlying IFI term FB−FMF_{B} - F_{M} (numerator) compared expectation FB−dfM/(N−1)F_{B} - \\text{df}_{M}/(N-1) (denominator). Main reference: Bollen (1989)","code":""},{"path":[]},{"path":"https://floschuberth.github.io/cSEM/articles/Using-assess.html","id":"implementation-2","dir":"Articles","previous_headings":"Methods & Formulae > Fit Indices","what":"Implementation","title":"Postestimation: Assessing a model","text":"functions implemented : calculateChiSquare(), calculateChiSquareDf(), calculateCFI(), calculateNFI(), calculateNNFI(), calculateIFI(), calculateGFI(), calculateRMSEA(), calculateRMSTheta(), calculateSRMR().","code":""},{"path":"https://floschuberth.github.io/cSEM/articles/Using-assess.html","id":"see-also-2","dir":"Articles","previous_headings":"Methods & Formulae > Fit Indices","what":"See also","title":"Postestimation: Assessing a model","text":"Several fit indices require fitting function, .e., distance measure like geodesic distance, squared Euclidean distance maximum likelihood distance. implemented : calculateDG(), calculateDL(), calculateDML().","code":""},{"path":[]},{"path":"https://floschuberth.github.io/cSEM/articles/Using-assess.html","id":"definition-3","dir":"Articles","previous_headings":"Methods & Formulae > Reliability","what":"Definition","title":"Postestimation: Assessing a model","text":"Reliability consistency measurement, .e., degree hypothetical repetition measure yield results. , reliability closeness measure error free measure. confused validity perfectly reliable measure may invalid. Practically, reliability must empirically assessed based theoretical framework. dominant theoretical framework compare empirical reliability results well-known true score framework provides foundation measurement model described Notation help file. Based true score framework using terminology notation Notation Termniology help files, reliability generic measurement defined : amount proxy true score variance, Var(η‾)Var(\\bar\\eta), relative proxy test score variance, Var(η̂)Var(\\hat\\eta). identical squared correlation common factor proxy/composite test score: ρη,η̂2=Cor(η,η̂)2\\rho_{\\eta, \\hat\\eta}^2 = Cor(\\eta, \\hat\\eta)^2. “kind” reliability commonly referred internal consistency reliability. Based true score theory three major types measurement models distinguished. type implies different assumptions give rise formulae written . well-established names different types measurement model provide natural naming candidates corresponding (internal consistency) reliabilities measure: Parallel – Assumption: ηkj=ηj→λkj=λj\\eta_{kj} = \\eta_j \\longrightarrow \\lambda_{kj} = \\lambda_j Var(εkj)=Var(εj)Var(\\varepsilon_{kj}) = Var(\\varepsilon_j). Tau-equivalent – Assumption: ηkj=ηj→λkj=λj\\eta_{kj} = \\eta_j \\longrightarrow \\lambda_{kj} = \\lambda_j Var(εkj)≠Var(εlj)Var(\\varepsilon_{kj}) \\neq Var(\\varepsilon_{lj}). Congeneric – Assumption: ηkj=λkjηj\\eta_{kj} = \\lambda_{kj}\\eta_j Var(εkj)≠Var(εlj)Var(\\varepsilon_{kj}) \\neq Var(\\varepsilon_{lj}). principal test score η̂\\hat\\eta weighted linear combinations indicators, .e., proxy stand-true score/common factor. Historically, however, test score generally assumed simple sum score, .e., weighted sum indicators weights assumed equal one. Hence, well-known reliability measures Jöreskog’s ρ\\rho Cronbach’s α\\alpha defined respect test score indeed represents simple sum score. Yet, reliability measures originally developed assuming sum score may equally well computed respect composite, .e., weighted score weights necessarily equal one. Apart form distinction congeneric (.e., Jöreskog’s ρ\\rho) tau-equivalent reliability (.e., Cronbach’s α\\alpha) therefore distinguish reliability estimates based test score (composite) uses weights weight approach used obtain .object test score (proxy) based unit weights. former indicated adding “weighted” original name.","code":""},{"path":"https://floschuberth.github.io/cSEM/articles/Using-assess.html","id":"formulae-3","dir":"Articles","previous_headings":"Methods & Formulae > Reliability","what":"Formulae","title":"Postestimation: Assessing a model","text":"general formula reliability (weighted) congeneric reliability: ρC;weighted=Var(η‾)Var(η̂k)=(𝐰′𝛌)2𝐰′𝚺𝐰 \\rho_{C; \\text{weighted}} = \\frac{Var(\\bar\\eta)}{Var(\\hat\\eta_k)} = \\frac{(\\boldsymbol{\\mathbf{w}}'\\boldsymbol{\\mathbf{\\lambda}})^2}{\\boldsymbol{\\mathbf{w}}'\\boldsymbol{\\mathbf{\\Sigma}}\\boldsymbol{\\mathbf{w}}} Assuming 𝐰=𝛊\\boldsymbol{\\mathbf{w}} = \\boldsymbol{\\mathbf{\\iota}}, .e., unit weights, “classical” formula congeneric reliability (.e., Jöreskog’s ρ\\rho), follows: ρC=Var(η‾)Var(η̂k)=(∑λk)2(∑λk)2+Var(ε‾) \\rho_C = \\frac{Var(\\bar\\eta)}{Var(\\hat\\eta_k)} = \\frac{\\left(\\sum\\lambda_k\\right)^2}{\\left(\\sum\\lambda_k\\right)^2 + Var(\\bar\\varepsilon)} Using assumptions imposed tau-equivalent measurement model obtain (weighted) tau-equivalent reliability, .e., (weighted) Cronbach’s alpha): ρT;weighted=λ2(∑wk)2λ2(∑wk)2+∑wk2Var(εk)=σ‾x(∑wk)2σ‾x[(∑wk)2−∑wk2]+∑wk2Var(xk) \\rho_{T; \\text{weighted}}  = \\frac{\\lambda^2(\\sum w_k)^2}{\\lambda^2(\\sum w_k)^2 + \\sum w_k^2Var(\\varepsilon_k)}  = \\frac{\\bar\\sigma_x(\\sum w_k)^2}{\\bar\\sigma_x[(\\sum w_k)^2 - \\sum w_k^2] + \\sum w_k^2Var(x_k)} used fact λk=λ\\lambda_k = \\lambda (tau-equivalence), λ2\\lambda^2 equals average covariance indicators: σ‾x=1K(K−1)∑k=1K∑l=1Kσkl\\bar\\sigma_x = \\frac{1}{K(K-1)}\\sum^K_{k=1}\\sum^K_{l=1} \\sigma_{kl} , assuming wk=1w_k = 1, .e., unit weights, “classical” formula tau-equivalent reliability (Cronbach’s α\\alpha) follows: ρT=λ2K2λ2K2+∑Var(ε‾k)=σ‾xK2σ‾x[K2−K]+KVar(xk) \\rho_T = \\frac{\\lambda^2K^2}{\\lambda^2K^2 + \\sum Var(\\bar\\varepsilon_k)}  = \\frac{\\bar\\sigma_xK^2}{\\bar\\sigma_x[K^2 - K] + K Var(x_k)} Using assumptions imposed parallel measurement model obtain parallel reliability: ρP=λ2(∑wk)2λ2(∑wk)2+Var(ε)∑wk2=σ‾x(∑wk)2σ‾x[(∑wk)2−∑wk2]+Var(x)∑wk2 \\rho_P = \\frac{\\lambda^2(\\sum w_k)^2}{\\lambda^2(\\sum w_k)^2 + Var(\\varepsilon)\\sum w_k^2} =   \\frac{\\bar\\sigma_x(\\sum w_k)^2}{\\bar\\sigma_x[(\\sum w_k)^2 - \\sum w_k^2] + Var(x)\\sum w_k^2} cSEM indicators always standardized weights chosen Var(η̂k)=1Var(\\hat\\eta_k) = 1. done scaling weight vector 𝐰\\boldsymbol{\\mathbf{w}} (𝐰′𝚺𝐰)−12(\\boldsymbol{\\mathbf{w}}'\\boldsymbol{\\mathbf{\\Sigma}}\\boldsymbol{\\mathbf{w}})^{-\\frac{1}{2}}. simplifies formulae: ρC;weighted=(∑wkλk)2=(𝐰′𝛌)2ρT;weighted=ρP;weighted=ρ‾x(∑wk)2 \\begin{align} \\rho_{C; \\text{weighted}} &= (\\sum w_k\\lambda_k)^2 = (\\boldsymbol{\\mathbf{w}}'\\boldsymbol{\\mathbf{\\lambda}})^2 \\\\ \\rho_{T; \\text{weighted}} = \\rho_{P; \\text{weighted}} &=  \\bar\\rho_x(\\sum w_k)^2 \\\\ \\end{align}  ρ‾x=σ‾x\\bar\\rho_x = \\bar\\sigma_x average correlation indicators. Consequently, parallel tau-equivalent reliability always identical cSEM. far formulae motivated theoretically. Since 𝚺\\boldsymbol{\\mathbf{\\Sigma}} unknown can replaced 𝐒\\boldsymbol{\\mathbf{S}} (empirical indicator correlation matrix) 𝚺̂\\hat{\\boldsymbol{\\mathbf{\\Sigma}}} (model-implied indicator correlation matrix), however, 𝐒\\boldsymbol{\\mathbf{S}} 𝚺̂\\hat{\\boldsymbol{\\mathbf{\\Sigma}}} generally equal. practical implication ρC\\rho_{C} computed (𝐰′𝛌)2(\\boldsymbol{\\mathbf{w}}'\\boldsymbol{\\mathbf{\\lambda}})^2 using unit weights weights can fact scaled (𝐰′𝐒𝐰)−12(\\boldsymbol{\\mathbf{w}}'\\boldsymbol{\\mathbf{S}}\\boldsymbol{\\mathbf{w}})^{-\\frac{1}{2}} (𝐰′𝚺̂𝐰)−12(\\boldsymbol{\\mathbf{w}}'\\hat{\\boldsymbol{\\mathbf{\\Sigma}}}\\boldsymbol{\\mathbf{w}})^{-\\frac{1}{2}}! Similarly, ρC;weighted\\rho_{C; \\text{weighted}} can computed using weights scaled using either 𝐒\\boldsymbol{\\mathbf{S}} 𝚺̂\\hat{\\boldsymbol{\\mathbf{\\Sigma}}}. Consequently fact four types congeneric reliability depending type weight type scaling weights. Hence, calculation “” congeneric reliability always: (𝐰′𝛌)2(\\boldsymbol{\\mathbf{w}}'\\boldsymbol{\\mathbf{\\lambda}})^2 𝐰\\boldsymbol{\\mathbf{w}} can : vector unit weights scaled (𝐰′𝚺̂𝐰)−12(\\boldsymbol{\\mathbf{w}}'\\hat{\\boldsymbol{\\mathbf{\\Sigma}}}\\boldsymbol{\\mathbf{w}})^{-\\frac{1}{2}}. typically people refer congeneric reliability (Jöreskog’s ρ\\rho). label type reliability estimate ρC\\rho_C. vector unit weights scaled (𝐰′𝐒𝐰)−12(\\boldsymbol{\\mathbf{w}}'\\boldsymbol{\\mathbf{S}}\\boldsymbol{\\mathbf{w}})^{-\\frac{1}{2}}. known name. usefulness open question. label type reliability estimate ρC;mm\\rho_{C;mm}. vector weights obtained using composite-based estimator (e.g. PLS-PM) scaled (𝐰′𝐒𝐰)−12(\\boldsymbol{\\mathbf{w}}'\\boldsymbol{\\mathbf{S}}\\boldsymbol{\\mathbf{w}})^{-\\frac{1}{2}}. Dijkstra Henseler’s ρA\\rho_A. label type reliability estimate ρC;weighted\\rho_{C;\\text{weighted}}. vector weights obtained using composite-based estimator (e.g. PLS-PM) scaled (𝐰′𝚺̂𝐰)−12(\\boldsymbol{\\mathbf{w}}'\\hat{\\boldsymbol{\\mathbf{\\Sigma}}}\\boldsymbol{\\mathbf{w}})^{-\\frac{1}{2}}. known name. usefulness open question. label type reliability estimate ρC;weighted;mm\\rho_{C;\\text{weighted};mm}","code":""},{"path":"https://floschuberth.github.io/cSEM/articles/Using-assess.html","id":"a-note-on-the-terminology","dir":"Articles","previous_headings":"Methods & Formulae > Reliability > Formulae","what":"A note on the terminology","title":"Postestimation: Assessing a model","text":"vast bulk literature dating back seminal work Spearman (e.g., Spearman (1904)) written subject reliability. Inevitably, definitions, formulae, notation terminology conventions unsystematic confusing. particularly true newcomers structural equation modeling applied users whose primary concern apply appropriate method appropriate case without poring books research papers understand intricate detail. cSEM seek make working reliabilities consistent possible relying paper Cho (2016) proposed uniform formula-generating methods systematic naming conventions common reliability measures. Naturally, conventional terminology deeply entrenched within nomenclatura particular filed (e.g., coefficient alpha alias Cronbach’s alpha pychometrics) new, albeit consistent, naming scheme seems superfluous best. However, belief merit “standardized” naming pattern eventually helpful users helps clarify potential misconceptions thus preventing potential misuse, (ab)use Cronbach alpha reliability measure congeneric measurement models. Apart considerations, package takes pragmatic stance sense use consistent naming naturally provides consistent naming scheme functions systematic formula generating methods make code maintenance easier. Eventually, matters formula correct application. facilitate translation different naming systems conventions provide “translation table” : Systematic names common synonymous names reliability estimates found literature","code":""},{"path":"https://floschuberth.github.io/cSEM/articles/Using-assess.html","id":"closed-form-confidence-interval","dir":"Articles","previous_headings":"Methods & Formulae > Reliability > Formulae","what":"Closed-form confidence interval","title":"Postestimation: Assessing a model","text":"Trinchera, Marie, Marcoulides (2018) proposed closed-form confidence interval (CI) tau-equivalent reliability (Cronbach’s alpha). compute CI, set .closed_form_ci = TRUE calling assess() invoke calculateRhoT(..., .closed_form_ci = TRUE) directly. level CI can changed supplying single value vector values .alpha.","code":""},{"path":"https://floschuberth.github.io/cSEM/articles/Using-assess.html","id":"implementation-3","dir":"Articles","previous_headings":"Methods & Formulae > Reliability","what":"Implementation","title":"Postestimation: Assessing a model","text":"functions implemented calculateRhoC() calculateRhoT().","code":""},{"path":[]},{"path":"https://floschuberth.github.io/cSEM/articles/Using-assess.html","id":"definition-4","dir":"Articles","previous_headings":"Methods & Formulae > The Goodness of Fit (GoF)","what":"Definition","title":"Postestimation: Assessing a model","text":"Calculate Goodness Fit (GoF) proposed Tenenhaus, Amanto, Vinzi (2004). Note , contrary name suggests, GoF measure (overall) model fit χ2\\chi^2-fit test sense. See e.g. Henseler Sarstedt (2012) discussion.","code":""},{"path":"https://floschuberth.github.io/cSEM/articles/Using-assess.html","id":"formulae-4","dir":"Articles","previous_headings":"Methods & Formulae > The Goodness of Fit (GoF)","what":"Formulae","title":"Postestimation: Assessing a model","text":"GoF defined : GoF=⌀COMk×⌀Rstructural2=1k∑k=1Kλk2+1M∑m=1MRm;structural2\\text{GoF} = \\sqrt{\\varnothing \\text{COM}_k \\times \\varnothing R^2_{structural}} =  \\sqrt{\\frac{1}{k}\\sum^K_{k=1} \\lambda^2_k + \\frac{1}{M} \\sum^M_{m = 1} R^2_{m;structural}}  COMkCOM_k communality indicator kk, .e. variance indicator explained connected latent variable Rm;structural2R^2_{m; structural} R squared mm’th equation structural model.","code":""},{"path":"https://floschuberth.github.io/cSEM/articles/Using-assess.html","id":"implementation-4","dir":"Articles","previous_headings":"Methods & Formulae > The Goodness of Fit (GoF)","what":"Implementation","title":"Postestimation: Assessing a model","text":"function implemented : calculateGoF().","code":""},{"path":[]},{"path":"https://floschuberth.github.io/cSEM/articles/Using-assess.html","id":"definition-5","dir":"Articles","previous_headings":"Methods & Formulae > The Heterotrait-Monotrait-Ratio of Correlations (HTMT)","what":"Definition","title":"Postestimation: Assessing a model","text":"heterotrait-monotrait ratio correlations (HTMT) first proposed byHenseler, Ringle, Sarstedt (2015) assess convergent discriminant validity.","code":""},{"path":"https://floschuberth.github.io/cSEM/articles/Using-assess.html","id":"formulae-5","dir":"Articles","previous_headings":"Methods & Formulae > The Heterotrait-Monotrait-Ratio of Correlations (HTMT)","what":"Formulae","title":"Postestimation: Assessing a model","text":"See: Henseler, Ringle, Sarstedt (2015) page 121 (equation (6))","code":""},{"path":"https://floschuberth.github.io/cSEM/articles/Using-assess.html","id":"implementation-5","dir":"Articles","previous_headings":"Methods & Formulae > The Heterotrait-Monotrait-Ratio of Correlations (HTMT)","what":"Implementation","title":"Postestimation: Assessing a model","text":"function implemented : calculateHTMT().","code":""},{"path":[]},{"path":"https://floschuberth.github.io/cSEM/articles/cSEM.html","id":"preface","dir":"Articles","previous_headings":"","what":"Preface","title":"Introduction to cSEM","text":"Structural equation modeling (SEM) used developed decades across variety research fields, including psychology, sociology, business research. almost inevitable consequence, different terminology system , extent, mathematical notation evolved within field years. “terminological mess” one major obstacles interdisciplinary research (scientific) debate, hinders broader understanding methodological issues , even worse, promotes systematic misuse (e.g., use Cronbach’s alpha estimator congeneric reliability). especially true users new SEM, practitioners overwhelmed terminology field, find term thought finally understood defined differently another field, adding confusion. prime example term “formative” (measurement) used describe causal-formative composite model, see e.g., Henseler (2017) clarification. Ultimately, matter (mis)communication, believe can satisfactorily resolved providing clear, unambiguous definition term symbol used package. emphasize trying impose “” conventions, claiming “correct” conventions, merely trying make communication us (authors package) (users package) unambiguous error-free possible. Therefore, provide Terminology file Notation file, contain key terms mathematical notation/symbols consider important, along definition. Users encouraged read files carefully avoid potential misunderstandings. Terminology file contains term feel defined explained ensure package users understand supplementary help files vignettes way package authors intended. Notation file contains fundamental mathematical notation/symbols used package documentation, along definition. exceptions, mostly follow standard notation laid e.g., Bollen (1989). package designed according set principles terminology part different commonly used open source commercial software packages similar content (e.g., SmartPLS). Together Terminology Notation files introduction explains principles. Finally, use cSEM effectively, helpful understand design. Therefore, architecture design package call “cSEM workflow” discussed.","code":""},{"path":[]},{"path":"https://floschuberth.github.io/cSEM/articles/cSEM.html","id":"what-is-structural-equation-modeling-sem","dir":"Articles","previous_headings":"Composite-based structural equation modeling","what":"What is structural equation modeling (SEM)","title":"Introduction to cSEM","text":"Structural equation modeling (SEM) analyzing, .e., modeling, estimating, assessing, testing, (causal) relationships concepts - entity defined conceptual definition - concepts /observable quantities generally referred indicators, manifest variables items. Broadly speaking, two modeling approaches concepts relationship exist. refer first latent variable common factor model second composite model. approach entails set methods, test, evaluation criteria well specific terminology may may adequate within realm approach.","code":""},{"path":"https://floschuberth.github.io/cSEM/articles/cSEM.html","id":"lvmodel","dir":"Articles","previous_headings":"Composite-based structural equation modeling > What is structural equation modeling (SEM)","what":"The classical latent variable or common factor model","title":"Introduction to cSEM","text":"Assuming researcher identifies JJconcepts KK indicators, fundamental feature latent variable model assumption existence set JJlatent variables (common factors) serve representation one JJconcepts studied sense latent variable causally responsible manifestations set KjK_jindicators supposed measure concept question. entirety measurement relations captured measurement model relates indicators latent variables according researchers theory observables related concepts question. entirety relationships concepts (.e., representation statistical model, construct) captured structural model whose parameters usually center researchers interest. Caution warranted though common factor respective concept thing. Within “classical” covariance-based factor-based literature concept, construct, latent variable representation common factor often used interchangeably (Rigdon 2012, 2016; Rigdon, Becker, Sarstedt 2019). case cSEM readers explicitly made aware fact concepts abstract entity may modeled common factor, however, assertion correctness approach terms “closeness common factor related concept” made. Parameters latent variable models usually retrieved maximum likelihood (ML). basic idea ML find parameters difference model-implied empirical indicator covariance matrix minimized. estimation methods therefore often referred covariance-based methods.","code":""},{"path":"https://floschuberth.github.io/cSEM/articles/cSEM.html","id":"cmodel","dir":"Articles","previous_headings":"Composite-based structural equation modeling > What is structural equation modeling (SEM)","what":"The composite model","title":"Introduction to cSEM","text":"second approach known composite model. opposed latent variable common factor model, composites presuppose existence latent variable. Hence, designed entities (artifacts) “OECD Better Life Index” arguably latent counterpart may adequately described composite, .e., linear combination observables defining composite. Composites may also formed represent latent variables/common factors (precisely concepts modeled common factors) case composite serves proxy stand-latent variable. However, cSEM, term “composite model” used refer model former sense, .e., model composite direct representation concept/construct! Parameters composite models retrieved composite-based approach partial least squares path modeling (PLS-PM), generalized structured component analysis (GSCA) dimension reduction techniques principal component analysis (PCA). basic idea composite-based approach build scores/composites concept subsequently retrieve structural model parameters series (linear) regressions. estimation methods therefore often referred variance-based methods regression maximizes explained variance dependent variable.","code":""},{"path":"https://floschuberth.github.io/cSEM/articles/cSEM.html","id":"what-is-composite-based-sem","dir":"Articles","previous_headings":"Composite-based structural equation modeling","what":"What is composite-based SEM?","title":"Introduction to cSEM","text":"Composite-based SEM entirety methods, approaches, procedures, algorithms way another involve linear compounds (composites/proxies/scores), .e., linear combinations observables retrieving (estimating) quantities interest coefficients structural model. crucial clearly distinguish composite model composite-based SEM. . former “” statistical model relating concepts observables, latter simply states composites - linear compounds, .e., weighted linear combinations observables - used retrieve quantities interest! Hence, composite-based SEM way obtaining/estimating parameters interest may thus used latent variable common factor model well composite model. However, interpretation parameter estimates fundamentally different since underlying models differ! sketched , common factor composite models fundamentally differ relation observables concepts modeled. Naturally, results , notably, (correct/meaningful) interpretation critically hinge type model user specifies. Across package therefore strictly distinguish Concepts/Constructs modeled common factors (alternatively latent variables) Concepts/Constructs modeled composites phrases repeatedly appear help files complementary files. therefore crucial remember supposed convey.","code":""},{"path":"https://floschuberth.github.io/cSEM/articles/cSEM.html","id":"using-csem","dir":"Articles","previous_headings":"","what":"Using cSEM","title":"Introduction to cSEM","text":"idea cSEM twofold: Provide unified framework common composite-based SEM approaches, including typical postestimation procedures. principal, similar lavaan covariance-bases/factor-based SEM. Make user experience hassle-free possible. first point always ongoing task since approaches constantly evolving new developments appearing pace , package authors, able keep . second point, however, particularly important us frustrated technical, unfriendly packages R can . Hence, start envisioned workflow essentially comprises three steps: Get essential: estimator approach works without data description parameters estimated data related parameters, .e. model. Hence, always need data set model. Since, model specification lavaan model syntax probably unbeatable ease well known R users interest SEM, us, lavaan model syntax obvious tool users specify model. Experience tells, R beginners biggest obstacle get data R. However, largely thanks RStudio, data import data transformation nowadays relatively easy handle. See Preparing data Specifying model sections . Estimate: matter model type data, estimation always done using one central function data first model second argument: Naturally, csem() function number additional arguments fine-tune estimation, however, since csem() automatically recognizes, instance, whether concept modeled common factor composite automatically applies appropriate correction attenuation, default arguments often sufficient. See Estimate using csem() section . Postestimate: Inspired grammar data manipulation underlying dplyr package, cSEM provides 5 postestimation verbs concisely cover common postestimation tasks well 4 additional test commands 2 general commands: assess() infer() predict() summarize() verify() testOMF() testMICOM() testHausman() testMGD() doIPMA() doNonlinearRedundancyAnalysis() doRedundancyAnalysis() verbs accept result call csem() input makes working function extremely simple. need remember word, specific syntax arguments. course, functions number additional arguments fine-tune postestimation. See Apply postestimation functions sections . details arguments consult individual help files. price pay increase flexibility primarily , mostly minor, loss computational speed, particular, intense resampling involved (.e., 5000 bootstrap run complex model , say, 1000 observations). Users looking efficient implementation common resampling routines may find faster implementations. said, believe, time saved using standardized estimate-postestimate workflow, matter model data used, well outweighs potential loss computational efficiency. following sections describe workflow detail.","code":"csem(.data = my_data, .model = my_model)"},{"path":"https://floschuberth.github.io/cSEM/articles/cSEM.html","id":"the-csem-workflow","dir":"Articles","previous_headings":"Using cSEM","what":"The cSEM-Workflow","title":"Introduction to cSEM","text":"described previous section, working cSEM consists 3-4 steps: Prepare/load data analyze Specify model estimate Estimate using csem() function Apply postestimation functions result 3.","code":""},{"path":"https://floschuberth.github.io/cSEM/articles/cSEM.html","id":"preparedata","dir":"Articles","previous_headings":"Using cSEM > The cSEM-Workflow","what":"Prepare the data","title":"Introduction to cSEM","text":"Technically, preparing data require cSEM therefore better considered preparation task, .e., “pre-cSEM” task. reason step nevertheless considered explicit part cSEM-workflow motivated experience applied/causal users tend shy away software like R “just getting data ” understanding show, manipulate work data can frustrating one aware R’s rich easy learn data import data processing capabilities. topics may overwhelming newcomers several years ago, data import data transformation become extremely simple user-friendly right tools packages used. best place start Rstudio Cheat sheet webpage, especially Data Import Data Transformation cheat sheets. cSEM relatively flexible type data accepted. Currently following data types/structures accepted: data.frame tibble column names matching indicator names used lavaan model description measurement composite model. Possible column types classes data provided : \"logical\" (TRUE/FALSE), \"numeric\" (\"double\" \"integer\"), \"factor\" (\"ordered\" /\"unordered\") mix several types. Additionally, data may also include one character column whose column name must given .id. Values column interpreted group identifiers csem() split data levels column run estimation level separately. Example: Assuming following simple model estimated: estimate model data frame NN rows (observations) K=4K = 4 columns column names expe1, imag1, expe2, imag2 required. order columns dataset irrelevant. cSEM order defined order names appear measurement composite model equations model description. case resulting matrix vector whose (row/column) names contain indicator names order expe1, expe2, imag1, imag2. one model specification . matrix column names matching indicator names used lavaan model description measurement model composite model description. list data frames matrices. case estimation repeated data frame matrix separately. current version 0.5.0 available CRAN provide tools handle missing values. Future versions likely include least basic approaches handling missing values. Regularly check https://github.com/FloSchuberth/cSEM/ get latest updates.","code":"model <- \" # Structural model EXPE ~ IMAG  # Reflective measurement model EXPE =~ expe1 + expe2 IMAG =~ imag1 + imag2 \""},{"path":"https://floschuberth.github.io/cSEM/articles/cSEM.html","id":"specifyingamodel","dir":"Articles","previous_headings":"Using cSEM > The cSEM-Workflow","what":"Specify a model","title":"Introduction to cSEM","text":"Models defined using lavaan model syntax. Currently, “standard” lavaan model syntax supported. comprises: definition latent variable/common factor (precisely: definition concept modeled common factor) “=~” operator. definition composite (precisely: definition concept modeled composite) “<~” operator. specification regression equations “~” operator. definition error (co)variances, indicator correlations, correlations exogenous constructs using “~~” operator. cSEM handles linear, nonlinear hierarchical models. Syntax model illustrated using variables build-satisfaction dataset. information see lavaan syntax tutorial.","code":""},{"path":"https://floschuberth.github.io/cSEM/articles/cSEM.html","id":"linear-models","dir":"Articles","previous_headings":"Using cSEM > The cSEM-Workflow > Specify a model","what":"Linear models","title":"Introduction to cSEM","text":"typical linear model look like : Note operator <~ tells cSEM concept left modeled composite; operator =~ tells cSEM concept left modeled common factor. ~~ tells cSEM measurement errors sat1 sat2 assumed correlate.","code":"model <- \" # Structural model EXPE ~ IMAG QUAL ~ EXPE VAL  ~ EXPE + QUAL SAT  ~ IMAG + EXPE + QUAL + VAL LOY  ~ IMAG + SAT  # Composite model IMAG <~ imag1 + imag2 + imag3                  # composite EXPE <~ expe1 + expe2 + expe3                  # composite QUAL <~ qual1 + qual2 + qual3 + qual4 + qual5  # composite VAL  <~ val1  + val2  + val3                   # composite  # Reflective measurement model SAT  =~ sat1  + sat2  + sat3  + sat4           # common factor LOY  =~ loy1  + loy2  + loy3  + loy4           # common factor  # Measurement error correlation sat1 ~~ sat2 \""},{"path":"https://floschuberth.github.io/cSEM/articles/cSEM.html","id":"nonlinear-models","dir":"Articles","previous_headings":"Using cSEM > The cSEM-Workflow > Specify a model","what":"Nonlinear models","title":"Introduction to cSEM","text":"Nonlinear terms specified interactions using dot operator \".\". Nonlinear terms include interactions exponential terms. latter described model syntax “interaction ”, e.g., x_1^3 = x1.x1.x1. Currently following terms allowed Single, e.g., eta1 Quadratic, e.g., eta1.eta1 Cubic, e.g., eta1.eta1.eta1 Two-way interaction, e.g., eta1.eta2 Three-way interaction, e.g., eta1.eta2.eta3 Quadratic two-way interaction, e.g., eta1.eta1.eta3 simple example look like :","code":"model <- \" # Structural model EXPE ~ IMAG + IMAG.IMAG  # Composite model EXPE <~ expe1 + expe2 IMAG <~ imag1 + imag2 \""},{"path":"https://floschuberth.github.io/cSEM/articles/cSEM.html","id":"hierarchical-second-order-models","dir":"Articles","previous_headings":"Using cSEM > The cSEM-Workflow > Specify a model","what":"Hierarchical (second order) models","title":"Introduction to cSEM","text":"Currently second-order models supported. Specification second-order construct takes place measurement/composite model. case QUAL modeled second-order common factor measured IMAG EXPE, IMAG EXPE modeled composites.","code":"model <- \" # Structural model SAT ~ QUAL VAL ~ SAT + QUAL  # Reflective measurement model SAT  =~ sat1 + sat2 VAL  =~ val1 + val2  # Composite model IMAG <~ imag1 + imag2 EXPE <~ expe1 + expe2  # Second-order term QUAL =~ IMAG + EXPE \""},{"path":"https://floschuberth.github.io/cSEM/articles/cSEM.html","id":"estimate-using-csem","dir":"Articles","previous_headings":"Using cSEM > The cSEM-Workflow","what":"Estimate using csem()","title":"Introduction to cSEM","text":"csem() central function package. Although possible estimate model using individual functions called csem() (parseModel(), processData(), calculateWeightsPLS(), estimatePath() etc.) using R’s :::mechanism non-exported functions, virtually always easier, safer quicker use csem() instead (functions exported). csem() accepts models data types described . result call csem()always object class cSEMResults. Technically, resulting object additional class attribute, namely cSEMResults_default, cSEMResults_multi cSEMResults_2ndorder depends type model /data provided, however, users usually need worry since postestimation functions automatically work classes. simplest possible call csem() involves data set model: equivalent : See csem() documentation details arguments.","code":"require(cSEM)  model <- \" # Path model / Regressions eta2 ~ eta1 eta3 ~ eta1 + eta2  # Reflective measurement model eta1 =~ y11 + y12 + y13 eta2 =~ y21 + y22 + y23 eta3 =~ y31 + y32 + y33 \"  a <- csem(.data = threecommonfactors, .model = model) a ## ________________________________________________________________________________ ## ----------------------------------- Overview ----------------------------------- ##  ## Estimation was successful. ##  ## The result is a list of class cSEMResults with list elements: ##  ##  - Estimates ##  - Information ##  ## To get an overview or help type: ##  ##  - ?cSEMResults ##  - str(<object-name>) ##  - listviewer::jsondedit(<object-name>, mode = 'view') ##  ## If you wish to access the list elements directly type e.g.  ##  ##  - <object-name>$Estimates ##  ## Available postestimation commands: ##  ##  - assess(<object-name>) ##  - infer(<object-name) ##  - predict(<object-name>) ##  - summarize(<object-name>) ##  - verify(<object-name>) ## ________________________________________________________________________________ csem(    .data                        = threecommonfactors,    .model                       = model,    .approach_cor_robust         = \"none\",    .approach_nl                 = \"sequential\",    .approach_paths              = \"OLS\",    .approach_weights            = \"PLS-PM\",    .conv_criterion              = \"diff_absolute\",    .disattenuate                = TRUE,    .dominant_indicators         = NULL,    .estimate_structural         = TRUE,    .id                          = NULL,    .iter_max                    = 100,    .normality                   = FALSE,    .PLS_approach_cf             = \"dist_squared_euclid\",    .PLS_ignore_structural_model = FALSE,    .PLS_modes                   = NULL,    .PLS_weight_scheme_inner     = \"path\",    .reliabilities               = NULL,    .starting_values             = NULL,    .tolerance                   = 1e-05,    .resample_method             = \"none\",    .resample_method2            = \"none\",    .R                           = 499,    .R2                          = 199,    .handle_inadmissibles        = \"drop\",    .user_funs                   = NULL,    .eval_plan                   = \"sequential\",    .seed                        = NULL,    .sign_change_option          = \"no\"     )"},{"path":"https://floschuberth.github.io/cSEM/articles/cSEM.html","id":"inference","dir":"Articles","previous_headings":"Using cSEM > The cSEM-Workflow > Estimate using csem()","what":"Inference","title":"Introduction to cSEM","text":"default, inferential quantities calculated since composite-based approaches, generally, closed-form solutions standard errors. cSEM relies bootstrap jackknife estimate standard errors, test statistics, critical quantiles, confidence intervals. cSEM offers two ways compute resamples: Inference can done first setting argument .resample_method \"jackkinfe\" \"bootstrap\" perform resampling subsequently use infer() (conveniently summarize() internally calls infer()) compute actual inferential quantities interest. result achieved passing cSEMResults object resamplecSEMResults() subsequently using summarize() infer(). Several confidence intervals implemented, see ?infer(): directly via infer() bootstrap jackknife resampling support platform-independent multiprocessing well random seeds via future framework. multiprocessing simply set .eval_plan = \"multiprocess\" case maximum number available cores used Windows. Windows many separate R instances opened background cores available instead. Note naturally overhead. Consequently, small number resamples multiprocessing generally faster compared sequential (single core) processing (default). Seeds set via .seed argument. typical call look like :","code":"b1 <- csem(.data = threecommonfactors, .model = model, .resample_method = \"bootstrap\") b2 <- resamplecSEMResults(a) summarize(b1) ## ________________________________________________________________________________ ## ----------------------------------- Overview ----------------------------------- ##  ##  General information: ##  ------------------------ ##  Estimation status                  = Ok ##  Number of observations             = 500 ##  Weight estimator                   = PLS-PM ##  Inner weighting scheme             = \"path\" ##  Type of indicator correlation      = Pearson ##  Path model estimator               = OLS ##  Second-order approach              = NA ##  Type of path model                 = Linear ##  Disattenuated                      = Yes (PLSc) ##  ##  Resample information: ##  --------------------- ##  Resample method                    = \"bootstrap\" ##  Number of resamples                = 499 ##  Number of admissible results       = 499 ##  Approach to handle inadmissibles   = \"drop\" ##  Sign change option                 = \"none\" ##  Random seed                        = 764908765 ##  ##  Construct details: ##  ------------------ ##  Name  Modeled as     Order         Mode       ##  ##  eta1  Common factor  First order   \"modeA\"    ##  eta2  Common factor  First order   \"modeA\"    ##  eta3  Common factor  First order   \"modeA\"    ##  ## ----------------------------------- Estimates ---------------------------------- ##  ## Estimated path coefficients: ## ============================ ##                                                              CI_percentile    ##   Path           Estimate  Std. error   t-stat.   p-value         95%         ##   eta2 ~ eta1      0.6713      0.0429   15.6332    0.0000 [ 0.5790; 0.7480 ]  ##   eta3 ~ eta1      0.4585      0.0845    5.4257    0.0000 [ 0.2980; 0.6319 ]  ##   eta3 ~ eta2      0.3052      0.0878    3.4751    0.0005 [ 0.1231; 0.4806 ]  ##  ## Estimated loadings: ## =================== ##                                                              CI_percentile    ##   Loading        Estimate  Std. error   t-stat.   p-value         95%         ##   eta1 =~ y11      0.6631      0.0424   15.6408    0.0000 [ 0.5834; 0.7430 ]  ##   eta1 =~ y12      0.6493      0.0394   16.4597    0.0000 [ 0.5708; 0.7231 ]  ##   eta1 =~ y13      0.7613      0.0325   23.4099    0.0000 [ 0.6944; 0.8261 ]  ##   eta2 =~ y21      0.5165      0.0519    9.9547    0.0000 [ 0.4095; 0.6103 ]  ##   eta2 =~ y22      0.7554      0.0353   21.3712    0.0000 [ 0.6887; 0.8188 ]  ##   eta2 =~ y23      0.7997      0.0404   19.8173    0.0000 [ 0.7145; 0.8712 ]  ##   eta3 =~ y31      0.8223      0.0335   24.5157    0.0000 [ 0.7526; 0.8808 ]  ##   eta3 =~ y32      0.6581      0.0398   16.5539    0.0000 [ 0.5772; 0.7296 ]  ##   eta3 =~ y33      0.7474      0.0386   19.3522    0.0000 [ 0.6723; 0.8264 ]  ##  ## Estimated weights: ## ================== ##                                                              CI_percentile    ##   Weight         Estimate  Std. error   t-stat.   p-value         95%         ##   eta1 <~ y11      0.3956      0.0222   17.8556    0.0000 [ 0.3532; 0.4364 ]  ##   eta1 <~ y12      0.3873      0.0206   18.8376    0.0000 [ 0.3491; 0.4280 ]  ##   eta1 <~ y13      0.4542      0.0202   22.5296    0.0000 [ 0.4178; 0.4969 ]  ##   eta2 <~ y21      0.3058      0.0271   11.3029    0.0000 [ 0.2545; 0.3559 ]  ##   eta2 <~ y22      0.4473      0.0221   20.2697    0.0000 [ 0.4068; 0.4919 ]  ##   eta2 <~ y23      0.4735      0.0209   22.6569    0.0000 [ 0.4376; 0.5135 ]  ##   eta3 <~ y31      0.4400      0.0190   23.1538    0.0000 [ 0.4021; 0.4760 ]  ##   eta3 <~ y32      0.3521      0.0189   18.6410    0.0000 [ 0.3134; 0.3864 ]  ##   eta3 <~ y33      0.3999      0.0189   21.1468    0.0000 [ 0.3661; 0.4396 ]  ##  ## ------------------------------------ Effects ----------------------------------- ##  ## Estimated total effects: ## ======================== ##                                                               CI_percentile    ##   Total effect    Estimate  Std. error   t-stat.   p-value         95%         ##   eta2 ~ eta1       0.6713      0.0429   15.6332    0.0000 [ 0.5790; 0.7480 ]  ##   eta3 ~ eta1       0.6634      0.0389   17.0619    0.0000 [ 0.5872; 0.7398 ]  ##   eta3 ~ eta2       0.3052      0.0878    3.4751    0.0005 [ 0.1231; 0.4806 ]  ##  ## Estimated indirect effects: ## =========================== ##                                                                  CI_percentile    ##   Indirect effect    Estimate  Std. error   t-stat.   p-value         95%         ##   eta3 ~ eta1          0.2049      0.0590    3.4715    0.0005 [ 0.0824; 0.3168 ]  ## ________________________________________________________________________________ ii <- infer(b1, .quantity = c(\"CI_standard_z\", \"CI_percentile\"), .alpha = c(0.01, 0.05)) ii$Path_estimates ## $CI_standard_z ##      eta2 ~ eta1 eta3 ~ eta1 eta3 ~ eta2 ## 99%L   0.5598612   0.2377709  0.08115925 ## 99%U   0.7810874   0.6731228  0.53353287 ## 95%L   0.5863081   0.2898159  0.13523915 ## 95%U   0.7546405   0.6210778  0.47945296 ##  ## $CI_percentile ##      eta2 ~ eta1 eta3 ~ eta1 eta3 ~ eta2 ## 99%L   0.5617044   0.2630452  0.07005526 ## 99%U   0.7739366   0.6773963  0.50542254 ## 95%L   0.5790356   0.2979587  0.12309674 ## 95%U   0.7480285   0.6318828  0.48056073 b <- csem(   .data            = satisfaction,   .model           = model,   .resample_method = \"bootstrap\",   .R               = 999,   .seed            = 98234,   .eval_plan       = \"multiprocess\")  # Output omitted"},{"path":"https://floschuberth.github.io/cSEM/articles/cSEM.html","id":"postestimate","dir":"Articles","previous_headings":"Using cSEM > The cSEM-Workflow","what":"Apply postestimation functions","title":"Introduction to cSEM","text":"5 major postestimation function 4 test-family functions: assess() Assess quality estimated model without conducting statistical test. Quality case taken catch-term common aspects model assessment. mainly comprises fit indices, reliability estimates, common validity assessment criteria related quality measures/indices rely formal test procedure. cSEM generic (fit) index quality/assessment measure referred quality criterion. infer() Calculate common inferential quantities. users interested estimated standard errors /confidences intervals summarize() usually helpful much user-friendly print method. predict() Predict indicator scores endogenous constructs based procedure introduced Shmueli et al. (2016). summarize() Summarize model. function mainly called side effect, printing structured summary estimates. also provides estimates user-friendly data frames. data frame format usually much convenient users intend present results e.g., paper presentation. verify() Verify admissibility estimated quantities given model. Results based estimated model exhibiting one following defects deemed inadmissible: non-convergence, loadings /(congeneric) reliabilities larger 1, construct VCV /model-implied VCV matrix positive (semi-)definite.","code":""},{"path":"https://floschuberth.github.io/cSEM/articles/cSEM.html","id":"the-test_-family-of-postestimation-functions","dir":"Articles","previous_headings":"Using cSEM > The cSEM-Workflow > Apply postestimation functions","what":"The test_* family of postestimation functions","title":"Introduction to cSEM","text":"testHausman() regression-based Hausman test SEM. testOMF() Test overall model fit based Beran Srivastava (1985). See also Dijkstra Henseler (2015). testMGD() Test group differences using several different approaches e.g., one described Klesel et al. (2019). testMICOM() Test measurement invariance composites proposed Henseler, Ringle, Sarstedt (2016)","code":""},{"path":"https://floschuberth.github.io/cSEM/articles/cSEM.html","id":"the-do_-family-of-postestimation-functions","dir":"Articles","previous_headings":"Using cSEM > The cSEM-Workflow > Apply postestimation functions","what":"The do_* family of postestimation functions","title":"Introduction to cSEM","text":"doIPMA() Performs importance-performance matrix analysis (IPMA). doNonlinearEffectsAnalysis() Performs nonlinear effects analysis floodlight surface analysis described e.g., Spiller et al. (2013). doRedundancyAnalysis() Performs redundancy analysis (RA) proposed Hair et al. (2016) reference Chin (1998). Technically, postestimation functions generic function methods objects class cSEMResults_default, cSEMResults_multi, cSEMResults_2ndorder. cSEM every cSEMResults_* object must also class cSEMResults internal reasons. using one major postestimation functions, method dispatch therefore technically done one cSEMResults_* class attributes, ignoring cSEMResults class attribute. long postestimation function used directly method dispatch practical concern end-user. difference, however, becomes important user seeks directly invoke internal function called one postestimation functions (e.g., calculateAVE() calculateHTMT() called assess()). case, objects class cSEMResults_default accepted ensures specific structure. Therefore, important remember internal functions generally generic.","code":""},{"path":"https://floschuberth.github.io/cSEM/articles/cSEM.html","id":"principles-underlying-csem","dir":"Articles","previous_headings":"Using cSEM","what":"Principles underlying cSEM","title":"Introduction to cSEM","text":"cSEM based number principles, shaped design, terminology scope. principles discussed ","code":""},{"path":"https://floschuberth.github.io/cSEM/articles/cSEM.html","id":"model-vs--estimation","dir":"Articles","previous_headings":"Using cSEM > Principles underlying cSEM","what":"Model vs. Estimation","title":"Introduction to cSEM","text":"way different concepts relationship modeled strictly distinct estimated. Hence strictly distinguish concepts modeled common factors (composites) actual estimation given model. opinion, differences fundamental understanding scope limits certain approach. notable consequence approaches partial least squares everything related (e.g., modes) generalized structured component analysis “” considered estimators/estimation approaches given model.","code":""},{"path":"https://floschuberth.github.io/cSEM/articles/cSEM.html","id":"composites-in-a-composite-model-vs--composites-in-a-common-factor-model-and-disattenuation","dir":"Articles","previous_headings":"Using cSEM > Principles underlying cSEM","what":"Composites in a composite model vs. composites in a common factor model and disattenuation","title":"Introduction to cSEM","text":"virtue package, cSEM uses composite-based estimators/approaches . Depending postulated model, linear compounds may therefore either serve composite part composite model proxy/stand-common factor. concept modeled common factor, proxy correlations, proxy-indicator correlations path coefficients inconsistent estimates supposed construct level counterparts (construct correlations, loadings path coefficients) unless proxy perfect representation construct level counterpart. commonly referred attenuation bias. Several approaches suggested correct biases. cSEM estimates correctly disattenuated default concepts involved modeled common factor! Disattenuation controlled .disattenuate argument csem(). Example Note since .approach_weights = \"PLS-PM\" .disattentuate = TRUE default (see role weighting scheme partial least squares (PLS) ) one concepts model modeled common factor, composite (proxy) correlations, loadings path coefficients adequately disattenuated using correction approach commonly known consistent partial least squares (PLSc). .disattenuate = FALSE concepts modeled composites “proper” PLS values returned.","code":"model <- \" ## Structural model eta2 ~ eta1  ## Measurement model eta1 <~ y11 + y12 + y13 eta2 =~ y21 + y22 + y23 \"  # Identical csem(threecommonfactors, model) csem(threecommonfactors, model, .disattenuate = TRUE)  # To supress automatic disattenuation csem(threecommonfactors, model, .disattenuate = FALSE)"},{"path":"https://floschuberth.github.io/cSEM/articles/cSEM.html","id":"roleofpls","dir":"Articles","previous_headings":"Using cSEM > Principles underlying cSEM","what":"The role of the weighting scheme and partial least squares (PLS)","title":"Introduction to cSEM","text":"principal, weighted combination appropriately chosen observables can used estimate structural relationships compounds. Hence, conceptual methodological issue discussed based composite build given (weighting) approach may equally well discussed potential weighting scheme. appropriateness potential superiority specific weighting approach “partial least squares path modeling” (PLS-PM) another “unit weights” (sum scores) generalized structured component analysis (GSCA) therefore extent question relative appropriateness relative superiority. notable consequence, believe well known approaches partial least squares path modeling (PLS-PM) generalized structured component analysis (GSCA) - contrary common belief - best exclusively understood prescriptions forming linear compounds based observables, .e., weighting approaches. , less.1 cSEM reflected fact \"PLS\" \"GSCA\" choices .approach_weights argument.","code":"model <- \" ## Structural model eta2 ~ eta1  ## Composite model eta1 <~ y11 + y12 + y13 eta2 <~ y21 + y22 + y23 \"  ### Currently the following weight approaches are implemented # Partial least squares path modeling (PLS) csem(threecommonfactors, model, .approach_weights = \"PLS-PM\") # default  # Generalized canonical correlation analysis (Kettenring approaches) csem(threecommonfactors, model, .approach_weights = \"SUMCORR\") csem(threecommonfactors, model, .approach_weights = \"MAXVAR\") csem(threecommonfactors, model, .approach_weights = \"SSQCORR\") csem(threecommonfactors, model, .approach_weights = \"MINVAR\") csem(threecommonfactors, model, .approach_weights = \"GENVAR\")  # Generalized structured component analysis (GSCA) csem(threecommonfactors, model, .approach_weights = \"GSCA\")  # Principal component analysis (PCA) csem(threecommonfactors, model, .approach_weights = \"PCA\")  # Factor score regression (FSR) using \"unit\", \"bartlett\" or \"regression\" weights csem(threecommonfactors, model, .approach_weights = \"unit\") csem(threecommonfactors, model, .approach_weights = \"bartlett\") csem(threecommonfactors, model, .approach_weights = \"regression\")"},{"path":[]},{"path":"https://floschuberth.github.io/cSEM/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Manuel E. Rademaker. Author. Florian Schuberth. Author, maintainer. Tamara Schamberger. Contributor. Michael Klesel. Contributor. Huu Phuc Nguyen. Contributor. Theo K. Dijkstra. Contributor. Jörg Henseler. Contributor.","code":""},{"path":"https://floschuberth.github.io/cSEM/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Rademaker, Manuel E. Schuberth, Florian (2020). cSEM: Composite-Based Structural Equation Modeling. Package version: 0.6.1. URL: https://floschuberth.github.io/cSEM/.","code":"@Manual{,   title = {cSEM: Composite-Based Structural Equation Modeling},   author = {Manuel E. Rademaker and Florian Schuberth},   year = {2020},   url = {https://floschuberth.github.io/cSEM/},   note = {Package version: 0.6.1}, }"},{"path":[]},{"path":"https://floschuberth.github.io/cSEM/index.html","id":"purpose","dir":"","previous_headings":"","what":"Purpose","title":"Composite-Based Structural Equation Modeling","text":"Estimate, analyse, test, study linear, nonlinear, hierarchical multi-group structural equation models using composite-based approaches procedures, including estimation techniques partial least squares path modeling (PLS-PM) derivatives (PLSc, OrdPLSc, robustPLSc), generalized structured component analysis (GSCA), generalized structured component analysis uniqueness terms (GSCAm), generalized canonical correlation analysis (GCCA), principal component analysis (PCA), factor score regression (FSR) using sum score, regression Bartlett scores (including bias correction using Croon’s approach), well several tests typical post-estimation procedures (e.g., verify admissibility estimates, assess model fit, test model fit, compute confidence intervals, compare groups, etc.).","code":""},{"path":"https://floschuberth.github.io/cSEM/index.html","id":"news-2025-05-15","dir":"","previous_headings":"","what":"News (2025-05-15):","title":"Composite-Based Structural Equation Modeling","text":"Release cSEM version 0.6.1 Release cSEM Version 0.6.0 Implementation plot() function visualize cSEM models. Thanks Nguyen. Enhancement predict() function","code":""},{"path":"https://floschuberth.github.io/cSEM/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Composite-Based Structural Equation Modeling","text":"package available CRAN: install development version, recommended, use:","code":"install.packages(\"cSEM\") # install.packages(\"devtools\") devtools::install_github(\"M-E-Rademaker/cSEM\")"},{"path":"https://floschuberth.github.io/cSEM/index.html","id":"getting-started","dir":"","previous_headings":"","what":"Getting started","title":"Composite-Based Structural Equation Modeling","text":"best place get started cSEM-website.","code":""},{"path":"https://floschuberth.github.io/cSEM/index.html","id":"basic-usage","dir":"","previous_headings":"","what":"Basic usage","title":"Composite-Based Structural Equation Modeling","text":"basic usage illustrated .  Usually, using cSEM 3 step procedure: Pick dataset specify model using lavaan syntax Use csem() Apply one post-estimation functions listed resulting object.","code":""},{"path":"https://floschuberth.github.io/cSEM/index.html","id":"post-estimation-functions","dir":"","previous_headings":"","what":"Post-Estimation Functions","title":"Composite-Based Structural Equation Modeling","text":"five major post-estimation verbs, three test family functions three -family function: assess() : assess model using common quality criteria infer() : calculate common inferential quantities (e.g., standard errors, confidence intervals) predict() : predict endogenous indicator values plot() : Plot cSEM model summarize() : summarize results verify() : verify admissibility estimates Tests performed using test family functions. Currently, following tests implemented: testCVPAT() performs cross-validated predictive ability test testOMF() : performs test overall model fit testMICOM() : performs test composite measurement invariance testMGD() : performs several tests assess multi-group differences testHausman() : performs regression-based Hausman test test endogeneity miscellaneous post-estimation functions belong -family functions. Currently, three functions implemented: doIPMA(): performs importance-performance matrix analysis doNonlinearEffectsAnalysis(): performs nonlinear effects analysis floodlight surface analysis doRedundancyAnalysis(): performs redundancy analysis functions require cSEMResults object.","code":""},{"path":"https://floschuberth.github.io/cSEM/index.html","id":"example","dir":"","previous_headings":"","what":"Example","title":"Composite-Based Structural Equation Modeling","text":"Models defined using lavaan syntax slight modifications (see Specifying model section cSEM-website). illustration use build-well-known satisfaction dataset. estimation conducted using csem() function. equal : result always named list class cSEMResults. access list elements use $: useful tool examine list listviewer package. new cSEM might good way familiarize structure cSEMResults object. Apply post-estimation functions:","code":"require(cSEM)      ## Note: The operator \"<~\" tells cSEM that the construct to its left is modeled ##       as a composite. ##       The operator \"=~\" tells cSEM that the construct to its left is modeled ##       as a common factor. ##       The operator \"~\" tells cSEM which are the dependent (left-hand side) and ##       independent variables (right-hand side).      model <- \" # Structural model EXPE ~ IMAG QUAL ~ EXPE VAL  ~ EXPE + QUAL SAT  ~ IMAG + EXPE + QUAL + VAL  LOY  ~ IMAG + SAT  # Composite model IMAG <~ imag1 + imag2 + imag3 EXPE <~ expe1 + expe2 + expe3  QUAL <~ qual1 + qual2 + qual3 + qual4 + qual5 VAL  <~ val1  + val2  + val3  # Reflective measurement model SAT  =~ sat1  + sat2  + sat3  + sat4 LOY  =~ loy1  + loy2  + loy3  + loy4 \" # Estimate using defaults res <- csem(.data = satisfaction, .model = model) res ## ________________________________________________________________________________ ## ----------------------------------- Overview ----------------------------------- ##  ## Estimation was successful. ##  ## The result is a list of class cSEMResults with list elements: ##  ##  - Estimates ##  - Information ##  ## To get an overview or help type: ##  ##  - ?cSEMResults ##  - str(<object-name>) ##  - listviewer::jsondedit(<object-name>, mode = 'view') ##  ## If you wish to access the list elements directly type e.g.  ##  ##  - <object-name>$Estimates ##  ## Available postestimation commands: ##  ##  - assess(<object-name>) ##  - infer(<object-name) ##  - predict(<object-name>) ##  - summarize(<object-name>) ##  - verify(<object-name>) ## ________________________________________________________________________________ csem(    .data                        = satisfaction,    .model                       = model,    .approach_cor_robust         = \"none\",    .approach_nl                 = \"sequential\",    .approach_paths              = \"OLS\",    .approach_weights            = \"PLS-PM\",    .conv_criterion              = \"diff_absolute\",    .disattenuate                = TRUE,    .dominant_indicators         = NULL,    .estimate_structural         = TRUE,    .id                          = NULL,    .iter_max                    = 100,    .normality                   = FALSE,    .PLS_approach_cf             = \"dist_squared_euclid\",    .PLS_ignore_structural_model = FALSE,    .PLS_modes                   = NULL,    .PLS_weight_scheme_inner     = \"path\",    .reliabilities               = NULL,    .starting_values             = NULL,    .tolerance                   = 1e-05,    .resample_method             = \"none\",     .resample_method2            = \"none\",    .R                           = 499,    .R2                          = 199,    .handle_inadmissibles        = \"drop\",    .user_funs                   = NULL,    .eval_plan                   = \"sequential\",    .seed                        = NULL,    .sign_change_option          = \"none\"     ) res$Estimates$Loading_estimates  res$Information$Model listviewer::jsonedit(res, mode = \"view\") # requires the listviewer package. ## Get a summary summarize(res) ## ________________________________________________________________________________ ## ----------------------------------- Overview ----------------------------------- ##  ##  General information: ##  ------------------------ ##  Estimation status                  = Ok ##  Number of observations             = 250 ##  Weight estimator                   = PLS-PM ##  Inner weighting scheme             = \"path\" ##  Type of indicator correlation      = Pearson ##  Path model estimator               = OLS ##  Second-order approach              = NA ##  Type of path model                 = Linear ##  Disattenuated                      = Yes (PLSc) ##  ##  Construct details: ##  ------------------ ##  Name  Modeled as     Order         Mode       ##  ##  IMAG  Composite      First order   \"modeB\"    ##  EXPE  Composite      First order   \"modeB\"    ##  QUAL  Composite      First order   \"modeB\"    ##  VAL   Composite      First order   \"modeB\"    ##  SAT   Common factor  First order   \"modeA\"    ##  LOY   Common factor  First order   \"modeA\"    ##  ## ----------------------------------- Estimates ---------------------------------- ##  ## Estimated path coefficients: ## ============================ ##   Path           Estimate  Std. error   t-stat.   p-value ##   EXPE ~ IMAG      0.4714          NA        NA        NA ##   QUAL ~ EXPE      0.8344          NA        NA        NA ##   VAL ~ EXPE       0.0457          NA        NA        NA ##   VAL ~ QUAL       0.7013          NA        NA        NA ##   SAT ~ IMAG       0.2450          NA        NA        NA ##   SAT ~ EXPE      -0.0172          NA        NA        NA ##   SAT ~ QUAL       0.2215          NA        NA        NA ##   SAT ~ VAL        0.5270          NA        NA        NA ##   LOY ~ IMAG       0.1819          NA        NA        NA ##   LOY ~ SAT        0.6283          NA        NA        NA ##  ## Estimated loadings: ## =================== ##   Loading          Estimate  Std. error   t-stat.   p-value ##   IMAG =~ imag1      0.6306          NA        NA        NA ##   IMAG =~ imag2      0.9246          NA        NA        NA ##   IMAG =~ imag3      0.9577          NA        NA        NA ##   EXPE =~ expe1      0.7525          NA        NA        NA ##   EXPE =~ expe2      0.9348          NA        NA        NA ##   EXPE =~ expe3      0.7295          NA        NA        NA ##   QUAL =~ qual1      0.7861          NA        NA        NA ##   QUAL =~ qual2      0.9244          NA        NA        NA ##   QUAL =~ qual3      0.7560          NA        NA        NA ##   QUAL =~ qual4      0.7632          NA        NA        NA ##   QUAL =~ qual5      0.7834          NA        NA        NA ##   VAL =~ val1        0.9518          NA        NA        NA ##   VAL =~ val2        0.8056          NA        NA        NA ##   VAL =~ val3        0.6763          NA        NA        NA ##   SAT =~ sat1        0.9243          NA        NA        NA ##   SAT =~ sat2        0.8813          NA        NA        NA ##   SAT =~ sat3        0.7127          NA        NA        NA ##   SAT =~ sat4        0.7756          NA        NA        NA ##   LOY =~ loy1        0.9097          NA        NA        NA ##   LOY =~ loy2        0.5775          NA        NA        NA ##   LOY =~ loy3        0.9043          NA        NA        NA ##   LOY =~ loy4        0.4917          NA        NA        NA ##  ## Estimated weights: ## ================== ##   Weight           Estimate  Std. error   t-stat.   p-value ##   IMAG <~ imag1      0.0156          NA        NA        NA ##   IMAG <~ imag2      0.4473          NA        NA        NA ##   IMAG <~ imag3      0.6020          NA        NA        NA ##   EXPE <~ expe1      0.2946          NA        NA        NA ##   EXPE <~ expe2      0.6473          NA        NA        NA ##   EXPE <~ expe3      0.2374          NA        NA        NA ##   QUAL <~ qual1      0.2370          NA        NA        NA ##   QUAL <~ qual2      0.4712          NA        NA        NA ##   QUAL <~ qual3      0.1831          NA        NA        NA ##   QUAL <~ qual4      0.1037          NA        NA        NA ##   QUAL <~ qual5      0.2049          NA        NA        NA ##   VAL <~ val1        0.7163          NA        NA        NA ##   VAL <~ val2        0.2202          NA        NA        NA ##   VAL <~ val3        0.2082          NA        NA        NA ##   SAT <~ sat1        0.3209          NA        NA        NA ##   SAT <~ sat2        0.3059          NA        NA        NA ##   SAT <~ sat3        0.2474          NA        NA        NA ##   SAT <~ sat4        0.2692          NA        NA        NA ##   LOY <~ loy1        0.3834          NA        NA        NA ##   LOY <~ loy2        0.2434          NA        NA        NA ##   LOY <~ loy3        0.3812          NA        NA        NA ##   LOY <~ loy4        0.2073          NA        NA        NA ##  ## Estimated indicator correlations: ## ================================= ##   Correlation       Estimate  Std. error   t-stat.   p-value ##   imag1 ~~ imag2      0.6437          NA        NA        NA ##   imag1 ~~ imag3      0.5433          NA        NA        NA ##   imag2 ~~ imag3      0.7761          NA        NA        NA ##   expe1 ~~ expe2      0.5353          NA        NA        NA ##   expe1 ~~ expe3      0.4694          NA        NA        NA ##   expe2 ~~ expe3      0.5467          NA        NA        NA ##   qual1 ~~ qual2      0.6053          NA        NA        NA ##   qual1 ~~ qual3      0.5406          NA        NA        NA ##   qual1 ~~ qual4      0.5662          NA        NA        NA ##   qual1 ~~ qual5      0.5180          NA        NA        NA ##   qual2 ~~ qual3      0.6187          NA        NA        NA ##   qual2 ~~ qual4      0.6517          NA        NA        NA ##   qual2 ~~ qual5      0.6291          NA        NA        NA ##   qual3 ~~ qual4      0.4752          NA        NA        NA ##   qual3 ~~ qual5      0.5074          NA        NA        NA ##   qual4 ~~ qual5      0.6402          NA        NA        NA ##   val1 ~~ val2        0.6344          NA        NA        NA ##   val1 ~~ val3        0.4602          NA        NA        NA ##   val2 ~~ val3        0.6288          NA        NA        NA ##  ## ------------------------------------ Effects ----------------------------------- ##  ## Estimated total effects: ## ======================== ##   Total effect    Estimate  Std. error   t-stat.   p-value ##   EXPE ~ IMAG       0.4714          NA        NA        NA ##   QUAL ~ IMAG       0.3933          NA        NA        NA ##   QUAL ~ EXPE       0.8344          NA        NA        NA ##   VAL ~ IMAG        0.2974          NA        NA        NA ##   VAL ~ EXPE        0.6309          NA        NA        NA ##   VAL ~ QUAL        0.7013          NA        NA        NA ##   SAT ~ IMAG        0.4807          NA        NA        NA ##   SAT ~ EXPE        0.5001          NA        NA        NA ##   SAT ~ QUAL        0.5911          NA        NA        NA ##   SAT ~ VAL         0.5270          NA        NA        NA ##   LOY ~ IMAG        0.4840          NA        NA        NA ##   LOY ~ EXPE        0.3142          NA        NA        NA ##   LOY ~ QUAL        0.3714          NA        NA        NA ##   LOY ~ VAL         0.3311          NA        NA        NA ##   LOY ~ SAT         0.6283          NA        NA        NA ##  ## Estimated indirect effects: ## =========================== ##   Indirect effect    Estimate  Std. error   t-stat.   p-value ##   QUAL ~ IMAG          0.3933          NA        NA        NA ##   VAL ~ IMAG           0.2974          NA        NA        NA ##   VAL ~ EXPE           0.5852          NA        NA        NA ##   SAT ~ IMAG           0.2357          NA        NA        NA ##   SAT ~ EXPE           0.5173          NA        NA        NA ##   SAT ~ QUAL           0.3696          NA        NA        NA ##   LOY ~ IMAG           0.3020          NA        NA        NA ##   LOY ~ EXPE           0.3142          NA        NA        NA ##   LOY ~ QUAL           0.3714          NA        NA        NA ##   LOY ~ VAL            0.3311          NA        NA        NA ## ________________________________________________________________________________ ## Verify admissibility of the results verify(res) ## ________________________________________________________________________________ ##  ## Verify admissibility: ##  ##   admissible ##  ## Details: ##  ##   Code   Status    Description ##   1      ok        Convergence achieved                                    ##   2      ok        All absolute standardized loading estimates <= 1        ##   3      ok        Construct VCV is positive semi-definite                 ##   4      ok        All reliability estimates <= 1                          ##   5      ok        Model-implied indicator VCV is positive semi-definite   ## ________________________________________________________________________________ ## Test overall model fit testOMF(res) ## ________________________________________________________________________________ ## --------- Test for overall model fit based on Beran & Srivastava (1985) -------- ##  ## Null hypothesis: ##  ##        ┌──────────────────────────────────────────────────────────────────┐ ##        │                                                                  │ ##        │   H0: The model-implied indicator covariance matrix equals the   │ ##        │   population indicator covariance matrix.                        │ ##        │                                                                  │ ##        └──────────────────────────────────────────────────────────────────┘ ##  ## Test statistic and critical value:  ##  ##                                      Critical value ##  Distance measure    Test statistic    95%    ##  dG                      0.6493      0.3250   ##  SRMR                    0.0940      0.0523   ##  dL                      2.2340      0.6921   ##  dML                     2.9219      1.6139   ##   ##  ## Decision:  ##  ##                          Significance level ##  Distance measure          95%    ##  dG                      reject   ##  SRMR                    reject   ##  dL                      reject   ##  dML                     reject   ##   ## Additional information: ##  ##  Out of 499 bootstrap replications 472 are admissible. ##  See ?verify() for what constitutes an inadmissible result. ##  ##  The seed used was: 1435398027 ## ________________________________________________________________________________ ## Assess the model assess(res) ## ________________________________________________________________________________ ##  ##  Construct        AVE           R2          R2_adj     ##  SAT            0.6851        0.7624        0.7585     ##  LOY            0.5552        0.5868        0.5834     ##  EXPE             NA          0.2222        0.2190     ##  QUAL             NA          0.6963        0.6951     ##  VAL              NA          0.5474        0.5438     ##  ## -------------- Common (internal consistency) reliability estimates ------------- ##  ##  Construct Cronbachs_alpha   Joereskogs_rho   Dijkstra-Henselers_rho_A  ##  SAT        0.8940           0.8960                0.9051           ##  LOY        0.8194           0.8237                0.8761           ##  ## ----------- Alternative (internal consistency) reliability estimates ----------- ##  ##  Construct       RhoC         RhoC_mm    RhoC_weighted ##  SAT            0.8960        0.8938        0.9051     ##  LOY            0.8237        0.8011        0.8761     ##  ##  Construct  RhoC_weighted_mm     RhoT      RhoT_weighted ##  SAT            0.9051        0.8940        0.8869     ##  LOY            0.8761        0.8194        0.7850     ##  ## --------------------------- Distance and fit measures -------------------------- ##  ##  Geodesic distance             = 0.6493432 ##  Squared Euclidean distance    = 2.23402 ##  ML distance                   = 2.921932 ##  ##  Chi_square       = 727.5611 ##  Chi_square_df    = 3.954137 ##  CFI              = 0.8598825 ##  CN               = 75.14588 ##  GFI              = 0.7280612 ##  IFI              = 0.8615598 ##  NFI              = 0.8229918 ##  NNFI             = 0.8240917 ##  RMSEA            = 0.108922 ##  RMS_theta        = 0.05069299 ##  SRMR             = 0.09396871 ##  ##  Degrees of freedom       = 184 ##  ## --------------------------- Model selection criteria --------------------------- ##  ##  Construct        AIC          AICc          AICu      ##  EXPE          -59.8152      192.2824      -57.8072    ##  QUAL          -294.9343     -42.8367      -292.9263   ##  VAL           -193.2127      58.9506      -190.1945   ##  SAT           -350.2874     -97.9418      -345.2368   ##  LOY           -215.9322      36.2311      -212.9141   ##  ##  Construct        BIC           FPE           GM       ##  EXPE          -52.7723       0.7872       259.8087    ##  QUAL          -287.8914      0.3074       271.8568    ##  VAL           -182.6483      0.4617       312.7010    ##  SAT           -332.6801      0.2463       278.2973    ##  LOY           -205.3678      0.4216       291.0665    ##  ##  Construct        HQ            HQc       Mallows_Cp   ##  EXPE          -56.9806      -56.8695       2.7658     ##  QUAL          -292.0997     -291.9886      14.8139    ##  VAL           -188.9608     -188.7516      52.1366    ##  SAT           -343.2010     -342.7088      10.6900    ##  LOY           -211.6804     -211.4711      30.5022    ##  ## ----------------------- Variance inflation factors (VIFs) ---------------------- ##  ##   Dependent construct: 'VAL' ##  ##  Independent construct    VIF value  ##  EXPE                      3.2928    ##  QUAL                      3.2928    ##  ##   Dependent construct: 'SAT' ##  ##  Independent construct    VIF value  ##  EXPE                      3.2985    ##  QUAL                      4.4151    ##  IMAG                      1.7280    ##  VAL                       2.6726    ##  ##   Dependent construct: 'LOY' ##  ##  Independent construct    VIF value  ##  IMAG                      1.9345    ##  SAT                       1.9345    ##  ## -------------- Variance inflation factors (VIFs) for modeB weights ------------- ##  ##   Construct: 'IMAG' ##  ##  Weight    VIF value  ##  imag1      1.7215    ##  imag2      3.0515    ##  imag3      2.5356    ##  ##   Construct: 'EXPE' ##  ##  Weight    VIF value  ##  expe1      1.4949    ##  expe2      1.6623    ##  expe3      1.5212    ##  ##   Construct: 'QUAL' ##  ##  Weight    VIF value  ##  qual1      1.8401    ##  qual2      2.5005    ##  qual3      1.7796    ##  qual4      2.1557    ##  qual5      2.0206    ##  ##   Construct: 'VAL' ##  ##  Weight    VIF value  ##  val1       1.6912    ##  val2       2.2049    ##  val3       1.6714    ##  ## -------------------------- Effect sizes (Cohen's f^2) -------------------------- ##  ##   Dependent construct: 'EXPE' ##  ##  Independent construct       f^2     ##  IMAG                      0.2856    ##  ##   Dependent construct: 'QUAL' ##  ##  Independent construct       f^2     ##  EXPE                      2.2928    ##  ##   Dependent construct: 'VAL' ##  ##  Independent construct       f^2     ##  EXPE                      0.0014    ##  QUAL                      0.3301    ##  ##   Dependent construct: 'SAT' ##  ##  Independent construct       f^2     ##  IMAG                      0.1462    ##  EXPE                      0.0004    ##  QUAL                      0.0468    ##  VAL                       0.4373    ##  ##   Dependent construct: 'LOY' ##  ##  Independent construct       f^2     ##  IMAG                      0.0414    ##  SAT                       0.4938    ##  ## ----------------------- Discriminant validity assessment ----------------------- ##  ##  Heterotrait-monotrait ratio of correlations matrix (HTMT matrix) ##  ##           SAT LOY ## SAT 1.0000000   0 ## LOY 0.7432489   1 ##  ##  ##  Advanced heterotrait-monotrait ratio of correlations matrix (HTMT2 matrix) ##  ##           SAT LOY ## SAT 1.0000000   0 ## LOY 0.7140046   1 ##  ##  ##  Fornell-Larcker matrix ##  ##           SAT       LOY ## SAT 0.6851491 0.5696460 ## LOY 0.5696460 0.5551718 ##  ##  ## ------------------------------------ Effects ----------------------------------- ##  ## Estimated total effects: ## ======================== ##   Total effect    Estimate  Std. error   t-stat.   p-value ##   EXPE ~ IMAG       0.4714          NA        NA        NA ##   QUAL ~ IMAG       0.3933          NA        NA        NA ##   QUAL ~ EXPE       0.8344          NA        NA        NA ##   VAL ~ IMAG        0.2974          NA        NA        NA ##   VAL ~ EXPE        0.6309          NA        NA        NA ##   VAL ~ QUAL        0.7013          NA        NA        NA ##   SAT ~ IMAG        0.4807          NA        NA        NA ##   SAT ~ EXPE        0.5001          NA        NA        NA ##   SAT ~ QUAL        0.5911          NA        NA        NA ##   SAT ~ VAL         0.5270          NA        NA        NA ##   LOY ~ IMAG        0.4840          NA        NA        NA ##   LOY ~ EXPE        0.3142          NA        NA        NA ##   LOY ~ QUAL        0.3714          NA        NA        NA ##   LOY ~ VAL         0.3311          NA        NA        NA ##   LOY ~ SAT         0.6283          NA        NA        NA ##  ## Estimated indirect effects: ## =========================== ##   Indirect effect    Estimate  Std. error   t-stat.   p-value ##   QUAL ~ IMAG          0.3933          NA        NA        NA ##   VAL ~ IMAG           0.2974          NA        NA        NA ##   VAL ~ EXPE           0.5852          NA        NA        NA ##   SAT ~ IMAG           0.2357          NA        NA        NA ##   SAT ~ EXPE           0.5173          NA        NA        NA ##   SAT ~ QUAL           0.3696          NA        NA        NA ##   LOY ~ IMAG           0.3020          NA        NA        NA ##   LOY ~ EXPE           0.3142          NA        NA        NA ##   LOY ~ QUAL           0.3714          NA        NA        NA ##   LOY ~ VAL            0.3311          NA        NA        NA ## ________________________________________________________________________________ ## Predict indicator scores of endogenous constructs predict(res) ## ________________________________________________________________________________ ## ----------------------------------- Overview ----------------------------------- ##  ##  Number of obs. training            = 225 ##  Number of obs. test                = 25 ##  Number of cv folds                 = 10 ##  Number of repetitions              = 1 ##  Handle inadmissibles               = stop ##  Estimator target                   = 'PLS-PM' ##  Estimator benchmark                = 'lm' ##  Disattenuation target              = 'TRUE' ##  Disattenuation benchmark           = 'FALSE' ##  Approach to predict                = 'earliest' ##  ## ------------------------------ Prediction metrics ------------------------------ ##  ##  ##   Name      MAE target  MAE benchmark  RMSE target RMSE benchmark   Q2_predict ##   expe1         1.4556         1.6007       1.9052         2.1120       0.0593 ##   expe2         1.4159         1.4995       1.9439         2.0341       0.1931 ##   expe3         1.6304         1.7347       2.1238         2.2121       0.1271 ##   qual1         1.4740         1.5633       1.9270         2.0706       0.1199 ##   qual2         1.5761         1.5390       2.0460         2.0554       0.2118 ##   qual3         1.7350         1.7318       2.2231         2.2706       0.1206 ##   qual4         1.2346         1.1964       1.5994         1.6335       0.2282 ##   qual5         1.5064         1.5112       1.9415         1.9621       0.1889 ##   val1          1.4447         1.3658       1.8682         1.7639       0.2512 ##   val2          1.2326         1.2260       1.6548         1.7262       0.1750 ##   val3          1.4873         1.3888       1.9705         1.9331       0.1483 ##   sat1          1.2469         1.2305       1.6435         1.6199       0.3427 ##   sat2          1.2227         1.1980       1.6310         1.6213       0.3147 ##   sat3          1.3372         1.2875       1.6663         1.7222       0.2161 ##   sat4          1.3138         1.2554       1.6645         1.6325       0.2800 ##   loy1          1.6853         1.6585       2.2295         2.2199       0.2744 ##   loy2          1.4885         1.4893       1.9173         1.9841       0.1321 ##   loy3          1.7060         1.6589       2.2828         2.2600       0.2706 ##   loy4          1.6858         1.6848       2.1760         2.2958       0.0908 ## ________________________________________________________________________________"},{"path":"https://floschuberth.github.io/cSEM/index.html","id":"resampling-and-inference","dir":"","previous_headings":"Example","what":"Resampling and Inference","title":"Composite-Based Structural Equation Modeling","text":"default inferential statistics calculated since composite-based estimators closed-form expressions standard errors. Resampling used instead. cSEM mostly relies bootstrap procedure (although jackknife implemented well) estimate standard errors, test statistics, critical quantiles. cSEM offers two ways resampling: Setting .resample_method csem() \"jackknife\" \"bootstrap\" subsequently using post-estimation functions summarize() infer(). result achieved passing cSEMResults object resamplecSEMResults() subsequently using post-estimation functions summarize() infer(). summarize() function reports inferential statistics: Several bootstrap-based confidence intervals implemented, see ?infer(): bootstrap jackknife resampling support platform-independent multiprocessing well setting random seeds via future framework. multiprocessing simply set .eval_plan = \"multisession\" case maximum number available cores used Windows. Windows many separate R instances opened background cores available instead. Note naturally overhead small number resamples multiprocessing always faster compared sequential (single core) processing (default). Seeds set via .seed argument.","code":"# Setting `.resample_method` b1 <- csem(.data = satisfaction, .model = model, .resample_method = \"bootstrap\") # Using resamplecSEMResults() b2 <- resamplecSEMResults(res) summarize(b1) ## ________________________________________________________________________________ ## ----------------------------------- Overview ----------------------------------- ##  ##  General information: ##  ------------------------ ##  Estimation status                  = Ok ##  Number of observations             = 250 ##  Weight estimator                   = PLS-PM ##  Inner weighting scheme             = \"path\" ##  Type of indicator correlation      = Pearson ##  Path model estimator               = OLS ##  Second-order approach              = NA ##  Type of path model                 = Linear ##  Disattenuated                      = Yes (PLSc) ##  ##  Resample information: ##  --------------------- ##  Resample method                    = \"bootstrap\" ##  Number of resamples                = 499 ##  Number of admissible results       = 484 ##  Approach to handle inadmissibles   = \"drop\" ##  Sign change option                 = \"none\" ##  Random seed                        = 1977515262 ##  ##  Construct details: ##  ------------------ ##  Name  Modeled as     Order         Mode       ##  ##  IMAG  Composite      First order   \"modeB\"    ##  EXPE  Composite      First order   \"modeB\"    ##  QUAL  Composite      First order   \"modeB\"    ##  VAL   Composite      First order   \"modeB\"    ##  SAT   Common factor  First order   \"modeA\"    ##  LOY   Common factor  First order   \"modeA\"    ##  ## ----------------------------------- Estimates ---------------------------------- ##  ## Estimated path coefficients: ## ============================ ##                                                              CI_percentile    ##   Path           Estimate  Std. error   t-stat.   p-value         95%         ##   EXPE ~ IMAG      0.4714      0.0640    7.3620    0.0000 [ 0.3525; 0.6041 ]  ##   QUAL ~ EXPE      0.8344      0.0237   35.2259    0.0000 [ 0.7834; 0.8746 ]  ##   VAL ~ EXPE       0.0457      0.0880    0.5193    0.6036 [-0.1027; 0.2278 ]  ##   VAL ~ QUAL       0.7013      0.0840    8.3519    0.0000 [ 0.5243; 0.8539 ]  ##   SAT ~ IMAG       0.2450      0.0527    4.6468    0.0000 [ 0.1478; 0.3510 ]  ##   SAT ~ EXPE      -0.0172      0.0699   -0.2467    0.8052 [-0.1533; 0.1141 ]  ##   SAT ~ QUAL       0.2215      0.0955    2.3203    0.0203 [ 0.0409; 0.4150 ]  ##   SAT ~ VAL        0.5270      0.0877    6.0077    0.0000 [ 0.3423; 0.6807 ]  ##   LOY ~ IMAG       0.1819      0.0832    2.1864    0.0288 [ 0.0255; 0.3480 ]  ##   LOY ~ SAT        0.6283      0.0848    7.4083    0.0000 [ 0.4721; 0.7900 ]  ##  ## Estimated loadings: ## =================== ##                                                                CI_percentile    ##   Loading          Estimate  Std. error   t-stat.   p-value         95%         ##   IMAG =~ imag1      0.6306      0.0952    6.6224    0.0000 [ 0.4389; 0.8012 ]  ##   IMAG =~ imag2      0.9246      0.0386   23.9330    0.0000 [ 0.8249; 0.9780 ]  ##   IMAG =~ imag3      0.9577      0.0289   33.1944    0.0000 [ 0.8788; 0.9911 ]  ##   EXPE =~ expe1      0.7525      0.0768    9.8003    0.0000 [ 0.5672; 0.8676 ]  ##   EXPE =~ expe2      0.9348      0.0268   34.8163    0.0000 [ 0.8642; 0.9702 ]  ##   EXPE =~ expe3      0.7295      0.0712   10.2453    0.0000 [ 0.5768; 0.8405 ]  ##   QUAL =~ qual1      0.7861      0.0713   11.0301    0.0000 [ 0.6199; 0.8845 ]  ##   QUAL =~ qual2      0.9244      0.0214   43.1845    0.0000 [ 0.8720; 0.9573 ]  ##   QUAL =~ qual3      0.7560      0.0604   12.5064    0.0000 [ 0.6218; 0.8496 ]  ##   QUAL =~ qual4      0.7632      0.0531   14.3743    0.0000 [ 0.6462; 0.8520 ]  ##   QUAL =~ qual5      0.7834      0.0456   17.1646    0.0000 [ 0.6719; 0.8527 ]  ##   VAL =~ val1        0.9518      0.0210   45.2347    0.0000 [ 0.8984; 0.9832 ]  ##   VAL =~ val2        0.8056      0.0601   13.4012    0.0000 [ 0.6615; 0.9042 ]  ##   VAL =~ val3        0.6763      0.0714    9.4781    0.0000 [ 0.5234; 0.7999 ]  ##   SAT =~ sat1        0.9243      0.0223   41.4418    0.0000 [ 0.8741; 0.9612 ]  ##   SAT =~ sat2        0.8813      0.0274   32.1173    0.0000 [ 0.8216; 0.9308 ]  ##   SAT =~ sat3        0.7127      0.0561   12.6974    0.0000 [ 0.5969; 0.8043 ]  ##   SAT =~ sat4        0.7756      0.0515   15.0636    0.0000 [ 0.6644; 0.8675 ]  ##   LOY =~ loy1        0.9097      0.0520   17.4780    0.0000 [ 0.7958; 0.9895 ]  ##   LOY =~ loy2        0.5775      0.0876    6.5891    0.0000 [ 0.3783; 0.7264 ]  ##   LOY =~ loy3        0.9043      0.0427   21.1566    0.0000 [ 0.8064; 0.9770 ]  ##   LOY =~ loy4        0.4917      0.0956    5.1452    0.0000 [ 0.3125; 0.6821 ]  ##  ## Estimated weights: ## ================== ##                                                                CI_percentile    ##   Weight           Estimate  Std. error   t-stat.   p-value         95%         ##   IMAG <~ imag1      0.0156      0.1142    0.1369    0.8911 [-0.1863; 0.2543 ]  ##   IMAG <~ imag2      0.4473      0.1458    3.0679    0.0022 [ 0.1813; 0.7350 ]  ##   IMAG <~ imag3      0.6020      0.1382    4.3572    0.0000 [ 0.3181; 0.8331 ]  ##   EXPE <~ expe1      0.2946      0.1158    2.5450    0.0109 [ 0.0609; 0.5113 ]  ##   EXPE <~ expe2      0.6473      0.0810    7.9964    0.0000 [ 0.4796; 0.7816 ]  ##   EXPE <~ expe3      0.2374      0.0923    2.5713    0.0101 [ 0.0562; 0.4040 ]  ##   QUAL <~ qual1      0.2370      0.0916    2.5883    0.0096 [ 0.0738; 0.4230 ]  ##   QUAL <~ qual2      0.4712      0.0756    6.2361    0.0000 [ 0.3216; 0.6112 ]  ##   QUAL <~ qual3      0.1831      0.0806    2.2725    0.0231 [ 0.0168; 0.3288 ]  ##   QUAL <~ qual4      0.1037      0.0617    1.6804    0.0929 [-0.0057; 0.2300 ]  ##   QUAL <~ qual5      0.2049      0.0570    3.5919    0.0003 [ 0.0856; 0.3090 ]  ##   VAL <~ val1        0.7163      0.0899    7.9683    0.0000 [ 0.5290; 0.8811 ]  ##   VAL <~ val2        0.2202      0.0905    2.4336    0.0149 [ 0.0454; 0.4062 ]  ##   VAL <~ val3        0.2082      0.0586    3.5516    0.0004 [ 0.0883; 0.3139 ]  ##   SAT <~ sat1        0.3209      0.0156   20.5296    0.0000 [ 0.2937; 0.3547 ]  ##   SAT <~ sat2        0.3059      0.0142   21.5290    0.0000 [ 0.2827; 0.3375 ]  ##   SAT <~ sat3        0.2474      0.0122   20.2398    0.0000 [ 0.2213; 0.2683 ]  ##   SAT <~ sat4        0.2692      0.0123   21.8476    0.0000 [ 0.2454; 0.2916 ]  ##   LOY <~ loy1        0.3834      0.0273   14.0506    0.0000 [ 0.3266; 0.4380 ]  ##   LOY <~ loy2        0.2434      0.0314    7.7566    0.0000 [ 0.1702; 0.2948 ]  ##   LOY <~ loy3        0.3812      0.0267   14.2502    0.0000 [ 0.3298; 0.4309 ]  ##   LOY <~ loy4        0.2073      0.0356    5.8233    0.0000 [ 0.1410; 0.2821 ]  ##  ## Estimated indicator correlations: ## ================================= ##                                                                 CI_percentile    ##   Correlation       Estimate  Std. error   t-stat.   p-value         95%         ##   imag1 ~~ imag2      0.6437      0.0669    9.6187    0.0000 [ 0.4950; 0.7655 ]  ##   imag1 ~~ imag3      0.5433      0.0681    7.9783    0.0000 [ 0.4038; 0.6783 ]  ##   imag2 ~~ imag3      0.7761      0.0377   20.5965    0.0000 [ 0.7038; 0.8448 ]  ##   expe1 ~~ expe2      0.5353      0.0579    9.2489    0.0000 [ 0.4101; 0.6323 ]  ##   expe1 ~~ expe3      0.4694      0.0586    8.0072    0.0000 [ 0.3537; 0.5865 ]  ##   expe2 ~~ expe3      0.5467      0.0591    9.2453    0.0000 [ 0.4313; 0.6512 ]  ##   qual1 ~~ qual2      0.6053      0.0604   10.0187    0.0000 [ 0.4773; 0.7063 ]  ##   qual1 ~~ qual3      0.5406      0.0620    8.7262    0.0000 [ 0.4062; 0.6377 ]  ##   qual1 ~~ qual4      0.5662      0.0641    8.8274    0.0000 [ 0.4442; 0.6822 ]  ##   qual1 ~~ qual5      0.5180      0.0688    7.5334    0.0000 [ 0.3753; 0.6428 ]  ##   qual2 ~~ qual3      0.6187      0.0528   11.7130    0.0000 [ 0.4954; 0.7022 ]  ##   qual2 ~~ qual4      0.6517      0.0593   10.9968    0.0000 [ 0.5210; 0.7559 ]  ##   qual2 ~~ qual5      0.6291      0.0574   10.9637    0.0000 [ 0.5080; 0.7250 ]  ##   qual3 ~~ qual4      0.4752      0.0616    7.7088    0.0000 [ 0.3453; 0.5831 ]  ##   qual3 ~~ qual5      0.5074      0.0606    8.3760    0.0000 [ 0.3788; 0.6139 ]  ##   qual4 ~~ qual5      0.6402      0.0568   11.2775    0.0000 [ 0.5190; 0.7359 ]  ##   val1 ~~ val2        0.6344      0.0531   11.9377    0.0000 [ 0.5227; 0.7338 ]  ##   val1 ~~ val3        0.4602      0.0684    6.7307    0.0000 [ 0.3247; 0.5922 ]  ##   val2 ~~ val3        0.6288      0.0645    9.7494    0.0000 [ 0.4793; 0.7373 ]  ##  ## ------------------------------------ Effects ----------------------------------- ##  ## Estimated total effects: ## ======================== ##                                                               CI_percentile    ##   Total effect    Estimate  Std. error   t-stat.   p-value         95%         ##   EXPE ~ IMAG       0.4714      0.0640    7.3620    0.0000 [ 0.3525; 0.6041 ]  ##   QUAL ~ IMAG       0.3933      0.0601    6.5404    0.0000 [ 0.2804; 0.5152 ]  ##   QUAL ~ EXPE       0.8344      0.0237   35.2259    0.0000 [ 0.7834; 0.8746 ]  ##   VAL ~ IMAG        0.2974      0.0611    4.8645    0.0000 [ 0.1970; 0.4252 ]  ##   VAL ~ EXPE        0.6309      0.0516   12.2352    0.0000 [ 0.5300; 0.7305 ]  ##   VAL ~ QUAL        0.7013      0.0840    8.3519    0.0000 [ 0.5243; 0.8539 ]  ##   SAT ~ IMAG        0.4807      0.0663    7.2488    0.0000 [ 0.3556; 0.6152 ]  ##   SAT ~ EXPE        0.5001      0.0547    9.1357    0.0000 [ 0.3901; 0.6035 ]  ##   SAT ~ QUAL        0.5911      0.0908    6.5110    0.0000 [ 0.3895; 0.7502 ]  ##   SAT ~ VAL         0.5270      0.0877    6.0077    0.0000 [ 0.3423; 0.6807 ]  ##   LOY ~ IMAG        0.4840      0.0672    7.2055    0.0000 [ 0.3582; 0.6266 ]  ##   LOY ~ EXPE        0.3142      0.0528    5.9525    0.0000 [ 0.2136; 0.4154 ]  ##   LOY ~ QUAL        0.3714      0.0829    4.4819    0.0000 [ 0.2180; 0.5392 ]  ##   LOY ~ VAL         0.3311      0.0782    4.2348    0.0000 [ 0.1895; 0.4858 ]  ##   LOY ~ SAT         0.6283      0.0848    7.4083    0.0000 [ 0.4721; 0.7900 ]  ##  ## Estimated indirect effects: ## =========================== ##                                                                  CI_percentile    ##   Indirect effect    Estimate  Std. error   t-stat.   p-value         95%         ##   QUAL ~ IMAG          0.3933      0.0601    6.5404    0.0000 [ 0.2804; 0.5152 ]  ##   VAL ~ IMAG           0.2974      0.0611    4.8645    0.0000 [ 0.1970; 0.4252 ]  ##   VAL ~ EXPE           0.5852      0.0717    8.1581    0.0000 [ 0.4398; 0.7218 ]  ##   SAT ~ IMAG           0.2357      0.0484    4.8657    0.0000 [ 0.1492; 0.3401 ]  ##   SAT ~ EXPE           0.5173      0.0625    8.2764    0.0000 [ 0.4006; 0.6383 ]  ##   SAT ~ QUAL           0.3696      0.0615    6.0090    0.0000 [ 0.2420; 0.4795 ]  ##   LOY ~ IMAG           0.3020      0.0552    5.4680    0.0000 [ 0.2020; 0.4177 ]  ##   LOY ~ EXPE           0.3142      0.0528    5.9525    0.0000 [ 0.2136; 0.4154 ]  ##   LOY ~ QUAL           0.3714      0.0829    4.4819    0.0000 [ 0.2180; 0.5392 ]  ##   LOY ~ VAL            0.3311      0.0782    4.2348    0.0000 [ 0.1895; 0.4858 ]  ## ________________________________________________________________________________ infer(b1, .quantity = c(\"CI_standard_z\", \"CI_percentile\")) # no print method yet b <- csem(   .data            = satisfaction,   .model           = model,    .resample_method = \"bootstrap\",   .R               = 999,   .seed            = 98234,   .eval_plan       = \"multisession\")"},{"path":"https://floschuberth.github.io/cSEM/reference/Anime.html","id":null,"dir":"Reference","previous_headings":"","what":"Data: Anime — Anime","title":"Data: Anime — Anime","text":"data frame 183 observations 13 variables.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/Anime.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Data: Anime — Anime","text":"","code":"Anime"},{"path":"https://floschuberth.github.io/cSEM/reference/Anime.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Data: Anime — Anime","text":"object class data.frame 183 rows 13 columns.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/Anime.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Data: Anime — Anime","text":"Original source: github.com/ISS-Analytics/pls-predict/","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/Anime.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Data: Anime — Anime","text":"data set example github.com/ISS-Analytics/pls-predict/ irrelevant variables removed.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/Benitezetal2020.html","id":null,"dir":"Reference","previous_headings":"","what":"Data: Benitezetal2020 — Benitezetal2020","title":"Data: Benitezetal2020 — Benitezetal2020","text":"data frame containing 22 variables 300 observations.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/Benitezetal2020.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Data: Benitezetal2020 — Benitezetal2020","text":"","code":"Benitezetal2020"},{"path":"https://floschuberth.github.io/cSEM/reference/Benitezetal2020.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Data: Benitezetal2020 — Benitezetal2020","text":"object class data.frame 300 rows 22 columns.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/Benitezetal2020.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Data: Benitezetal2020 — Benitezetal2020","text":"dataset provided supplementary material Benitez et al. (2020) .","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/Benitezetal2020.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Data: Benitezetal2020 — Benitezetal2020","text":"simulated data contains variables social executive employee behavior. Moreover, contains variables social media capability business performance. dataset used illustrative example Benitez et al. (2020) .","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/Benitezetal2020.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Data: Benitezetal2020 — Benitezetal2020","text":"Benitez J, Henseler J, Castillo , Schuberth F (2020). “perform report impactful analysis using partial least squares: Guidelines confirmatory explanatory research.” Information & Management, 2(57), 103168. doi:10.1016/j.im.2019.05.003 .","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/Benitezetal2020.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Data: Benitezetal2020 — Benitezetal2020","text":"","code":"#============================================================================ # Example is taken from Benitez et al. (2020) #============================================================================ model_Benitez <-\" # Reflective measurement models# Reflective measurement models SEXB =~ SEXB1 + SEXB2 + SEXB3 +SEXB4 SEMB =~ SEMB1 + SEMB2 + SEMB3 + SEMB4  # Composite models SMC <~ SMC1 + SMC2 + SMC3 + SMC4 BPP <~ BPP1 + BPP2 + BPP3 + BPP4 + BPP5  # Control variables FS<~ FirmSize Ind <~ Industry1 + Industry2 + Industry3  # Structural model SMC ~ SEXB + SEMB  BPP ~ SMC + Ind + FS \"  out <- csem(.data = Benitezetal2020, .model = model_Benitez,             .PLS_weight_scheme_inner = 'factorial',             .tolerance = 1e-06)"},{"path":"https://floschuberth.github.io/cSEM/reference/BergamiBagozzi2000.html","id":null,"dir":"Reference","previous_headings":"","what":"Data: BergamiBagozzi2000 — BergamiBagozzi2000","title":"Data: BergamiBagozzi2000 — BergamiBagozzi2000","text":"data frame containing 22 variables 305 observations.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/BergamiBagozzi2000.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Data: BergamiBagozzi2000 — BergamiBagozzi2000","text":"","code":"BergamiBagozzi2000"},{"path":"https://floschuberth.github.io/cSEM/reference/BergamiBagozzi2000.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Data: BergamiBagozzi2000 — BergamiBagozzi2000","text":"object class data.frame 305 rows 22 columns.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/BergamiBagozzi2000.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Data: BergamiBagozzi2000 — BergamiBagozzi2000","text":"Survey among South Korean employees conducted reported Bergami Bagozzi (2000) .","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/BergamiBagozzi2000.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Data: BergamiBagozzi2000 — BergamiBagozzi2000","text":"dataset contains 22 variables originates larger survey among South Korean employees conducted reported Bergami Bagozzi (2000) . also used  Hwang Takane (2004)  Henseler (2021)  demonstration purposes, see corresponding tutorial.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/BergamiBagozzi2000.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Data: BergamiBagozzi2000 — BergamiBagozzi2000","text":"Bergami M, Bagozzi RP (2000). “Self-categorization, affective commitment group self-esteem distinct aspects social identity organization.” British Journal Social Psychology, 39(4), 555–577. doi:10.1348/014466600164633 . Henseler J (2021). Composite-Based Structural Equation Modeling: Analyzing Latent Emergent Variables. Guilford Press, New York. Hwang H, Takane Y (2004). “Generalized Structured Component Analysis.” Psychometrika, 69(1), 81–99.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/BergamiBagozzi2000.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Data: BergamiBagozzi2000 — BergamiBagozzi2000","text":"","code":"#============================================================================ # Example is taken from Henseler (2021) #============================================================================ model_Bergami_Bagozzi_Henseler=\" # Measurement models OrgPres =~ cei1 + cei2 + cei3 + cei4 + cei5 + cei6 + cei7 + cei8  OrgIden =~ ma1 + ma2 + ma3 + ma4 + ma5 + ma6 AffLove =~ orgcmt1 + orgcmt2 + orgcmt3 + orgcmt7 AffJoy  =~ orgcmt5 + orgcmt8 Gender  <~ gender  # Structural model  OrgIden ~ OrgPres AffLove ~ OrgPres + OrgIden + Gender  AffJoy  ~ OrgPres + OrgIden + Gender  \"  out <- csem(.data = BergamiBagozzi2000,              .model = model_Bergami_Bagozzi_Henseler,             .PLS_weight_scheme_inner = 'factorial',             .tolerance = 1e-06 )  #============================================================================ # Example is taken from Hwang et al. (2004) #============================================================================   model_Bergami_Bagozzi_Hwang=\" # Measurement models OrgPres =~ cei1 + cei2 + cei3 + cei4 + cei5 + cei6 + cei7 + cei8  OrgIden =~ ma1 + ma2 + ma3 + ma4 + ma5 + ma6 AffJoy =~ orgcmt1 + orgcmt2 + orgcmt3 + orgcmt7 AffLove  =~ orgcmt5 + orgcmt6 + orgcmt8  # Structural model  OrgIden ~ OrgPres  AffLove ~ OrgIden AffJoy  ~ OrgIden\"  out_Hwang <- csem(.data = BergamiBagozzi2000,                   .model = model_Bergami_Bagozzi_Hwang,                  .approach_weights = \"GSCA\",                  .disattenuate = FALSE,                  .id = \"gender\",                  .tolerance = 1e-06)"},{"path":"https://floschuberth.github.io/cSEM/reference/ITFlex.html","id":null,"dir":"Reference","previous_headings":"","what":"Data: ITFlex — ITFlex","title":"Data: ITFlex — ITFlex","text":"data frame containing 16 variables 100 observations.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/ITFlex.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Data: ITFlex — ITFlex","text":"","code":"ITFlex"},{"path":"https://floschuberth.github.io/cSEM/reference/ITFlex.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Data: ITFlex — ITFlex","text":"data frame containing following variables: ITCOMP1 Software applications can easily transported used across multiple platforms. ITCOMP2 firm provides multiple interfaces entry points (e.g., web access) external end users. ITCOMP3 firm establishes corporate rules standards hardware operating systems ensure platform compatibility. ITCOMP4 Data captured one part organization immediately available everyone firm. ITCONN1 organization electronic links connections throughout entire firm. ITCONN2 firm linked business partners electronic channels (e.g., websites, e-mail, wireless devices, electronic data interchange). ITCONN3 remote, branch, mobile offices connected central office. ITCONN4 identifiable communications bottlenecks within firm. MOD1 firm possesses great speed developing new business applications modifying existing applications. MOD2 corporate database able communicate several different protocols. MOD3 Reusable software modules widely used new systems development. MOD4 personnel use object-oriented prepackaged modular tools create software applications. ITPSF1 personnel ability work effectively cross-functional teams. ITPSF2 personnel able interpret business problems develop appropriate technical solutions. ITPSF3 personnel self-directed proactive. ITPSF4 personnel knowledgeable key success factors firm.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/ITFlex.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Data: ITFlex — ITFlex","text":"data collected survey Benitez et al. (2018) .","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/ITFlex.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Data: ITFlex — ITFlex","text":"dataset studied Benitez et al. (2018)  used Henseler (2021)  demonstration purposes, see corresponding tutorial. questionnaire items measured 5-point scale.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/ITFlex.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Data: ITFlex — ITFlex","text":"Benitez J, Ray G, Henseler J (2018). “Impact Information Technology Infrastructure Flexibility Mergers Acquisitions.” MIS Quarterly, 42(1), 25–43. Henseler J (2021). Composite-Based Structural Equation Modeling: Analyzing Latent Emergent Variables. Guilford Press, New York.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/ITFlex.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Data: ITFlex — ITFlex","text":"","code":"#============================================================================ # Example is taken from Henseler (2020) #============================================================================ model_IT_Fex=\" # Composite models ITComp  <~ ITCOMP1 + ITCOMP2 + ITCOMP3 + ITCOMP4 Modul   <~ MOD1 + MOD2 + MOD3 + MOD4 ITConn  <~ ITCONN1 + ITCONN2 + ITCONN3 + ITCONN4 ITPers  <~ ITPSF1 + ITPSF2 + ITPSF3 + ITPSF4  # Saturated structural model ITPers ~ ITComp + Modul + ITConn Modul  ~ ITComp + ITConn  ITConn ~ ITComp  \"  out <- csem(.data = ITFlex, .model = model_IT_Fex,            .PLS_weight_scheme_inner = 'factorial',            .tolerance = 1e-06,            .PLS_ignore_structural_model = TRUE)"},{"path":"https://floschuberth.github.io/cSEM/reference/LancelotMiltgenetal2016.html","id":null,"dir":"Reference","previous_headings":"","what":"Data: LancelotMiltgenetal2016 — LancelotMiltgenetal2016","title":"Data: LancelotMiltgenetal2016 — LancelotMiltgenetal2016","text":"data frame containing 10 variables 1090 observations.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/LancelotMiltgenetal2016.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Data: LancelotMiltgenetal2016 — LancelotMiltgenetal2016","text":"","code":"LancelotMiltgenetal2016"},{"path":"https://floschuberth.github.io/cSEM/reference/LancelotMiltgenetal2016.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Data: LancelotMiltgenetal2016 — LancelotMiltgenetal2016","text":"object class data.frame 1090 rows 11 columns.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/LancelotMiltgenetal2016.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Data: LancelotMiltgenetal2016 — LancelotMiltgenetal2016","text":"data collected cooperation European Commission Joint Research Center Institute Prospective Technological Studies, contract “Young People Emerging Digital Services: Exploratory Survey Motivations, Perceptions, Acceptance Risk” (EC JRC Contract IPTS : 150876-2007 F1ED-FR).","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/LancelotMiltgenetal2016.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Data: LancelotMiltgenetal2016 — LancelotMiltgenetal2016","text":"data analysed Lancelot-Miltgen et al. (2016)  study young consumers’ adoption intentions location tracker technology light privacy concerns. also used Henseler (2021)  demonstration purposes, see corresponding tutorial.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/LancelotMiltgenetal2016.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Data: LancelotMiltgenetal2016 — LancelotMiltgenetal2016","text":"Henseler J (2021). Composite-Based Structural Equation Modeling: Analyzing Latent Emergent Variables. Guilford Press, New York. Lancelot-Miltgen C, Henseler J, Gelhard C, Popovic (2016). “Introducing new products affect consumer privacy: mediation model.” Journal Business Research, 69(10), 4659–4666. doi:10.1016/j.jbusres.2016.04.015 .","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/LancelotMiltgenetal2016.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Data: LancelotMiltgenetal2016 — LancelotMiltgenetal2016","text":"","code":"#============================================================================ # Example is taken from Henseler (2020) #============================================================================ model_Med <- \" # Reflective measurement model Trust =~ trust1 + trust2 PrCon =~ privcon1 + privcon2 + privcon3 + privcon4 Risk  =~ risk1 + risk2 + risk3 Int   =~ intent1 + intent2  # Structural model Int   ~ Trust + PrCon + Risk Risk  ~ Trust + PrCon Trust ~ PrCon \"  out <- csem(.data = LancelotMiltgenetal2016, .model = model_Med,             .PLS_weight_scheme_inner = 'factorial',             .tolerance = 1e-06 )"},{"path":"https://floschuberth.github.io/cSEM/reference/PoliticalDemocracy.html","id":null,"dir":"Reference","previous_headings":"","what":"Data: political democracy — PoliticalDemocracy","title":"Data: political democracy — PoliticalDemocracy","text":"Industrialization Political Democracy dataset. dataset used throughout Bollen's 1989 book (see pages 12, 17, 36 chapter 2, pages 228 following chapter 7, pages 321 following chapter 8; Bollen (1989) ). dataset contains various measures political democracy industrialization developing countries.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/PoliticalDemocracy.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Data: political democracy — PoliticalDemocracy","text":"","code":"PoliticalDemocracy"},{"path":"https://floschuberth.github.io/cSEM/reference/PoliticalDemocracy.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Data: political democracy — PoliticalDemocracy","text":"data frame 75 observations 11 variables. y1 Expert ratings freedom press 1960 y2 freedom political opposition 1960 y3 fairness elections 1960 y4 effectiveness elected legislature 1960 y5 Expert ratings freedom press 1965 y6 freedom political opposition 1965 y7 fairness elections 1965 y8 effectiveness elected legislature 1965 x1 gross national product (GNP) per capita 1960 x2 inanimate energy consumption per capita 1960 x3 percentage labor force industry 1960","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/PoliticalDemocracy.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Data: political democracy — PoliticalDemocracy","text":"lavaan package (version 0.6-3).","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/PoliticalDemocracy.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Data: political democracy — PoliticalDemocracy","text":"Bollen KA (1989). Structural Equations Latent Variables. Wiley-Interscience. ISBN 978-0471011712.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/PoliticalDemocracy.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Data: political democracy — PoliticalDemocracy","text":"","code":"#============================================================================ # Example is taken from the lavaan website #============================================================================ # Note: example is modified. Across-block correlations are removed model <- \" # Measurement model   ind60 =~ x1 + x2 + x3   dem60 =~ y1 + y2 + y3 + y4   dem65 =~ y5 + y6 + y7 + y8    # Regressions / Path model   dem60 ~ ind60   dem65 ~ ind60 + dem60    # residual correlations   y2 ~~ y4   y6 ~~ y8 \"  aa <- csem(PoliticalDemocracy, model)"},{"path":"https://floschuberth.github.io/cSEM/reference/Russett.html","id":null,"dir":"Reference","previous_headings":"","what":"Data: Russett — Russett","title":"Data: Russett — Russett","text":"data frame containing 10 variables 47 observations.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/Russett.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Data: Russett — Russett","text":"","code":"Russett"},{"path":"https://floschuberth.github.io/cSEM/reference/Russett.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Data: Russett — Russett","text":"data frame containing following variables 47 countries: gini Gini index concentration farm percentage landholders collectively occupy one-half agricultural land (starting farmers smallest plots land working toward largest) rent percentage total number farms rent land. Transformation: ln (x + 1) gnpr 1955 gross national product per capita U.S. dollars. Transformation: ln (x) labo percentage labor force employed agriculture. Transformation: ln (x) inst Instability personnel based term office chief executive. Transformation: exp (x - 16.3) ecks total number politically motivated violent incidents, plots protracted guerrilla warfare. Transformation: ln (x + 1) deat number people killed result internal group violence per 1,000,000 people. Transformation: ln (x + 1) stab One country stable democracy, zero otherwise dict One country experiences dictatorship, zero otherwise","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/Russett.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Data: Russett — Russett","text":": Henseler (2021)","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/Russett.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Data: Russett — Russett","text":"dataset initially compiled Russett (1964) , discussed reprinted Gifi (1990) , partially transformed Tenenhaus Tenenhaus (2011) . also used Henseler (2021)  demonstration purposes.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/Russett.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Data: Russett — Russett","text":"Gifi (1990). Nonlinear multivariate analysis. Wiley. Henseler J (2021). Composite-Based Structural Equation Modeling: Analyzing Latent Emergent Variables. Guilford Press, New York. Russett BM (1964). “Inequality Instability: Relation Land Tenure Politics.” World Politics, 16(3), 442–454. doi:10.2307/2009581 . Tenenhaus , Tenenhaus M (2011). “Regularized generalized canonical correlation analysis.” Psychometrika, 76(2), 257–284.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/Russett.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Data: Russett — Russett","text":"","code":"#============================================================================ # Example is taken from Henseler (2020) #============================================================================ model_Russett=\" # Composite model AgrIneq <~ gini + farm + rent IndDev  <~ gnpr + labo PolInst <~ inst + ecks + deat + stab + dict  # Structural model PolInst ~ AgrIneq + IndDev \"  out <- csem(.data = Russett, .model = model_Russett,             .PLS_weight_scheme_inner = 'factorial',             .tolerance = 1e-06 )"},{"path":"https://floschuberth.github.io/cSEM/reference/SQ.html","id":null,"dir":"Reference","previous_headings":"","what":"Data: SQ — SQ","title":"Data: SQ — SQ","text":"data frame containing 23 variables 411 observations. original indicators measured 6-point scale. version dataset, indicators scaled 0 100.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/SQ.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Data: SQ — SQ","text":"","code":"SQ"},{"path":"https://floschuberth.github.io/cSEM/reference/SQ.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Data: SQ — SQ","text":"object class data.frame 411 rows 23 columns.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/SQ.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Data: SQ — SQ","text":"dataset provided Jörg Henseler.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/SQ.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Data: SQ — SQ","text":"data comes European manufacturer durable consumer goods studied Bliemel et al. (2004)  focused service quality. also used Henseler (2021)  demonstration purposes, see corresponding tutorial.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/SQ.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Data: SQ — SQ","text":"Bliemel FW, Adolphs K, Henseler J (2004). “Reconceptualizing service quality. formative measurement approach using PLS path modeling.” Munuera-Aleman JL (ed.), Proceedings 33rd EMAC Conference, 224. Henseler J (2021). Composite-Based Structural Equation Modeling: Analyzing Latent Emergent Variables. Guilford Press, New York.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/Sigma_Summers_composites.html","id":null,"dir":"Reference","previous_headings":"","what":"Data: Summers — Sigma_Summers_composites","title":"Data: Summers — Sigma_Summers_composites","text":"(18 x 18) indicator correlation matrix.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/Sigma_Summers_composites.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Data: Summers — Sigma_Summers_composites","text":"","code":"Sigma_Summers_composites"},{"path":"https://floschuberth.github.io/cSEM/reference/Sigma_Summers_composites.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Data: Summers — Sigma_Summers_composites","text":"object class matrix (inherits array) 18 rows 18 columns.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/Sigma_Summers_composites.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Data: Summers — Sigma_Summers_composites","text":"calculation based Dijkstra Henseler (2015) .","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/Sigma_Summers_composites.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Data: Summers — Sigma_Summers_composites","text":"indicator correlation matrix modified version Summers (1965)  model. constructs modeled composites.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/Sigma_Summers_composites.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Data: Summers — Sigma_Summers_composites","text":"Dijkstra TK, Henseler J (2015). “Consistent Asymptotically Normal PLS Estimators Linear Structural Equations.” Computational Statistics & Data Analysis, 81, 10–23. Summers R (1965). “Capital Intensive Approach Small Sample Properties Various Simultaneous Equation Estimators.” Econometrica, 33(1), 1–41.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/Sigma_Summers_composites.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Data: Summers — Sigma_Summers_composites","text":"","code":"require(cSEM)  model <- \" ETA1 ~ ETA2 + XI1 + XI2 ETA2 ~ ETA1 + XI3 +XI4  ETA1 ~~ ETA2  XI1  <~ x1 + x2 + x3 XI2  <~ x4 + x5 + x6 XI3  <~ x7 + x8 + x9 XI4  <~ x10 + x11 + x12 ETA1 <~ y1 + y2 + y3 ETA2 <~ y4 + y5 + y6 \"  ## Generate data summers_dat <- MASS::mvrnorm(n = 300, mu = rep(0, 18),                               Sigma = Sigma_Summers_composites, empirical = TRUE)  ## Estimate res <- csem(.data = summers_dat, .model = model) # inconsistent  ##  # 2SLS res_2SLS <- csem(.data = summers_dat, .model = model, .approach_paths = \"2SLS\",                  .instruments = list(ETA1 = c('XI1', 'XI2', 'XI3', 'XI4'),                                      ETA2 = c('XI1', 'XI2', 'XI3', 'XI4')) )"},{"path":"https://floschuberth.github.io/cSEM/reference/Switching.html","id":null,"dir":"Reference","previous_headings":"","what":"Data: Switching — Switching","title":"Data: Switching — Switching","text":"data frame containing 26 variables 767 observations.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/Switching.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Data: Switching — Switching","text":"","code":"Switching"},{"path":"https://floschuberth.github.io/cSEM/reference/Switching.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Data: Switching — Switching","text":"object class data.frame 767 rows 26 columns.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/Switching.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Data: Switching — Switching","text":"dataset provided Jörg Henseler.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/Switching.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Data: Switching — Switching","text":"data contains variables consumers’ intention switch service provider. also used Henseler (2021)  demonstration purposes, see corresponding tutorial.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/Switching.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Data: Switching — Switching","text":"Henseler J (2021). Composite-Based Structural Equation Modeling: Analyzing Latent Emergent Variables. Guilford Press, New York.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/Switching.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Data: Switching — Switching","text":"","code":"#============================================================================ # Example is taken from Henseler (2021) #============================================================================ model_Int <-\" # Measurement models INV =~ INV1 + INV2 + INV3 +INV4 SAT =~ SAT1 + SAT2 + SAT3 INT =~ INT1 + INT2  # Structural model containing an interaction term. INT ~ INV + SAT + INV.SAT \"  out <- csem(.data = Switching, .model = model_Int,             .PLS_weight_scheme_inner = 'factorial',             .tolerance = 1e-06)"},{"path":"https://floschuberth.github.io/cSEM/reference/Yooetal2000.html","id":null,"dir":"Reference","previous_headings":"","what":"Data: Yooetal2000 — Yooetal2000","title":"Data: Yooetal2000 — Yooetal2000","text":"data frame containing 34 variables 569 observations.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/Yooetal2000.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Data: Yooetal2000 — Yooetal2000","text":"","code":"Yooetal2000"},{"path":"https://floschuberth.github.io/cSEM/reference/Yooetal2000.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Data: Yooetal2000 — Yooetal2000","text":"object class data.frame 569 rows 34 columns.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/Yooetal2000.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Data: Yooetal2000 — Yooetal2000","text":"Simulated data correlation matrix data studied Yoo et al. (2000) .","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/Yooetal2000.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Data: Yooetal2000 — Yooetal2000","text":"data simulated identical correlation matrix data analysed Yoo et al. (2000)  examine five elements marketing mix, namely price, store image, distribution intensity, advertising spending, price deals, related -called dimensions brand equity, .e., perceived brand quality, brand loyalty, brand awareness/associations. also used Henseler (2017)  Henseler (2021)  demonstration purposes, see corresponding tutorial.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/Yooetal2000.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Data: Yooetal2000 — Yooetal2000","text":"Henseler J (2017). “Bridging Design Behavioral Research Variance-Based Structural Equation Modeling.” Journal Advertising, 46(1), 178–192. doi:10.1080/00913367.2017.1281780 . Henseler J (2021). Composite-Based Structural Equation Modeling: Analyzing Latent Emergent Variables. Guilford Press, New York. Yoo B, Donthu N, Lee S (2000). “Examination Selected Marketing Mix Elements Brand Equity.” Journal Academy Marketing Science, 28(2), 195–211. doi:10.1177/0092070300282002 .","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/Yooetal2000.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Data: Yooetal2000 — Yooetal2000","text":"","code":"#============================================================================ # Example is taken from Henseler (2021) #============================================================================ model_HOC=\" # Measurement models FOC PR =~ PR1 + PR2 + PR3 IM =~ IM1 + IM2 + IM3 DI =~ DI1 + DI2 + DI3 AD =~ AD1 + AD2 + AD3 DL =~ DL1 + DL2 + DL3 AA =~ AA1 + AA2 + AA3 + AA4 + AA5 + AA6 LO =~ LO1 + LO3 QL =~ QL1 + QL2 + QL3 + QL4 + QL5 + QL6  # Composite model for SOC BR <~ QL + LO + AA  # Structural model BR~ PR + IM + DI + AD + DL  \"  out <- csem(.data = Yooetal2000, .model = model_HOC,             .PLS_weight_scheme_inner = 'factorial',             .tolerance = 1e-06)"},{"path":"https://floschuberth.github.io/cSEM/reference/adjustAlpha.html","id":null,"dir":"Reference","previous_headings":"","what":"Internal: Multiple testing correction — adjustAlpha","title":"Internal: Multiple testing correction — adjustAlpha","text":"Adjust given significance level .alpha accommodate multiple testing. following corrections implemented: none (Default) correction done. bonferroni Bonferroni correction done, .e., alpha divided number comparisons .nr_comparisons.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/adjustAlpha.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Internal: Multiple testing correction — adjustAlpha","text":"","code":"adjustAlpha(  .alpha                 = args_default()$.alpha,  .approach_alpha_adjust = args_default()$.approach_alpha_adjust,  .nr_comparisons        = args_default()$.nr_comparisons )"},{"path":"https://floschuberth.github.io/cSEM/reference/adjustAlpha.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Internal: Multiple testing correction — adjustAlpha","text":".alpha integer numeric vector significance levels. Defaults 0.05. .approach_alpha_adjust Character string. Approach used adjust significance level accommodate multiple testing. One \"none\" \"bonferroni\". Defaults \"none\". .nr_comparisons Integer. number comparisons. Defaults NULL.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/adjustAlpha.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Internal: Multiple testing correction — adjustAlpha","text":"vector (possibly adjusted) significance levels.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/args_assess_dotdotdot.html","id":null,"dir":"Reference","previous_headings":"","what":"Complete list of assess()'s ... arguments — args_assess_dotdotdot","title":"Complete list of assess()'s ... arguments — args_assess_dotdotdot","text":"complete alphabetical list possible arguments accepted assess()'s ... (dotdotdot) argument.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/args_assess_dotdotdot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Complete list of assess()'s ... arguments — args_assess_dotdotdot","text":".absolute Logical. absolute HTMT values returned? Defaults TRUE . .alpha integer numeric vector significance levels. Defaults 0.05. .ci vector character strings naming confidence interval compute. possible choices see infer(). .closed_form_ci Logical. closed-form confidence interval computed? Defaults FALSE. .handle_inadmissibles Character string. inadmissible results treated? One \"drop\", \"ignore\", \"replace\". \"drop\", replications/resamples yielding inadmissible result dropped (.e. number results returned potentially less .R). \"ignore\" results returned even replications yielded inadmissible results (.e. number results returned equal .R). \"replace\" resampling continues exactly .R admissible solutions. Depending frequency inadmissible solutions may significantly increase computing time. Defaults \"drop\". .inference Logical. critical values computed? Defaults FALSE. .null_model Logical. degrees freedom null model computed? Defaults FALSE. .R Integer. number bootstrap replications. Defaults 499. .saturated Logical. saturated structural model used? Defaults FALSE. .seed Integer NULL. random seed use. Defaults NULL case arbitrary seed chosen. Note scope seed limited body function used . Hence, global seed altered! .type_gfi Character string. fitting function GFI based ? One \"ML\" maximum likelihood fitting function, \"GLS\" generalized least squares fitting function \"ULS\" unweighted least squares fitting function (squared Euclidean distance). Defaults \"ML\". .type_vcv Character string. model-implied correlation matrix calculated? One \"indicator\" \"construct\". Defaults \"indicator\".","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/args_assess_dotdotdot.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Complete list of assess()'s ... arguments — args_assess_dotdotdot","text":"arguments supplied ... argument assess() accepted subset functions called assess(). following list shows argument passed function: .absolute Accepted /Passed : calculateHTMT() .alpha Accepted /Passed : calculateRhoT(), calculateHTMT(), calculateCN() .ci Accepted /Passed : calculateHTMT() .closed_form_ci Accepted /Passed : calculateRhoT() .handle_inadmissibles Accepted /Passed : calculateHTMT() .inference Accepted /Passed : calculateHTMT .null_model Accepted /Passed : calculateDf() .R Accepted /Passed : calculateHTMT() .saturated Accepted /Passed : calculateSRMR(), calculateDG(), calculateDL(), calculateDML()subsequently fit(). .seed Accepted /Passed : calculateHTMT() .type_gfi Accepted /Passed : calculateGFI() .type_vcv Accepted /Passed : calculateSRMR(), calculateDG(), calculateDL(), calculateDML() subsequently fit().","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/args_default.html","id":null,"dir":"Reference","previous_headings":"","what":"Show argument defaults or candidates — args_default","title":"Show argument defaults or candidates — args_default","text":"Show arguments used package functions including default candidate values. argument descriptions see: csem_arguments.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/args_default.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Show argument defaults or candidates — args_default","text":"","code":"args_default(.choices = FALSE)"},{"path":"https://floschuberth.github.io/cSEM/reference/args_default.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Show argument defaults or candidates — args_default","text":".choices Logical. candidate values arguments returned? Defaults FALSE.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/args_default.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Show argument defaults or candidates — args_default","text":"named list argument names defaults accepted candidates.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/args_default.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Show argument defaults or candidates — args_default","text":"default args_default()returns list default values argument name. list accepted candidate values required instead, use .choices = TRUE.","code":""},{"path":[]},{"path":[]},{"path":"https://floschuberth.github.io/cSEM/reference/assess.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Assess model — assess","text":"","code":"assess(   .object              = NULL,    .quality_criterion   = c(\"all\", \"aic\", \"aicc\", \"aicu\", \"bic\", \"fpe\", \"gm\", \"hq\",                            \"hqc\", \"mallows_cp\", \"ave\",                            \"rho_C\", \"rho_C_mm\", \"rho_C_weighted\",                             \"rho_C_weighted_mm\", \"dg\", \"dl\", \"dml\", \"df\",                            \"effects\", \"f2\", \"fl_criterion\", \"chi_square\", \"chi_square_df\",                            \"cfi\", \"cn\", \"gfi\", \"ifi\", \"nfi\", \"nnfi\",                             \"reliability\",                            \"rmsea\", \"rms_theta\", \"srmr\",                            \"gof\", \"htmt\", \"htmt2\", \"r2\", \"r2_adj\",                            \"rho_T\", \"rho_T_weighted\", \"vif\",                             \"vifmodeB\"),   .only_common_factors = TRUE,    ... )"},{"path":"https://floschuberth.github.io/cSEM/reference/assess.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Assess model — assess","text":".object R object class cSEMResults resulting call csem(). .quality_criterion Character string. single character string vector character strings naming quality criterion compute. See Details section list possible candidates. Defaults \"\" case possible quality criteria computed. .only_common_factors Logical. concepts modeled common factors included calculating one following quality criteria: AVE, Fornell-Larcker criterion, HTMT, reliability estimates. Defaults TRUE. ... arguments passed functions called assess(). See args_assess_dotdotdot complete list available arguments.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/assess.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Assess model — assess","text":"named list quality criteria. Note single quality criteria computed return value still list!","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/assess.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Assess model — assess","text":"Assess model using common quality criteria. See Postestimation: Assessing model article cSEM website details. function essentially wrapper around number internal functions perform \"assessment task\" (called quality criterion cSEM parlance) like computing reliability estimates, effect size (Cohen's f^2), heterotrait-monotrait ratio correlations (HTMT) etc. default every possible quality criterion calculated (.quality_criterion = \"\"). subset quality criteria needed single character string vector character strings naming criteria computed may supplied assess() via .quality_criterion argument. Currently, following quality criteria implemented (alphabetical order): Average variance extracted (AVE); \"ave\" estimate amount variation indicators due underlying latent variable. Practically, calculated ratio (indicator) true score variances (.e., sum squared loadings) relative sum total indicator variances. AVE inherently tied common factor model. therefore unclear meaningfully interpret AVE results constructs modeled composites. possible report AVE constructs modeled composites setting .only_common_factors = FALSE, however, result interpreted caution may conceptual meaning. Calculation done calculateAVE(). Congeneric reliability; \"rho_C\", \"rho_C_mm\", \"rho_C_weighted\", \"rho_C_weighted_mm\" estimate reliability assuming congeneric measurement model (.e., loadings allowed differ) test score (proxy) based unit weights. four different versions implemented. See Methods Formulae section Postestimation: Assessing model article cSEM website details. Alternative synonymous names \"rho_C\" : composite reliability, construct reliability, reliability coefficient, Jöreskog's rho, coefficient omega, Dillon-Goldstein's rho. \"rho_C_weighted\": (Dijkstra-Henselers) rhoA. rho_C_mm rho_C_weighted_mm corresponding names. former uses unit weights scaled (w'Sw)^(-1/2) latter weights scaled (w'Sigma_hat w)^(-1/2) Sigma_hat model-implied indicator correlation matrix. Congeneric reliability inherently tied common factor model. therefore unclear meaningfully interpret congeneric reliability estimates constructs modeled composites. possible report congeneric reliability constructs modeled composites setting .only_common_factors = FALSE, however, result interpreted caution may conceptual meaning. Calculation done calculateRhoC(). Distance measures; \"dg\", \"dl\", \"dml\" Measures distance model-implied empirical indicator correlation matrix. Currently, geodesic distance (\"dg\"), squared Euclidean distance (\"dl\") maximum likelihood-based distance function implemented (\"dml\"). Calculation done calculateDL(), calculateDG(), calculateDML(). Degrees freedom, \"df\" Returns degrees freedom. Calculation done calculateDf(). Effects; \"effects\" Total indirect effect estimates. Additionally, variance accounted (VAF) computed. VAF defined ratio variables indirect effect total effect. Calculation done calculateEffects(). Effect size; \"f2\" index effect size independent variable structural regression equation. measure commonly known Cohen's f^2. effect size k'th independent variable case defined ratio (R2_included - R2_excluded)/(1 - R2_included), R2_included R2_excluded R squares original structural model regression equation (R2_included) alternative specification k'th variable dropped (R2_excluded). Calculation done calculatef2(). Fit indices; \"chi_square\", \"chi_square_df\", \"cfi\", \"cn\", \"gfi\", \"ifi\", \"nfi\", \"nnfi\",  \"rmsea\", \"rms_theta\", \"srmr\" Several absolute incremental fit indices. Note suitability models containing constructs modeled composites still open research question. Also note fit indices tests hypothesis testing sense decisions based common one-size-fits-cut-offs proposed literature suffer serious statistical drawbacks. Calculation done calculateChiSquare(), calculateChiSquareDf(), calculateCFI(), calculateGFI(), calculateIFI(), calculateNFI(), calculateNNFI(), calculateRMSEA(), calculateRMSTheta() calculateSRMR(). Fornell-Larcker criterion; \"fl_criterion\" rule suggested Fornell Larcker (1981)  assess discriminant validity. Fornell-Larcker criterion decision rule based comparison squared construct correlations average variance extracted. FL returns matrix squared construct correlations -diagonal AVEs main diagonal. Calculation done calculateFLCriterion(). Goodness Fit (GoF); \"gof\" GoF defined square root mean R squares structural model times mean variances indicators explained related constructs (.e., average lambda^2_k). latter, constructs modeled common factors considered explain indicator variance contrast composite indicators actually build construct. Note , contrary name suggests, GoF measure model fit Chi-square fit test sense. Calculation done calculateGoF(). Heterotrait-monotrait ratio correlations (HTMT); \"htmt\" estimate correlation latent variables assuming tau equivalent measurement models. HTMT used assess convergent /discriminant validity construct. HTMT inherently tied common factor model. model contains less two constructs modeled common factors .only_common_factors = TRUE, NA returned. possible report HTMT constructs modeled composites setting .only_common_factors = FALSE, however, result interpreted caution may conceptual meaning. Calculation done calculateHTMT(). HTMT2; \"htmt2\" estimate correlation latent variables assuming congeneric measurement models. HTMT2 used assess convergent /discriminant validity construct. HTMT inherently tied common factor model. model contains less two constructs modeled common factors .only_common_factors = TRUE, NA returned. possible report HTMT constructs modeled composites setting .only_common_factors = FALSE, however, result interpreted caution may conceptual meaning. Calculation done calculateHTMT(). Model selection criteria: \"aic\", \"aicc\", \"aicu\", \"bic\", \"fpe\", \"gm\", \"hq\", \"hqc\", \"mallows_cp\" Several model selection criteria suggested Sharma et al. (2019)  context PLS. See: calculateModelSelectionCriteria() details. Reliability: \"reliability\" described Methods Formulae section Postestimation: Assessing model article cSEM website many different estimators (internal consistency) reliability. Choosing .quality_criterion = \"reliability\" computes three common measures, namely: \"Cronbach's alpha\" (identical \"rho_T\"), \"Jöreskog's rho\" (identical \"rho_C_mm\"), \"Dijkstra-Henseler's rho \" (identical \"rho_C_weighted_mm\"). Reliability inherently tied common factor model. therefore unclear meaningfully interpret reliability estimates constructs modeled composites. possible report three common reliability estimates constructs modeled composites setting .only_common_factors = FALSE, however, result interpreted caution may conceptual meaning. R square R square adjusted; \"r2\", \"r2_adj\" R square adjusted R square structural regression equation. Calculated running csem(). Tau-equivalent reliability; \"rho_T\" estimate reliability assuming tau-equivalent measurement model (.e. measurement model equal loadings) test score (proxy) based unit weights. Tau-equivalent reliability preferred name reliability estimates assume tau-equivalent measurement model Cronbach's alpha. tau-equivalent reliability (Cronbach's alpha) inherently tied common factor model. therefore unclear meaningfully interpret tau-equivalent reliability estimates constructs modeled composites. possible report tau-equivalent reliability estimates constructs modeled composites setting .only_common_factors = FALSE, however, result interpreted caution may conceptual meaning. Calculation done calculateRhoT(). Variance inflation factors (VIF); \"vif\" index amount (multi-)collinearity independent variables regression equation. Computed structural equation. Practically, VIF_k defined ratio 1 (1 - R2_k) R2_k R squared regression k'th independent variable remaining independent variables. Calculated running csem(). Variance inflation factors PLS-PM mode B (VIF-ModeB); \"vifmodeB\" index amount (multi-)collinearity independent variables (indicators) mode B regression equations. Computed .object obtained using .weight_approach = \"PLS-PM\" least one mode mode B. Practically, VIF-ModeB_k defined ratio 1 (1 - R2_k) R2_k R squared regression k'th indicator block j remaining indicators block. Calculation done calculateVIFModeB(). details important quality criteria see Methods Formulae section Postestimation: Assessing model article cSEM website. quality criteria inherently tied classical common factor model therefore meaningfully interpreted within common factor model (see Postestimation: Assessing model article details). possible force computation quality criteria constructs modeled composites setting .only_common_factors = FALSE, however, explicitly warn interpret quality criteria analogy common factor model case, interpretation often carry composite models.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/assess.html","id":"resampling","dir":"Reference","previous_headings":"","what":"Resampling","title":"Assess model — assess","text":"resample given quality criterion supply name function calculates desired quality criterion csem()'s .user_funs argument. See resamplecSEMResults() details.","code":""},{"path":[]},{"path":"https://floschuberth.github.io/cSEM/reference/assess.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Assess model — assess","text":"","code":"# =========================================================================== # Using the three common factors dataset # =========================================================================== model <- \" # Structural model eta2 ~ eta1 eta3 ~ eta1 + eta2  # Each concept is measured by 3 indicators, i.e., modeled as latent variable eta1 =~ y11 + y12 + y13 eta2 =~ y21 + y22 + y23 eta3 =~ y31 + y32 + y33 \"  res <- csem(threecommonfactors, model) a   <- assess(res) # computes all quality criteria (.quality_criterion = \"all\") a #> ________________________________________________________________________________ #>  #> \tConstruct        AVE           R2          R2_adj     #> \teta1           0.4803          NA            NA       #> \teta2           0.4923        0.4507        0.4496     #> \teta3           0.5559        0.4912        0.4892     #>  #> -------------- Common (internal consistency) reliability estimates ------------- #>  #> \tConstruct Cronbachs_alpha   Joereskogs_rho   Dijkstra-Henselers_rho_A  #> \teta1        0.7318           0.7339                0.7388           #> \teta2        0.7281           0.7380                0.7647           #> \teta3        0.7860           0.7884                0.7964           #>  #> ----------- Alternative (internal consistency) reliability estimates ----------- #>  #> \tConstruct       RhoC         RhoC_mm    RhoC_weighted #> \teta1           0.7339        0.7341        0.7388     #> \teta2           0.7380        0.7361        0.7647     #> \teta3           0.7884        0.7875        0.7964     #>  #> \tConstruct  RhoC_weighted_mm     RhoT      RhoT_weighted #> \teta1           0.7388        0.7318        0.7288     #> \teta2           0.7647        0.7281        0.7095     #> \teta3           0.7964        0.7860        0.7820     #>  #> --------------------------- Distance and fit measures -------------------------- #>  #> \tGeodesic distance             = 0.006013595 #> \tSquared Euclidean distance    = 0.01121567 #> \tML distance                   = 0.03203348 #>  #> \tChi_square       = 15.9847 #> \tChi_square_df    = 0.6660294 #> \tCFI              = 1 #> \tCN               = 1137.78 #> \tGFI              = 0.9920803 #> \tIFI              = 1.005614 #> \tNFI              = 0.9889886 #> \tNNFI             = 1 #> \tRMSEA            = 0 #> \tRMS_theta        = 0.1050618 #> \tSRMR             = 0.01578725 #>  #> \tDegrees of freedom       = 24 #>  #> --------------------------- Model selection criteria --------------------------- #>  #> \tConstruct        AIC          AICc          AICu      #> \teta2          -296.5459     205.5025      -294.5419   #> \teta3          -332.8544     169.2264      -329.8454   #>  #> \tConstruct        BIC           FPE           GM       #> \teta2          -288.1166      0.5526       511.4292    #> \teta3          -320.2106      0.5139       517.6438    #>  #> \tConstruct        HQ            HQc       Mallows_Cp   #> \teta2          -293.2383     -293.1793      3.0000     #> \teta3          -327.8930     -327.7823      5.0000     #>  #> ----------------------- Variance inflation factors (VIFs) ---------------------- #>  #>   Dependent construct: 'eta3' #>  #> \tIndependent construct    VIF value  #> \teta1                      1.8205    #> \teta2                      1.8205    #>  #> -------------------------- Effect sizes (Cohen's f^2) -------------------------- #>  #>   Dependent construct: 'eta2' #>  #> \tIndependent construct       f^2     #> \teta1                      0.8205    #>  #>   Dependent construct: 'eta3' #>  #> \tIndependent construct       f^2     #> \teta1                      0.2270    #> \teta2                      0.1005    #>  #> ----------------------- Discriminant validity assessment ----------------------- #>  #> \tHeterotrait-monotrait ratio of correlations matrix (HTMT matrix) #>  #>           eta1      eta2 eta3 #> eta1 1.0000000 0.0000000    0 #> eta2 0.6782752 1.0000000    0 #> eta3 0.6668841 0.6124418    1 #>  #>  #> \tAdvanced heterotrait-monotrait ratio of correlations matrix (HTMT2 matrix) #>  #>           eta1      eta2 eta3 #> eta1 1.0000000 0.0000000    0 #> eta2 0.6724003 1.0000000    0 #> eta3 0.6652760 0.5958725    1 #>  #>  #> \tFornell-Larcker matrix #>  #>           eta1      eta2      eta3 #> eta1 0.4802903 0.4506886 0.4400530 #> eta2 0.4506886 0.4922660 0.3757225 #> eta3 0.4400530 0.3757225 0.5559458 #>  #>  #> ------------------------------------ Effects ----------------------------------- #>  #> Estimated total effects: #> ======================== #>   Total effect    Estimate  Std. error   t-stat.   p-value #>   eta2 ~ eta1       0.6713          NA        NA        NA #>   eta3 ~ eta1       0.6634          NA        NA        NA #>   eta3 ~ eta2       0.3052          NA        NA        NA #>  #> Estimated indirect effects: #> =========================== #>   Indirect effect    Estimate  Std. error   t-stat.   p-value #>   eta3 ~ eta1          0.2049          NA        NA        NA #> ________________________________________________________________________________  ## The return value is a named list. Type for example: a$HTMT #> $htmts #>           eta1      eta2 eta3 #> eta1 1.0000000 0.0000000    0 #> eta2 0.6782752 1.0000000    0 #> eta3 0.6668841 0.6124418    1 #>  #> $quantiles #> NULL #>  #> $nr_admissibles #> NULL #>   # You may also just compute a subset of the quality criteria assess(res, .quality_criterion = c(\"ave\", \"rho_C\", \"htmt\")) #> ________________________________________________________________________________ #>  #> \tConstruct        AVE      #> \teta1           0.4803     #> \teta2           0.4923     #> \teta3           0.5559     #>  #> ----------- Alternative (internal consistency) reliability estimates ----------- #>  #> \tConstruct       RhoC      #> \teta1           0.7339     #> \teta2           0.7380     #> \teta3           0.7884     #>  #> ----------------------- Discriminant validity assessment ----------------------- #>  #> \tHeterotrait-monotrait ratio of correlations matrix (HTMT matrix) #>  #>           eta1      eta2 eta3 #> eta1 1.0000000 0.0000000    0 #> eta2 0.6782752 1.0000000    0 #> eta3 0.6668841 0.6124418    1 #>  #> ________________________________________________________________________________  ## Resampling --------------------------------------------------------------- # To resample a given quality criterion use csem()'s .user_funs argument # Note: The output of the quality criterion needs to be a vector or a matrix. #       Matrices will be vectorized columnwise. res <- csem(threecommonfactors, model,              .resample_method = \"bootstrap\",              .R               = 40,             .user_funs       = cSEM:::calculateSRMR )  ## Look at the resamples res$Estimates$Estimates_resample$Estimates1$User_fun$Resampled[1:4, ] #> [1] 0.02438619 0.02707452 0.02523378 0.02534859  ## Use infer() to compute e.g., the 95% percentile confidence interval res_infer <- infer(res, .quantity = \"CI_percentile\")  ## The results are saved under the name \"User_fun\" res_infer$User_fun  #> $CI_percentile #>            [,1] #> 95%L 0.01837867 #> 95%U 0.03392481 #>   ## Several quality criteria can be resampled simultaneously res <- csem(threecommonfactors, model,              .resample_method = \"bootstrap\",             .R               = 40,             .user_funs       = list(               \"SRMR\" = cSEM:::calculateSRMR,               \"RMS_theta\" = cSEM:::calculateRMSTheta             ),             .tolerance = 1e-04 ) res$Estimates$Estimates_resample$Estimates1$SRMR$Resampled[1:4, ] #> [1] 0.03218570 0.03292924 0.02765952 0.02580635 res$Estimates$Estimates_resample$Estimates1$RMS_theta$Resampled[1:4] #> [1] 0.10647892 0.10494791 0.09898391 0.10461084"},{"path":"https://floschuberth.github.io/cSEM/reference/buildDotCode.html","id":null,"dir":"Reference","previous_headings":"","what":"Internal: Build DOT code for the SEM plot, including construct correlations. — buildDotCode","title":"Internal: Build DOT code for the SEM plot, including construct correlations. — buildDotCode","text":"Constructs DOT script SEM path diagram, now including correlations constructs (just exogenous ones). Correctly handles drawing one edge per correlation.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/buildDotCode.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Internal: Build DOT code for the SEM plot, including construct correlations. — buildDotCode","text":"","code":"buildDotCode(   title,   graph_attrs,   constructs,   r2_values,   measurement_edge_fun,   path_coefficients,   path_p_values,   correlations,   plot_significances,   plot_correlations,   plot_structural_model_only,   plot_labels,   is_second_order = FALSE,   model_measurement = NULL,   model_error_cor = NULL,   construct_correlations = NULL,   indicator_correlations = NULL )"},{"path":"https://floschuberth.github.io/cSEM/reference/buildDotCode.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Internal: Build DOT code for the SEM plot, including construct correlations. — buildDotCode","text":"title title plot. graph_attrs Optional graph attributes. constructs vector constructs. r2_values Named vector R2 values. measurement_edge_fun Function generate measurement edge code. path_coefficients Matrix/data frame path coefficients. path_p_values Named vector path p-values. Used construct correlations . correlations List containing correlations (exogenous indicator). plot_significances Logical. Whether display significance levels. plot_correlations Option indicator correlations (\"none\", \"exo\", \"\"). plot_structural_model_only Logical. Whether display structural model. is_second_order Logical. Whether model second-order. model_measurement matrix. measurement matrix. model_error_cor matrix. construct_correlations matrix. construct correlation matrix. indicator_correlations matrix. indicator correlation matrix.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/buildDotCode.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Internal: Build DOT code for the SEM plot, including construct correlations. — buildDotCode","text":"character string containing complete DOT code.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/cSEM-package.html","id":null,"dir":"Reference","previous_headings":"","what":"cSEM: A package for composite-based structural equation modeling — cSEM-package","title":"cSEM: A package for composite-based structural equation modeling — cSEM-package","text":"Estimate, analyze, test, study linear, nonlinear, hierarchical multigroup structural equation models using composite-based approaches procedures including estimation techniques partial least squares path modeling (PLS) derivatives (PLSc, ordPLSc, robustPLSc), generalized structured component analysis (GSCA), generalized structured component analysis uniqueness terms (GSCAm), generalized canonical correlation analysis (GCCA) unit weights (sum score) fixed weights, well several tests typical postestimation procedures (e.g., assess model fit, compute direct, indirect total effects).","code":""},{"path":[]},{"path":"https://floschuberth.github.io/cSEM/reference/cSEM-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"cSEM: A package for composite-based structural equation modeling — cSEM-package","text":"Maintainer: Florian Schuberth f.schuberth@utwente.nl (ORCID) Authors: Manuel E. Rademaker manuel-rademaker@outlook.de (ORCID) contributors: Tamara Schamberger tamara.schamberger@uni-wuerzburg.de (ORCID) [contributor] Michael Klesel (ORCID) [contributor] Huu Phuc Nguyen (ORCID) [contributor] Theo K. Dijkstra [contributor] Jörg Henseler (ORCID) [contributor]","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/calculate2ndStage.html","id":null,"dir":"Reference","previous_headings":"","what":"Internal: Second/Third stage of the two-stage approach for second order constructs — calculate2ndStage","title":"Internal: Second/Third stage of the two-stage approach for second order constructs — calculate2ndStage","text":"Performs second third stage model containing second order constructs.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/calculate2ndStage.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Internal: Second/Third stage of the two-stage approach for second order constructs — calculate2ndStage","text":"","code":"calculate2ndStage(  .csem_model          = args_default()$.csem_model,  .first_stage_results = args_default()$.first_stage_results,  .original_arguments  = args_default()$.original_arguments,  .approach_2ndorder   = args_default()$.approach_2ndorder   )"},{"path":"https://floschuberth.github.io/cSEM/reference/calculate2ndStage.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Internal: Second/Third stage of the two-stage approach for second order constructs — calculate2ndStage","text":".csem_model (possibly incomplete) cSEMModel-list. .original_arguments list arguments used within csem(). .approach_2ndorder Character string. Approach used models containing second-order constructs. One : \"2stage\", \"mixed\". Defaults \"2stage\".","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/calculate2ndStage.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Internal: Second/Third stage of the two-stage approach for second order constructs — calculate2ndStage","text":"cSEMResults object.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/calculateAVE.html","id":null,"dir":"Reference","previous_headings":"","what":"Average variance extracted (AVE) — calculateAVE","title":"Average variance extracted (AVE) — calculateAVE","text":"Calculate average variance extracted (AVE) proposed Fornell Larcker (1981) . details see cSEM website","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/calculateAVE.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Average variance extracted (AVE) — calculateAVE","text":"","code":"calculateAVE(  .object              = NULL,  .only_common_factors = TRUE )"},{"path":"https://floschuberth.github.io/cSEM/reference/calculateAVE.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Average variance extracted (AVE) — calculateAVE","text":".object R object class cSEMResults resulting call csem(). .only_common_factors Logical. concepts modeled common factors included calculating one following quality criteria: AVE, Fornell-Larcker criterion, HTMT, reliability estimates. Defaults TRUE.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/calculateAVE.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Average variance extracted (AVE) — calculateAVE","text":"named vector numeric values (AVEs). .object list cSEMResults objects, list AVEs returned.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/calculateAVE.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Average variance extracted (AVE) — calculateAVE","text":"AVE inherently tied common factor model. therefore unclear meaningfully interpret AVE context composite model. possible, however, force computation AVE constructs modeled composites setting .only_common_factors = FALSE.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/calculateAVE.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Average variance extracted (AVE) — calculateAVE","text":"Fornell C, Larcker DF (1981). “Evaluating structural equation models unobservable variables measurement error.” Journal Marketing Research, XVIII, 39–50.","code":""},{"path":[]},{"path":"https://floschuberth.github.io/cSEM/reference/calculateCompositeVCV.html","id":null,"dir":"Reference","previous_headings":"","what":"Internal: Calculate composite variance-covariance matrix — calculateCompositeVCV","title":"Internal: Calculate composite variance-covariance matrix — calculateCompositeVCV","text":"Calculate sample variance-covariance (VCV) matrix composites/proxies.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/calculateCompositeVCV.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Internal: Calculate composite variance-covariance matrix — calculateCompositeVCV","text":"","code":"calculateCompositeVCV(  .S  = args_default()$.S,  .W  = args_default()$.W  )"},{"path":"https://floschuberth.github.io/cSEM/reference/calculateCompositeVCV.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Internal: Calculate composite variance-covariance matrix — calculateCompositeVCV","text":".S (K x K) empirical indicator correlation matrix. .W (J x K) matrix weights.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/calculateCompositeVCV.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Internal: Calculate composite variance-covariance matrix — calculateCompositeVCV","text":"(J x J) composite VCV matrix.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/calculateConstructVCV.html","id":null,"dir":"Reference","previous_headings":"","what":"Internal: Calculate construct variance-covariance matrix — calculateConstructVCV","title":"Internal: Calculate construct variance-covariance matrix — calculateConstructVCV","text":"Calculate variance-covariance matrix (VCV) constructs, .e., correlations involve common factors/latent variables diattenuated.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/calculateConstructVCV.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Internal: Calculate construct variance-covariance matrix — calculateConstructVCV","text":"","code":"calculateConstructVCV(  .C          = args_default()$.C,   .Q          = args_default()$.Q  )"},{"path":"https://floschuberth.github.io/cSEM/reference/calculateConstructVCV.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Internal: Calculate construct variance-covariance matrix — calculateConstructVCV","text":".C (J x J) composite variance-covariance matrix. .Q vector composite-construct correlations element names equal names J construct names used measurement model. Note Q^2 also called reliability coefficient.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/calculateConstructVCV.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Internal: Calculate construct variance-covariance matrix — calculateConstructVCV","text":"(J x J) construct VCV matrix. Disattenuated requested.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/calculateCorrectionFactors.html","id":null,"dir":"Reference","previous_headings":"","what":"Internal: Calculate PLSc correction factors — calculateCorrectionFactors","title":"Internal: Calculate PLSc correction factors — calculateCorrectionFactors","text":"Calculates correction factor used PLSc.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/calculateCorrectionFactors.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Internal: Calculate PLSc correction factors — calculateCorrectionFactors","text":"","code":"calculateCorrectionFactors(  .S               = args_default()$.S,  .W               = args_default()$.W,  .modes           = args_default()$.modes,  .csem_model      = args_default()$.csem_model,  .PLS_approach_cf = args_default()$.PLS_approach_cf  )"},{"path":"https://floschuberth.github.io/cSEM/reference/calculateCorrectionFactors.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Internal: Calculate PLSc correction factors — calculateCorrectionFactors","text":".S (K x K) empirical indicator correlation matrix. .W (J x K) matrix weights. .modes vector giving mode construct form \"name\" = \"mode\". used internally. .csem_model (possibly incomplete) cSEMModel-list. .PLS_approach_cf Character string. Approach used obtain correction factors PLSc. One : \"dist_squared_euclid\", \"dist_euclid_weighted\", \"fisher_transformed\", \"mean_arithmetic\", \"mean_geometric\", \"mean_harmonic\", \"geo_of_harmonic\". Defaults \"dist_squared_euclid\". Ignored .disattenuate = FALSE .approach_weights PLS-PM.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/calculateCorrectionFactors.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Internal: Calculate PLSc correction factors — calculateCorrectionFactors","text":"numeric vector correction factors element names equal names J constructs used measurement model.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/calculateCorrectionFactors.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Internal: Calculate PLSc correction factors — calculateCorrectionFactors","text":"Currently, seven approaches available: \"dist_squared_euclid\" (default) \"dist_euclid_weighted\" \"fisher_transformed\" \"mean_geometric\" \"mean_harmonic\" \"mean_arithmetic\" \"geo_of_harmonic\" (yet implemented) See (Dijkstra 2013)  details.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/calculateCorrectionFactors.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Internal: Calculate PLSc correction factors — calculateCorrectionFactors","text":"Dijkstra TK (2013). “Note Make Partial Least Squares Consistent.” Working Paper. doi:10.13140/RG.2.1.4547.5688 .","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/calculateDf.html","id":null,"dir":"Reference","previous_headings":"","what":"Degrees of freedom — calculateDf","title":"Degrees of freedom — calculateDf","text":"Calculate degrees freedom given model cSEMResults object.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/calculateDf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Degrees of freedom — calculateDf","text":"","code":"calculateDf(   .object     = NULL,   .null_model = FALSE,   ...   )"},{"path":"https://floschuberth.github.io/cSEM/reference/calculateDf.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Degrees of freedom — calculateDf","text":".object R object class cSEMResults resulting call csem(). .null_model Logical. degrees freedom null model computed? Defaults FALSE. ... Ignored.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/calculateDf.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Degrees of freedom — calculateDf","text":"single numeric value.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/calculateDf.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Degrees of freedom — calculateDf","text":"Although, composite-based estimators always retrieve parameters postulated models via estimation composite model, computation degrees freedom depends postulated model. See: cSEM website details degrees freedom calculated. compute degrees freedom null model use .null_model = TRUE. degrees freedom null model identical number non-redundant -diagonal elements empirical indicator correlation matrix. implicitly assumes null model model-implied indicator correlation matrix equal identity matrix.","code":""},{"path":[]},{"path":"https://floschuberth.github.io/cSEM/reference/calculateDistance.html","id":null,"dir":"Reference","previous_headings":"","what":"Internal: Matrix difference — calculateDistance","title":"Internal: Matrix difference — calculateDistance","text":"Calculates average differences possible pairs (symmetric) matrices list using given distance measure.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/calculateDistance.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Internal: Matrix difference — calculateDistance","text":"","code":"calculateDistance(   .matrices = NULL,    .distance = args_default()$.distance   )"},{"path":"https://floschuberth.github.io/cSEM/reference/calculateDistance.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Internal: Matrix difference — calculateDistance","text":".matrices list least two matrices. .distance Character string. distance measure. One : \"geodesic\" \"squared_euclidean\". Defaults \"geodesic\".","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/calculateDistance.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Internal: Matrix difference — calculateDistance","text":"numeric vector length one containing (arithmetic) mean differences possible pairs matrices supplied via .matrices.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/calculateDistance.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Internal: Matrix difference — calculateDistance","text":".matrices must list least two matrices. two matrices supplied arithmetic mean differences possible pairs (symmetric) matrices list computed. Mathematically n chose 2. Hence, supplying large number matrices become computationally challenging. Currently two distance measures supported: geodesic (Default) geodesic distance. squared_euclidean squared Euclidean distance","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/calculateEffects.html","id":null,"dir":"Reference","previous_headings":"","what":"Internal: Calculate direct, indirect and total effect — calculateEffects","title":"Internal: Calculate direct, indirect and total effect — calculateEffects","text":"direct effects equal estimated coefficients. total effect equals (-B)^-1 Gamma. indirect effect equals difference total effect indirect effect. addition, variance accounted (VAF) calculated. VAF defined ratio variables indirect effect total effect. Helper generic functions summarize() assess().","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/calculateEffects.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Internal: Calculate direct, indirect and total effect — calculateEffects","text":"","code":"calculateEffects(  .object       = NULL,  .output_type  = c(\"data.frame\", \"matrix\") )"},{"path":"https://floschuberth.github.io/cSEM/reference/calculateEffects.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Internal: Calculate direct, indirect and total effect — calculateEffects","text":".object R object class cSEMResults resulting call csem(). .output_type Character string. type output return. One \"complete\" \"structured\". See Value section details. Defaults \"complete\".","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/calculateEffects.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Internal: Calculate direct, indirect and total effect — calculateEffects","text":"matrix data frame effects.","code":""},{"path":[]},{"path":"https://floschuberth.github.io/cSEM/reference/calculateFLCriterion.html","id":null,"dir":"Reference","previous_headings":"","what":"Fornell-Larcker criterion — calculateFLCriterion","title":"Fornell-Larcker criterion — calculateFLCriterion","text":"Computes Fornell-Larcker matrix.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/calculateFLCriterion.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fornell-Larcker criterion — calculateFLCriterion","text":"","code":"calculateFLCriterion(   .object              = NULL,   .only_common_factors = TRUE,   ...   )"},{"path":"https://floschuberth.github.io/cSEM/reference/calculateFLCriterion.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fornell-Larcker criterion — calculateFLCriterion","text":".object R object class cSEMResults resulting call csem(). .only_common_factors Logical. concepts modeled common factors included calculating one following quality criteria: AVE, Fornell-Larcker criterion, HTMT, reliability estimates. Defaults TRUE. ... Ignored.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/calculateFLCriterion.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fornell-Larcker criterion — calculateFLCriterion","text":"matrix squared construct correlations -diagonal AVEs main diagonal.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/calculateFLCriterion.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fornell-Larcker criterion — calculateFLCriterion","text":"Fornell-Larcker criterion (FL criterion) rule suggested Fornell Larcker (1981)  assess discriminant validity. Fornell-Larcker criterion decision rule based comparison squared construct correlations average variance extracted (AVE). FL criterion inherently tied common factor model. therefore unclear meaningfully interpret FL criterion context model contains constructs modeled composites.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/calculateFLCriterion.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Fornell-Larcker criterion — calculateFLCriterion","text":"Fornell C, Larcker DF (1981). “Evaluating structural equation models unobservable variables measurement error.” Journal Marketing Research, XVIII, 39–50.","code":""},{"path":[]},{"path":"https://floschuberth.github.io/cSEM/reference/calculateFR.html","id":null,"dir":"Reference","previous_headings":"","what":"Internal: ANOVA F-test statistic — calculateFR","title":"Internal: ANOVA F-test statistic — calculateFR","text":"Calculate ANOVA F-test statistic suggested Sarstedt et al. (2011)  OTG testing procedure.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/calculateFR.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Internal: ANOVA F-test statistic — calculateFR","text":"","code":"calculateFR(.resample_sarstedt)"},{"path":"https://floschuberth.github.io/cSEM/reference/calculateFR.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Internal: ANOVA F-test statistic — calculateFR","text":".resample_sarstedt matrix containing parameter estimates potentially compared id column indicating group adherence row.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/calculateFR.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Internal: ANOVA F-test statistic — calculateFR","text":"named scalar, test statistic ANOVA F-test","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/calculateFR.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Internal: ANOVA F-test statistic — calculateFR","text":"Sarstedt M, Henseler J, Ringle CM (2011). “Multigroup Analysis Partial Least Squares (PLS) Path Modeling: Alternative Methods Empirical Results.” Advances International Marketing, 195–218. Emerald Group Publishing Limited. doi:10.1108/s1474-7979(2011)0000022012 .","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/calculateGoF.html","id":null,"dir":"Reference","previous_headings":"","what":"Goodness of Fit (GoF) — calculateGoF","title":"Goodness of Fit (GoF) — calculateGoF","text":"Calculate Goodness Fit (GoF) proposed Tenenhaus et al. (2004) . Note , contrary name suggests, GoF measure model fit sense SEM. See e.g. Henseler Sarstedt (2012)  discussion.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/calculateGoF.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Goodness of Fit (GoF) — calculateGoF","text":"","code":"calculateGoF(  .object              = NULL )"},{"path":"https://floschuberth.github.io/cSEM/reference/calculateGoF.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Goodness of Fit (GoF) — calculateGoF","text":".object R object class cSEMResults resulting call csem().","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/calculateGoF.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Goodness of Fit (GoF) — calculateGoF","text":"single numeric value.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/calculateGoF.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Goodness of Fit (GoF) — calculateGoF","text":"GoF inherently tied common factor model. therefore unclear meaningfully interpret GoF context model contains constructs modeled composites.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/calculateGoF.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Goodness of Fit (GoF) — calculateGoF","text":"Henseler J, Sarstedt M (2012). “Goodness--fit Indices Partial Least Squares Path Modeling.” Computational Statistics, 28(2), 565–580. doi:10.1007/s00180-012-0317-1 . Tenenhaus M, Amanto S, Vinzi VE (2004). “Global Goodness--Fit Index PLS Structural Equation Modelling.” Proceedings XLII SIS Scientific Meeting, 739–742.","code":""},{"path":[]},{"path":"https://floschuberth.github.io/cSEM/reference/calculateHTMT.html","id":null,"dir":"Reference","previous_headings":"","what":"HTMT — calculateHTMT","title":"HTMT — calculateHTMT","text":"Computes either heterotrait-monotrait ratio correlations (HTMT) based Henseler et al. (2015)  HTMT2 proposed Roemer et al. (2021) . HTMT consistent estimator construct correlation case tau-equivalent measurement models, HTMT2 consistent estimator congeneric measurement models. general, used assess discriminant validity.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/calculateHTMT.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"HTMT — calculateHTMT","text":"","code":"calculateHTMT(  .object               = NULL,  .type_htmt            = c('htmt','htmt2'),  .absolute             = TRUE,  .alpha                = 0.05,  .ci                   = c(\"CI_percentile\", \"CI_standard_z\", \"CI_standard_t\",                             \"CI_basic\", \"CI_bc\", \"CI_bca\", \"CI_t_interval\"),  .inference            = FALSE,  .only_common_factors  = TRUE,  .R                    = 499,  .seed                 = NULL,  ... )"},{"path":"https://floschuberth.github.io/cSEM/reference/calculateHTMT.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"HTMT — calculateHTMT","text":".object R object class cSEMResults resulting call csem(). .type_htmt Character string indicating type HTMT calculated, .e., original HTMT (\"htmt\") HTMT2 (\"htmt2\"). Defaults \"htmt\" .absolute Logical. absolute HTMT values returned? Defaults TRUE . .alpha numeric value giving significance level. Defaults 0.05. .ci character strings naming type confidence interval use compute 1-alpha% quantile bootstrap HTMT values. possible choices see infer(). Ignored .inference = FALSE. Defaults \"CI_percentile\". .inference Logical. critical values computed? Defaults FALSE. .only_common_factors Logical. concepts modeled common factors included calculating one following quality criteria: AVE, Fornell-Larcker criterion, HTMT, reliability estimates. Defaults TRUE. .R Integer. number bootstrap replications. Defaults 499. .seed Integer NULL. random seed use. Defaults NULL case arbitrary seed chosen. Note scope seed limited body function used . Hence, global seed altered! ... Ignored.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/calculateHTMT.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"HTMT — calculateHTMT","text":"named list containing: values HTMT/HTMT2, .e., matrix HTMT/HTMT2 values lower triangular .inference = TRUE upper triangular contains upper limit 1-2*.alpha% bootstrap confidence interval HTMT/HTMT2 positive lower limit HTMT/HTMT2 negative. lower upper limits 1-2*.alpha% bootstrap confidence interval .inference = TRUE; otherwise NULL. number admissible bootstrap runs, .e., number HTMT/HTMT2 values calculated bootstrap .inference = TRUE; otherwise NULL. Note, HTMT2 based geometric thus always calculated.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/calculateHTMT.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"HTMT — calculateHTMT","text":"Computation HTMT/HTMT2 assumes intra-block inter-block correlations indicators either -positive -negative. warning given case. obtain bootstrap confidence intervals HTMT/HTMT2 values, set .inference = TRUE. choose type confidence interval, use .ci. control bootstrap process, arguments .R .seed available. Note, .alpha multiplied two typically researchers interested one-sided bootstrap confidence intervals HTMT/HTMT2. Since HTMT HTMT2 assume reflective measurement model concepts modeled common factors considered default. concepts modeled composites HTMT may computed setting .only_common_factors = FALSE, however, unclear interpret values case.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/calculateHTMT.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"HTMT — calculateHTMT","text":"Henseler J, Ringle CM, Sarstedt M (2015). “New Criterion Assessing Discriminant Validity Variance-based Structural Equation Modeling.” Journal Academy Marketing Science, 43(1), 115–135. doi:10.1007/s11747-014-0403-8 . Roemer E, Schuberth F, Henseler J (2021). “HTMT2 – improved criterion assessing discriminant validity structural equation modeling.” Industrial Management & Data Systems, 121(12), 2637–2650.","code":""},{"path":[]},{"path":"https://floschuberth.github.io/cSEM/reference/calculateIndicatorCor.html","id":null,"dir":"Reference","previous_headings":"","what":"Internal: Calculate indicator correlation matrix — calculateIndicatorCor","title":"Internal: Calculate indicator correlation matrix — calculateIndicatorCor","text":"Calculate indicator correlation matrix using conventional robust methods.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/calculateIndicatorCor.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Internal: Calculate indicator correlation matrix — calculateIndicatorCor","text":"","code":"calculateIndicatorCor(   .X_cleaned           = NULL,    .approach_cor_robust = \"none\"  )"},{"path":"https://floschuberth.github.io/cSEM/reference/calculateIndicatorCor.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Internal: Calculate indicator correlation matrix — calculateIndicatorCor","text":".X_cleaned data.frame processed data (cleaned ordered). Note: X_cleaned may scaled! .approach_cor_robust Character string. Approach used obtain robust indicator correlation matrix. One : \"none\" case standard Bravais-Pearson correlation used, \"spearman\" Spearman rank correlation, \"mcd\" via MASS::cov.rob() robust correlation matrix. Defaults \"none\". Note many postestimation procedures (testOMF() fit() implicitly assume continuous indicator correlation matrix (e.g. Bravais-Pearson correlation matrix). use know .","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/calculateIndicatorCor.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Internal: Calculate indicator correlation matrix — calculateIndicatorCor","text":"list elements: $S (K x K) indicator correlation matrix $cor_type type(s) indicator correlation computed ( \"Pearson\", \"Polyserial\", \"Polychoric\") $thre_est Currently ignored (NULL)","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/calculateIndicatorCor.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Internal: Calculate indicator correlation matrix — calculateIndicatorCor","text":".approach_cor_robust = \"none\" (default) type correlation computed depends types columns .X_cleaned (.e., indicators) involved computation. Numeric-numeric columns (indicators) involved numeric, Bravais-Pearson product-moment correlation computed (via stats::cor()). Numeric-factor columns factor variable, polyserial correlation (Drasgow 1988)  computed (via polycor::polyserial()). Factor-factor columns factor variables, polychoric correlation (Drasgow 1988)  computed (via polycor::polychor()). Note: logical input treated 0-1 factor variable.  \"mcd\" (= minimum covariance determinant), MCD estimator (Rousseeuw Driessen 1999) , robust covariance estimator, applied (via MASS::cov.rob()). \"spearman\", Spearman rank correlation used (via stats::cor()).","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/calculateIndicatorCor.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Internal: Calculate indicator correlation matrix — calculateIndicatorCor","text":"Drasgow F (1988). “Polychoric polyserial correlations.” Encyclopedia Statistical Sciences, volume 7, 68-74. John Wiley & Sons Inc, Hoboken. Rousseeuw PJ, Driessen KV (1999). “Fast Algorithm Minimum Covariance Determinant Estimator.” Technometrics, 41(3), 212–223. doi:10.1080/00401706.1999.10485670 .","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/calculateInnerWeightsPLS.html","id":null,"dir":"Reference","previous_headings":"","what":"Internal: Calculate the inner weights for PLS-PM — calculateInnerWeightsPLS","title":"Internal: Calculate the inner weights for PLS-PM — calculateInnerWeightsPLS","text":"PLS-PM forms \"inner\" composites weighted sum related composites. inner weights obtained using one following schemes (Lohmöller 1989) : centroid According centroid weighting scheme inner weight used form composite j either 1 correlation composite j via structural model related composite = 1, ..., positive -1 negative. factorial According factorial weighting scheme inner weight used form inner composite j equal correlation composite j via structural model related composite = 1, ..., . path Lets call construct arrow pointing construct j predecessors j arrows going j constructs followers j. According path weighting scheme, inner weights computed follows. Take construct j: predecessors j set inner weight predecessor correlation j. followers j set inner weight follower coefficient multiple regression j followers = 1,...,. Except path weighting scheme relatedness can come two flavors. .PLS_ignore_structural_model = TRUE constructs considered related. .PLS_ignore_structural_model = FALSE (default) adjacent constructs considered. .PLS_ignore_structural_model = TRUE .PLS_weight_scheme_inner = \"path\" warning issued .PLS_ignore_structural_model changed FALSE.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/calculateInnerWeightsPLS.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Internal: Calculate the inner weights for PLS-PM — calculateInnerWeightsPLS","text":"","code":"calculateInnerWeightsPLS(   .S                           = args_default()$.S,   .W                           = args_default()$.W,   .csem_model                  = args_default()$.csem_model,   .PLS_ignore_structural_model = args_default()$.PLS_ignore_structrual_model,   .PLS_weight_scheme_inner     = args_default()$.PLS_weight_scheme_inner )"},{"path":"https://floschuberth.github.io/cSEM/reference/calculateInnerWeightsPLS.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Internal: Calculate the inner weights for PLS-PM — calculateInnerWeightsPLS","text":".S (K x K) empirical indicator correlation matrix. .W (J x K) matrix weights. .csem_model (possibly incomplete) cSEMModel-list. .PLS_ignore_structural_model Logical. structural model ignored calculating inner weights PLS-PM algorithm? Defaults FALSE. Ignored .approach_weights PLS-PM. .PLS_weight_scheme_inner Character string. inner weighting scheme used PLS-PM. One : \"centroid\", \"factorial\", \"path\". Defaults \"path\". Ignored .approach_weight PLS-PM.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/calculateInnerWeightsPLS.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Internal: Calculate the inner weights for PLS-PM — calculateInnerWeightsPLS","text":"(J x J) matrix E inner weights.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/calculateMAE.html","id":null,"dir":"Reference","previous_headings":"","what":"Internal: Calculate prediction metrics — calculateMAE","title":"Internal: Calculate prediction metrics — calculateMAE","text":"Currently, following prediction measures available:","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/calculateMAE.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Internal: Calculate prediction metrics — calculateMAE","text":"","code":"calculateMAE(resid)"},{"path":"https://floschuberth.github.io/cSEM/reference/calculateMAE.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Internal: Calculate prediction metrics — calculateMAE","text":"vector prediction measures observed variables belonging endogenous constructs","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/calculateMAE.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Internal: Calculate prediction metrics — calculateMAE","text":"Mean absolute error Mean absolute percentage error Mean squared error (MSE) Root mean squared error Theil's forecast accuracy Theil's forecast quality Bias proportion MSE Regression proportion MSE Disturbance proportion MSE","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/calculateModelSelectionCriteria.html","id":null,"dir":"Reference","previous_headings":"","what":"Model selection criteria — calculateModelSelectionCriteria","title":"Model selection criteria — calculateModelSelectionCriteria","text":"Calculate several information model selection criteria (MSC) Akaike information criterion (AIC), Bayesian information criterion (BIC) Hannan-Quinn criterion (HQ).","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/calculateModelSelectionCriteria.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Model selection criteria — calculateModelSelectionCriteria","text":"","code":"calculateModelSelectionCriteria(   .object          = NULL,   .ms_criterion    = c(\"all\", \"aic\", \"aicc\", \"aicu\", \"bic\", \"fpe\", \"gm\", \"hq\",                        \"hqc\", \"mallows_cp\"),   .by_equation     = TRUE,    .only_structural = TRUE    )"},{"path":"https://floschuberth.github.io/cSEM/reference/calculateModelSelectionCriteria.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Model selection criteria — calculateModelSelectionCriteria","text":".object R object class cSEMResults resulting call csem(). .ms_criterion Character string. Either single character string vector character strings naming model selection criterion compute. Defaults \"\". .by_equation criteria computed structural model equation separately? Defaults TRUE. .only_structural log-likelihood based structural model? Ignored .by_equation == TRUE. Defaults TRUE.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/calculateModelSelectionCriteria.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Model selection criteria — calculateModelSelectionCriteria","text":".by_equation == TRUE named list model selection criteria.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/calculateModelSelectionCriteria.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Model selection criteria — calculateModelSelectionCriteria","text":"default, criteria calculated (.ms_criterion == \"\"). compute subset criteria vector criteria may given. .by_equation == TRUE (default), criteria computed structural equation model separately, suggested Sharma et al. (2019)  context PLS. relevant formula can found Table B1 appendix Sharma et al. (2019) . .by_equation == FALSE AIC, BIC HQ whole model calculated. criteria currently ignored case! relevant formula (see, e.g., (Akaike 1974) , Schwarz (1978) , Hannan Quinn (1979) ): $$AIC = - 2*log(L) + 2*k$$ $$BIC = - 2*log(L) + k*ln(n)$$ $$HQ  = - 2*log(L) + 2*k*ln(ln(n))$$ log(L) log likelihood function multivariate normal distribution observable variables, k (total) number estimated parameters, n sample size. .only_structural == TRUE, log(L) based structural model . argument ignored .by_equation == TRUE.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/calculateModelSelectionCriteria.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Model selection criteria — calculateModelSelectionCriteria","text":"Akaike H (1974). “New Look Statistical Model Identification.” IEEE Transactions Automatic Control, 19(6), 716–723. Hannan EJ, Quinn BG (1979). “Determination order autoregression.” Journal Royal Statistical Society: Series B (Methodological), 41(2), 190–195. Schwarz G (1978). “Estimating Dimension Model.” Annals Statistics, 6(2), 461–464. doi:10.1214/aos/1176344136 . Sharma P, Sarstedt M, Shmueli G, Kim KH, Thiele KO (2019). “PLS-Based Model Selection: Role Alternative Explanations Information Systems Research.” Journal Association Information Systems, 20(4).","code":""},{"path":[]},{"path":"https://floschuberth.github.io/cSEM/reference/calculateOuterWeightsPLS.html","id":null,"dir":"Reference","previous_headings":"","what":"Internal: Calculate the outer weights for PLS-PM — calculateOuterWeightsPLS","title":"Internal: Calculate the outer weights for PLS-PM — calculateOuterWeightsPLS","text":"Calculates outer weights PLS-PM. Currently, originally suggested mode mode B suggested. Additionally, non-negative least squares (modeBNNLS) weights principal component analysis (PCA) implemented.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/calculateOuterWeightsPLS.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Internal: Calculate the outer weights for PLS-PM — calculateOuterWeightsPLS","text":"","code":"calculateOuterWeightsPLS(    .data   = args_default()$.data,      .S      = args_default()$.S,    .W      = args_default()$.W,    .E      = args_default()$.E,    .modes  = args_default()$.modes    )"},{"path":"https://floschuberth.github.io/cSEM/reference/calculateOuterWeightsPLS.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Internal: Calculate the outer weights for PLS-PM — calculateOuterWeightsPLS","text":".data data.frame matrix standardized unstandardized data (indicators/items/manifest variables). Possible column types classes data provided : \"logical\", \"numeric\" (\"double\" \"integer\"), \"factor\" (\"ordered\" /\"unordered\"), \"character\" (converted factor), mix several types. .S (K x K) empirical indicator correlation matrix. .W (J x K) matrix weights. .E (J x J) matrix inner weights. .modes vector giving mode construct form \"name\" = \"mode\". used internally.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/calculateOuterWeightsPLS.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Internal: Calculate the outer weights for PLS-PM — calculateOuterWeightsPLS","text":"(J x K) matrix outer weights.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/calculateParameterDifference.html","id":null,"dir":"Reference","previous_headings":"","what":"Internal: Parameter differences across groups — calculateParameterDifference","title":"Internal: Parameter differences across groups — calculateParameterDifference","text":"Calculate difference one parameter estimates across possible pairs groups (data sets) .object.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/calculateParameterDifference.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Internal: Parameter differences across groups — calculateParameterDifference","text":"","code":"calculateParameterDifference(   .object     = args_default()$.object,   .model      = args_default()$.model )"},{"path":"https://floschuberth.github.io/cSEM/reference/calculateParameterDifference.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Internal: Parameter differences across groups — calculateParameterDifference","text":".object R object class cSEMResults resulting call csem(). .model model lavaan model syntax indicating parameters (.e., path (~), loadings (=~), weights (<~)) compared across groups. Defaults NULL case parameters model compared.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/calculateParameterDifference.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Internal: Parameter differences across groups — calculateParameterDifference","text":"list length equal number possible pairs groups .object (mathematically, n choose 2, .e., 3 three groups 6 4 groups). list elements list three. first list element contains difference parameter estimates structural model, second list element difference estimated loadings, third difference estimated weights.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/calculatePr.html","id":null,"dir":"Reference","previous_headings":"","what":"Internal: Calculation of the CDF used in Henseler et al. (2009) — calculatePr","title":"Internal: Calculation of the CDF used in Henseler et al. (2009) — calculatePr","text":"Calculates probability theta^1 smaller equal theta^2. See Equation (6) Sarstedt et al. (2011) .","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/calculatePr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Internal: Calculation of the CDF used in Henseler et al. (2009) — calculatePr","text":"","code":"calculatePr(.resample_centered = NULL, .parameters_to_compare = NULL)"},{"path":"https://floschuberth.github.io/cSEM/reference/calculatePr.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Internal: Calculation of the CDF used in Henseler et al. (2009) — calculatePr","text":".parameters_to_compare model lavaan model syntax indicating parameters (.e, path (~), loadings (=~), weights (<~), correlations (~~)) compared across groups. Defaults NULL case weights, loadings path coefficients originally specified model compared.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/calculatePr.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Internal: Calculation of the CDF used in Henseler et al. (2009) — calculatePr","text":"named vector","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/calculatePr.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Internal: Calculation of the CDF used in Henseler et al. (2009) — calculatePr","text":"Sarstedt M, Henseler J, Ringle CM (2011). “Multigroup Analysis Partial Least Squares (PLS) Path Modeling: Alternative Methods Empirical Results.” Advances International Marketing, 195–218. Emerald Group Publishing Limited. doi:10.1108/s1474-7979(2011)0000022012 .","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/calculateRelativeGoF.html","id":null,"dir":"Reference","previous_headings":"","what":"Relative Goodness of Fit (relative GoF) — calculateRelativeGoF","title":"Relative Goodness of Fit (relative GoF) — calculateRelativeGoF","text":"Calculate Relative Goodness Fit (GoF) proposed Vinzi et al. (2010) . Note , contrary name suggests, Relative GoF measure model fit sense SEM. See e.g. Henseler Sarstedt (2012)  discussion.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/calculateRelativeGoF.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Relative Goodness of Fit (relative GoF) — calculateRelativeGoF","text":"","code":"calculateRelativeGoF(  .object              = NULL )"},{"path":"https://floschuberth.github.io/cSEM/reference/calculateRelativeGoF.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Relative Goodness of Fit (relative GoF) — calculateRelativeGoF","text":".object R object class cSEMResults resulting call csem().","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/calculateRelativeGoF.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Relative Goodness of Fit (relative GoF) — calculateRelativeGoF","text":"single numeric value.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/calculateRelativeGoF.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Relative Goodness of Fit (relative GoF) — calculateRelativeGoF","text":"Henseler J, Sarstedt M (2012). “Goodness--fit Indices Partial Least Squares Path Modeling.” Computational Statistics, 28(2), 565–580. doi:10.1007/s00180-012-0317-1 . Vinzi VE, Trinchera L, Amato S (2010). “PLS path modeling: foundations recent developments open issues model assessment improvement.” Vinzi VE, Wang H (eds.), Handbook Partial Least Squares, 47–82. Springer.","code":""},{"path":[]},{"path":"https://floschuberth.github.io/cSEM/reference/calculateReliabilities.html","id":null,"dir":"Reference","previous_headings":"","what":"Internal: Calculate Reliabilities — calculateReliabilities","title":"Internal: Calculate Reliabilities — calculateReliabilities","text":"Internal: Calculate Reliabilities","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/calculateReliabilities.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Internal: Calculate Reliabilities — calculateReliabilities","text":"","code":"calculateReliabilities(   .X = args_default()$.X,   .S = args_default()$.S,   .W = args_default()$.W,   .approach_weights = args_default()$.approach_weights,   .csem_model = args_default()$.csem_model,   .disattenuate = args_default()$.disattenuate,   .PLS_approach_cf = args_default()$.PLS_approach_cf,   .reliabilities = args_default()$.reliabilities )"},{"path":"https://floschuberth.github.io/cSEM/reference/calculateReliabilities.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Internal: Calculate Reliabilities — calculateReliabilities","text":".X matrix processed data (scaled, cleaned ordered). .S (K x K) empirical indicator correlation matrix. .W (J x K) matrix weights. .approach_weights Character string. Approach used obtain composite weights. One : \"PLS-PM\", \"SUMCORR\", \"MAXVAR\", \"SSQCORR\", \"MINVAR\", \"GENVAR\", \"GSCA\", \"PCA\", \"unit\", \"bartlett\", \"regression\". Defaults \"PLS-PM\". .csem_model (possibly incomplete) cSEMModel-list. .disattenuate Logical. composite/proxy correlations disattenuated yield consistent loadings path estimates least one construct modeled common factor? Defaults TRUE. .PLS_approach_cf Character string. Approach used obtain correction factors PLSc. One : \"dist_squared_euclid\", \"dist_euclid_weighted\", \"fisher_transformed\", \"mean_arithmetic\", \"mean_geometric\", \"mean_harmonic\", \"geo_of_harmonic\". Defaults \"dist_squared_euclid\". Ignored .disattenuate = FALSE .approach_weights PLS-PM. .reliabilities character vector \"name\" = value pairs, value number 0 1 \"name\" character string corresponding construct name, NULL. Reliabilities may given subset constructs. Defaults NULL case reliabilities estimated csem(). Currently, supported .approach_weights = \"PLS-PM\".","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/calculateVIFModeB.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate variance inflation factors (VIF) for weights obtained by PLS Mode B — calculateVIFModeB","title":"Calculate variance inflation factors (VIF) for weights obtained by PLS Mode B — calculateVIFModeB","text":"Calculate variance inflation factor (VIF) weights obtained PLS-PM's Mode B.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/calculateVIFModeB.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate variance inflation factors (VIF) for weights obtained by PLS Mode B — calculateVIFModeB","text":"","code":"calculateVIFModeB(.object = NULL)"},{"path":"https://floschuberth.github.io/cSEM/reference/calculateVIFModeB.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate variance inflation factors (VIF) for weights obtained by PLS Mode B — calculateVIFModeB","text":".object R object class cSEMResults resulting call csem().","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/calculateVIFModeB.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate variance inflation factors (VIF) for weights obtained by PLS Mode B — calculateVIFModeB","text":"named list vectors containing VIF values. list name name construct whose weights obtained Mode B. vectors contain VIF values obtained regression explanatory variable given construct remaining explanatory variables construct. weighting approach \"PLS-PM\" none constructs Mode B used, function silently returns NA.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/calculateVIFModeB.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Calculate variance inflation factors (VIF) for weights obtained by PLS Mode B — calculateVIFModeB","text":"Weight estimates obtained Mode B can suffer multicollinearity. VIF values commonly used assess severity multicollinearity. function applicable objects class cSEMResults_default. object classes use assess().","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/calculateVIFModeB.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Calculate variance inflation factors (VIF) for weights obtained by PLS Mode B — calculateVIFModeB","text":"references Rd macro \\insertAllCites help page.","code":""},{"path":[]},{"path":"https://floschuberth.github.io/cSEM/reference/calculateWeightsGSCA.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate composite weights using GSCA — calculateWeightsGSCA","title":"Calculate composite weights using GSCA — calculateWeightsGSCA","text":"Calculate composite weights using generalized structure component analysis (GSCA). first version approach presented Hwang Takane (2004) . Since , several advancements proposed. latest version GSCA can found Hwang Takane (2014) . version cSEMs implementation based .","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/calculateWeightsGSCA.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate composite weights using GSCA — calculateWeightsGSCA","text":"","code":"calculateWeightsGSCA(   .X                           = args_default()$.X,   .S                           = args_default()$.S,   .csem_model                  = args_default()$.csem_model,   .conv_criterion              = args_default()$.conv_criterion,   .iter_max                    = args_default()$.iter_max,   .starting_values             = args_default()$.starting_values,   .tolerance                   = args_default()$.tolerance    )"},{"path":"https://floschuberth.github.io/cSEM/reference/calculateWeightsGSCA.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate composite weights using GSCA — calculateWeightsGSCA","text":".X matrix processed data (scaled, cleaned ordered). .S (K x K) empirical indicator correlation matrix. .csem_model (possibly incomplete) cSEMModel-list. .conv_criterion Character string. criterion use convergence check. One : \"diff_absolute\", \"diff_squared\", \"diff_relative\". Defaults \"diff_absolute\". .iter_max Integer. maximum number iterations allowed. iter_max = 1 .approach_weights = \"PLS-PM\" one-step weights returned. algorithm exceeds specified number, weights iteration step .iter_max - 1  returned warning. Defaults 100. .starting_values named list vectors list names construct names whose indicator weights user wishes set. vectors must named vectors \"indicator_name\" = value pairs, value (scaled unscaled) starting weight. Defaults NULL. .tolerance Double. tolerance criterion convergence. Defaults 1e-05.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/calculateWeightsGSCA.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate composite weights using GSCA — calculateWeightsGSCA","text":"named list. J stands number constructs K number indicators. $W (J x K) matrix estimated weights. $E NULL $Modes named vector Modes used outer estimation, GSCA mode automatically set \"gsca\". $Conv_status convergence status. TRUE algorithm converged FALSE otherwise. $Iterations number iterations required.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/calculateWeightsGSCA.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Calculate composite weights using GSCA — calculateWeightsGSCA","text":"Hwang H, Takane Y (2004). “Generalized Structured Component Analysis.” Psychometrika, 69(1), 81–99. Hwang H, Takane Y (2014). Generalized Structured Component Analysis: Component-Based Approach Structural Equation Modeling,  Chapman & Hall/CRC Statistics Social Behavioral Sciences. Chapman Hall/CRC.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/calculateWeightsGSCAm.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate weights using GSCAm — calculateWeightsGSCAm","title":"Calculate weights using GSCAm — calculateWeightsGSCAm","text":"Calculate composite weights using generalized structured component analysis uniqueness terms (GSCAm) proposed Hwang et al. (2017) .","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/calculateWeightsGSCAm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate weights using GSCAm — calculateWeightsGSCAm","text":"","code":"calculateWeightsGSCAm(   .X                           = args_default()$.X,   .csem_model                  = args_default()$.csem_model,   .conv_criterion              = args_default()$.conv_criterion,   .iter_max                    = args_default()$.iter_max,   .starting_values             = args_default()$.starting_values,   .tolerance                   = args_default()$.tolerance    )"},{"path":"https://floschuberth.github.io/cSEM/reference/calculateWeightsGSCAm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate weights using GSCAm — calculateWeightsGSCAm","text":".X matrix processed data (scaled, cleaned ordered). .csem_model (possibly incomplete) cSEMModel-list. .conv_criterion Character string. criterion use convergence check. One : \"diff_absolute\", \"diff_squared\", \"diff_relative\". Defaults \"diff_absolute\". .iter_max Integer. maximum number iterations allowed. iter_max = 1 .approach_weights = \"PLS-PM\" one-step weights returned. algorithm exceeds specified number, weights iteration step .iter_max - 1  returned warning. Defaults 100. .starting_values named list vectors list names construct names whose indicator weights user wishes set. vectors must named vectors \"indicator_name\" = value pairs, value (scaled unscaled) starting weight. Defaults NULL. .tolerance Double. tolerance criterion convergence. Defaults 1e-05.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/calculateWeightsGSCAm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate weights using GSCAm — calculateWeightsGSCAm","text":"list elements $W (J x K) matrix estimated weights. $C (J x K) matrix estimated loadings. $B (J x J) matrix estimated path coefficients. $E NULL $Modes named vector Modes used outer estimation, GSCA mode automatically set 'gsca'. $Conv_status convergence status. TRUE algorithm converged FALSE otherwise. $Iterations number iterations required.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/calculateWeightsGSCAm.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Calculate weights using GSCAm — calculateWeightsGSCAm","text":"constructs modeled common factors calling csem() .appraoch_weights = \"GSCA\" automatically call calculateWeightsGSCAm() unless .disattenuate = FALSE. GSCAm currently works pure common factor models. reason implementation cSEM based (appendix) Hwang et al. (2017) . Following appendix, GSCAm fails least one construct modeled composite calculating weight estimates GSCAm leads product involving measurement matrix. matrix full rank construct modeled composite present. reason measurement matrix zero row every construct pure composite (.e. related loadings zero) , therefore, leads non-invertible matrix multiplying transposed.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/calculateWeightsGSCAm.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Calculate weights using GSCAm — calculateWeightsGSCAm","text":"Hwang H, Takane Y, Jung K (2017). “Generalized structured component analysis uniqueness terms accommodating measurement error.” Frontiers Psychology, 8(2137), 1–12.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/calculateWeightsKettenring.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate composite weights using GCCA — calculateWeightsKettenring","title":"Calculate composite weights using GCCA — calculateWeightsKettenring","text":"Calculates composite weights according one five criteria \"SUMCORR\", \"MAXVAR\", \"SSQCORR\", \"MINVAR\", \"GENVAR\" suggested Kettenring (1971) .","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/calculateWeightsKettenring.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate composite weights using GCCA — calculateWeightsKettenring","text":"","code":"calculateWeightsKettenring(   .S              = args_default()$.S,    .csem_model     = args_default()$.csem_model,      .approach_gcca  = args_default()$.approach_gcca   )"},{"path":"https://floschuberth.github.io/cSEM/reference/calculateWeightsKettenring.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate composite weights using GCCA — calculateWeightsKettenring","text":".S (K x K) empirical indicator correlation matrix. .csem_model (possibly incomplete) cSEMModel-list. .approach_gcca Character string. Kettenring approach use GCCA. One \"SUMCORR\", \"MAXVAR\", \"SSQCORR\", \"MINVAR\" \"GENVAR\". Defaults \"SUMCORR\".","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/calculateWeightsKettenring.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate composite weights using GCCA — calculateWeightsKettenring","text":"named list. J stands number constructs K number indicators. $W (J x K) matrix estimated weights. $E NULL $Modes GCCA mode used estimation. $Conv_status convergence status. TRUE algorithm converged FALSE otherwise. .approach_gcca = \"MINVAR\" .approach_gcca = \"MAXVAR\" convergence status NULL since closed-form estimators. $Iterations number iterations required. 0 .approach_gcca = \"MINVAR\" .approach_gcca = \"MAXVAR\"","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/calculateWeightsKettenring.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Calculate composite weights using GCCA — calculateWeightsKettenring","text":"Kettenring JR (1971). “Canonical Analysis Several Sets Variables.” Biometrika, 58(3), 433–451.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/calculateWeightsPCA.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate composite weights using principal component analysis (PCA) — calculateWeightsPCA","title":"Calculate composite weights using principal component analysis (PCA) — calculateWeightsPCA","text":"Calculate weights block extracting first principal component indicator correlation matrix S_jj blocks, .e., weights simply first eigenvector S_jj.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/calculateWeightsPCA.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate composite weights using principal component analysis (PCA) — calculateWeightsPCA","text":"","code":"calculateWeightsPCA(  .S                 = args_default()$.S,  .csem_model        = args_default()$.csem_model   )"},{"path":"https://floschuberth.github.io/cSEM/reference/calculateWeightsPCA.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate composite weights using principal component analysis (PCA) — calculateWeightsPCA","text":".S (K x K) empirical indicator correlation matrix. .csem_model (possibly incomplete) cSEMModel-list.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/calculateWeightsPCA.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate composite weights using principal component analysis (PCA) — calculateWeightsPCA","text":"named list. J stands number constructs K number indicators. $W (J x K) matrix estimated weights. $E NULL $Modes mode used. Always \"PCA\". $Conv_status NULL iterations $Iterations 0 iterations","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/calculateWeightsPLS.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate composite weights using PLS-PM — calculateWeightsPLS","title":"Calculate composite weights using PLS-PM — calculateWeightsPLS","text":"Calculate composite weights using partial least squares path modeling (PLS-PM) algorithm (Wold 1975) .","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/calculateWeightsPLS.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate composite weights using PLS-PM — calculateWeightsPLS","text":"","code":"calculateWeightsPLS(   .data                        = args_default()$.data,   .S                           = args_default()$.S,   .csem_model                  = args_default()$.csem_model,   .conv_criterion              = args_default()$.conv_criterion,   .iter_max                    = args_default()$.iter_max,   .PLS_ignore_structural_model = args_default()$.PLS_ignore_structural_model,   .PLS_modes                   = args_default()$.PLS_modes,   .PLS_weight_scheme_inner     = args_default()$.PLS_weight_scheme_inner,   .starting_values             = args_default()$.starting_values,   .tolerance                   = args_default()$.tolerance    )"},{"path":"https://floschuberth.github.io/cSEM/reference/calculateWeightsPLS.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate composite weights using PLS-PM — calculateWeightsPLS","text":".data data.frame matrix standardized unstandardized data (indicators/items/manifest variables). Possible column types classes data provided : \"logical\", \"numeric\" (\"double\" \"integer\"), \"factor\" (\"ordered\" /\"unordered\"), \"character\" (converted factor), mix several types. .S (K x K) empirical indicator correlation matrix. .csem_model (possibly incomplete) cSEMModel-list. .conv_criterion Character string. criterion use convergence check. One : \"diff_absolute\", \"diff_squared\", \"diff_relative\". Defaults \"diff_absolute\". .iter_max Integer. maximum number iterations allowed. iter_max = 1 .approach_weights = \"PLS-PM\" one-step weights returned. algorithm exceeds specified number, weights iteration step .iter_max - 1  returned warning. Defaults 100. .PLS_ignore_structural_model Logical. structural model ignored calculating inner weights PLS-PM algorithm? Defaults FALSE. Ignored .approach_weights PLS-PM. .PLS_modes Either named list specifying mode used construct form \"construct_name\" = mode, single character string giving mode used constructs, NULL. Possible choices mode : \"modeA\", \"modeB\", \"modeBNNLS\", \"unit\", \"PCA\", single integer vector fixed weights length indicators construct given \"construct_name\". single number provided identical using unit weights, weights rescaled related composite unit variance.  Defaults NULL. NULL appropriate mode according type construct used chosen. Ignored .approach_weight PLS-PM. .PLS_weight_scheme_inner Character string. inner weighting scheme used PLS-PM. One : \"centroid\", \"factorial\", \"path\". Defaults \"path\". Ignored .approach_weight PLS-PM. .starting_values named list vectors list names construct names whose indicator weights user wishes set. vectors must named vectors \"indicator_name\" = value pairs, value (scaled unscaled) starting weight. Defaults NULL. .tolerance Double. tolerance criterion convergence. Defaults 1e-05.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/calculateWeightsPLS.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate composite weights using PLS-PM — calculateWeightsPLS","text":"named list. J stands number constructs K number indicators. $W (J x K) matrix estimated weights. $E (J x J) matrix inner weights. $Modes named vector modes used outer estimation. $Conv_status convergence status. TRUE algorithm converged FALSE otherwise. one-step weights used via .iter_max = 1 non-iterative procedure used, convergence status set NULL. $Iterations number iterations required.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/calculateWeightsPLS.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Calculate composite weights using PLS-PM — calculateWeightsPLS","text":"Wold H (1975). “Path models latent variables: NIPALS approach.” Blalock HM, Aganbegian , Borodkin FM, Boudon R, Capecchi V (eds.), Quantitative Sociology,  International Perspectives Mathematical Statistical Modeling, 307–357. Academic Press, New York.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/calculateWeightsUnit.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate composite weights using unit weights — calculateWeightsUnit","title":"Calculate composite weights using unit weights — calculateWeightsUnit","text":"Calculate unit weights blocks, .e., indicator block equally weighted.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/calculateWeightsUnit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate composite weights using unit weights — calculateWeightsUnit","text":"","code":"calculateWeightsUnit(  .S                 = args_default()$.S,  .csem_model        = args_default()$.csem_model,  .starting_values   = args_default()$.starting_values   )"},{"path":"https://floschuberth.github.io/cSEM/reference/calculateWeightsUnit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate composite weights using unit weights — calculateWeightsUnit","text":".S (K x K) empirical indicator correlation matrix. .csem_model (possibly incomplete) cSEMModel-list. .starting_values named list vectors list names construct names whose indicator weights user wishes set. vectors must named vectors \"indicator_name\" = value pairs, value (scaled unscaled) starting weight. Defaults NULL.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/calculateWeightsUnit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate composite weights using unit weights — calculateWeightsUnit","text":"named list. J stands number constructs K number indicators. $W (J x K) matrix estimated weights. $E NULL $Modes mode used. Always \"unit\". $Conv_status NULL iterations $Iterations 0 iterations","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/calculatef2.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate Cohen's f^2 — calculatef2","title":"Calculate Cohen's f^2 — calculatef2","text":"Calculate effect size regression analysis (Cohen 1992)  known Cohen's f^2.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/calculatef2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate Cohen's f^2 — calculatef2","text":"","code":"calculatef2(.object = NULL)"},{"path":"https://floschuberth.github.io/cSEM/reference/calculatef2.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate Cohen's f^2 — calculatef2","text":".object R object class cSEMResults resulting call csem().","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/calculatef2.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate Cohen's f^2 — calculatef2","text":"matrix many rows structural equations. number columns equal total number right-hand side variables equations.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/calculatef2.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Calculate Cohen's f^2 — calculatef2","text":"Cohen J (1992). “power primer.” Psychological Bulletin, 112(1), 155–159.","code":""},{"path":[]},{"path":"https://floschuberth.github.io/cSEM/reference/checkConvergence.html","id":null,"dir":"Reference","previous_headings":"","what":"Internal: Check convergence — checkConvergence","title":"Internal: Check convergence — checkConvergence","text":"Check convergence algorithm using one following criteria: diff_absolute Checks largest elementwise absolute difference two matrices .W_new W.old smaller given tolerance. diff_squared Checks largest elementwise squared difference two matrices .W_new W.old smaller given tolerance. diff_relative Checks largest elementwise absolute rate change (new - old / new) two matrices .W_new W.old smaller given tolerance.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/checkConvergence.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Internal: Check convergence — checkConvergence","text":"","code":"checkConvergence(   .W_new          = args_default()$.W_new,   .W_old          = args_default()$.W_old,   .conv_criterion = args_default()$.conv_criterion,   .tolerance      = args_default()$.tolerance   )"},{"path":"https://floschuberth.github.io/cSEM/reference/checkConvergence.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Internal: Check convergence — checkConvergence","text":".W_new (J x K) matrix weights. .W_old (J x K) matrix weights. .conv_criterion Character string. criterion use convergence check. One : \"diff_absolute\", \"diff_squared\", \"diff_relative\". Defaults \"diff_absolute\". .tolerance Double. tolerance criterion convergence. Defaults 1e-05.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/checkConvergence.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Internal: Check convergence — checkConvergence","text":"TRUE converged; FALSE otherwise.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/check_connection.html","id":null,"dir":"Reference","previous_headings":"","what":"Internal: Check whether two indicators belong to the same construct. — check_connection","title":"Internal: Check whether two indicators belong to the same construct. — check_connection","text":"Checks whether two indicators belong construct.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/check_connection.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Internal: Check whether two indicators belong to the same construct. — check_connection","text":"","code":"check_connection(   .indicator1,   .indicator2,   .model_measurement,   .model_error_cor )"},{"path":"https://floschuberth.github.io/cSEM/reference/check_connection.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Internal: Check whether two indicators belong to the same construct. — check_connection","text":".indicator1 Character string. name indicator 1. .indicator2 Character string. name indicator 1. .model_measurement Matrix. measurement matrix indicating relationship constructs indicators. .model_error_cor Matrix. matrix indicates error correlation structure.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/check_connection.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Internal: Check whether two indicators belong to the same construct. — check_connection","text":"TRUE indicators belong construct, FALSE otherwise.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/classifyConstructs.html","id":null,"dir":"Reference","previous_headings":"","what":"Internal: Classify structural model terms by type — classifyConstructs","title":"Internal: Classify structural model terms by type — classifyConstructs","text":"Classify terms structural model according type.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/classifyConstructs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Internal: Classify structural model terms by type — classifyConstructs","text":"","code":"classifyConstructs(.terms = args_default()$.terms)"},{"path":"https://floschuberth.github.io/cSEM/reference/classifyConstructs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Internal: Classify structural model terms by type — classifyConstructs","text":".terms vector construct names classified.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/classifyConstructs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Internal: Classify structural model terms by type — classifyConstructs","text":"named list length equal number terms provided containing data frame columns \"Term_class\", \"Component\", \"Component_type\", \"Component_freq\".","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/classifyConstructs.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Internal: Classify structural model terms by type — classifyConstructs","text":"Classification required estimate nonlinear structural relationships. Currently following terms supported Single, e.g., eta1 Quadratic, e.g., eta1.eta1 Cubic, e.g., eta1.eta1.eta1 Two-way interaction, e.g., eta1.eta2 Three-way interaction, e.g., eta1.eta2.eta3 Quadratic two-way interaction, e.g., eta1.eta1.eta3 Note exponential terms modeled \"interactions \" .e., eta1^3 = eta1.eta1.eta1.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/cleanNode.html","id":null,"dir":"Reference","previous_headings":"","what":"Internal: Clean a node name. — cleanNode","title":"Internal: Clean a node name. — cleanNode","text":"Removes trailing \"_temp\" node name.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/cleanNode.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Internal: Clean a node name. — cleanNode","text":"","code":"cleanNode(node)"},{"path":"https://floschuberth.github.io/cSEM/reference/cleanNode.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Internal: Clean a node name. — cleanNode","text":"node node name.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/cleanNode.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Internal: Clean a node name. — cleanNode","text":"cleaned node name.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/convertModel.html","id":null,"dir":"Reference","previous_headings":"","what":"Internal: Convert second order cSEMModel — convertModel","title":"Internal: Convert second order cSEMModel — convertModel","text":"Uses cSEMModel containing second order constructs turns estimable model using either \"2stage\" approach \"mixed\" approach.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/convertModel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Internal: Convert second order cSEMModel — convertModel","text":"","code":"convertModel(  .csem_model        = NULL,   .approach_2ndorder = \"2stage\",  .stage             = \"first\"  )"},{"path":"https://floschuberth.github.io/cSEM/reference/convertModel.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Internal: Convert second order cSEMModel — convertModel","text":".csem_model (possibly incomplete) cSEMModel-list. .approach_2ndorder Character string. Approach used models containing second-order constructs. One : \"2stage\", \"mixed\". Defaults \"2stage\". .stage Character string. stage model needed . One \"first\" \"second\". Defaults \"first\".","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/convertModel.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Internal: Convert second order cSEMModel — convertModel","text":"cSEMModel list may passed function requiring .csem_model mandatory argument.","code":""},{"path":[]},{"path":"https://floschuberth.github.io/cSEM/reference/csem.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Composite-based SEM — csem","text":"","code":"csem( .data                  = NULL, .model                 = NULL, .approach_2ndorder     = c(\"2stage\", \"mixed\"), .approach_cor_robust   = c(\"none\", \"mcd\", \"spearman\"), .approach_nl           = c(\"sequential\", \"replace\"), .approach_paths        = c(\"OLS\", \"2SLS\"), .approach_weights      = c(\"PLS-PM\", \"SUMCORR\", \"MAXVAR\", \"SSQCORR\",                             \"MINVAR\", \"GENVAR\",\"GSCA\", \"PCA\",                            \"unit\", \"bartlett\", \"regression\"), .conv_criterion        = c(\"diff_absolute\", \"diff_squared\", \"diff_relative\"), .disattenuate          = TRUE, .dominant_indicators   = NULL, .estimate_structural   = TRUE, .id                    = NULL, .instruments           = NULL, .iter_max              = 100, .normality             = FALSE, .PLS_approach_cf       = c(\"dist_squared_euclid\", \"dist_euclid_weighted\",                             \"fisher_transformed\", \"mean_arithmetic\",                            \"mean_geometric\", \"mean_harmonic\",                            \"geo_of_harmonic\"), .PLS_ignore_structural_model = FALSE, .PLS_modes                   = NULL, .PLS_weight_scheme_inner     = c(\"path\", \"centroid\", \"factorial\"), .reliabilities         = NULL, .starting_values       = NULL, .resample_method       = c(\"none\", \"bootstrap\", \"jackknife\"), .resample_method2      = c(\"none\", \"bootstrap\", \"jackknife\"), .R                     = 499, .R2                    = 199, .handle_inadmissibles  = c(\"drop\", \"ignore\", \"replace\"), .user_funs             = NULL, .eval_plan             = c(\"sequential\", \"multicore\", \"multisession\"), .seed                  = NULL, .sign_change_option    = c(\"none\", \"individual\", \"individual_reestimate\",                             \"construct_reestimate\"), .tolerance             = 1e-05 )"},{"path":"https://floschuberth.github.io/cSEM/reference/csem.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Composite-based SEM — csem","text":".data data.frame matrix standardized unstandardized data (indicators/items/manifest variables). Additionally, list data sets (data frames matrices) accepted case estimation repeated data set. Possible column types classes data provided : \"logical\", \"numeric\" (\"double\" \"integer\"), \"factor\" (\"ordered\" /\"unordered\"), \"character\" (converted factor), mix several types. .model model lavaan model syntax cSEMModel list. .approach_2ndorder Character string. Approach used models containing second-order constructs. One : \"2stage\", \"mixed\". Defaults \"2stage\". .approach_cor_robust Character string. Approach used obtain robust indicator correlation matrix. One : \"none\" case standard Bravais-Pearson correlation used, \"spearman\" Spearman rank correlation, \"mcd\" via MASS::cov.rob() robust correlation matrix. Defaults \"none\". Note many postestimation procedures (testOMF() fit() implicitly assume continuous indicator correlation matrix (e.g. Bravais-Pearson correlation matrix). use know . .approach_nl Character string. Approach used estimate nonlinear structural relationships. One : \"sequential\" \"replace\". Defaults \"sequential\". .approach_paths Character string. Approach used estimate structural coefficients. One : \"OLS\" \"2SLS\". \"2SLS\", instruments need supplied .instruments. Defaults \"OLS\". .approach_weights Character string. Approach used obtain composite weights. One : \"PLS-PM\", \"SUMCORR\", \"MAXVAR\", \"SSQCORR\", \"MINVAR\", \"GENVAR\", \"GSCA\", \"PCA\", \"unit\", \"bartlett\", \"regression\". Defaults \"PLS-PM\". .conv_criterion Character string. criterion use convergence check. One : \"diff_absolute\", \"diff_squared\", \"diff_relative\". Defaults \"diff_absolute\". .disattenuate Logical. composite/proxy correlations disattenuated yield consistent loadings path estimates least one construct modeled common factor? Defaults TRUE. .dominant_indicators character vector \"construct_name\" = \"indicator_name\" pairs, \"indicator_name\" character string giving name dominant indicator \"construct_name\" character string corresponding construct name. Dominant indicators may specified subset constructs. Default NULL. .estimate_structural Logical. structural coefficients estimated? Defaults TRUE. .id Character string integer. character string giving name integer position column .data whose levels used split .data groups. Defaults NULL. .instruments named list vectors instruments. names list elements names dependent (LHS) constructs structural equation whose explanatory variables endogenous. vectors contain names instruments corresponding equation. Note exogenous variables given equation must supplied instruments . Defaults NULL. .iter_max Integer. maximum number iterations allowed. iter_max = 1 .approach_weights = \"PLS-PM\" one-step weights returned. algorithm exceeds specified number, weights iteration step .iter_max - 1  returned warning. Defaults 100. .normality Logical. joint normality \\([\\eta_{1:p}; \\zeta; \\epsilon]\\) assumed nonlinear model? See (Dijkstra Schermelleh-Engel 2014)  details. Defaults FALSE. Ignored model nonlinear. .PLS_approach_cf Character string. Approach used obtain correction factors PLSc. One : \"dist_squared_euclid\", \"dist_euclid_weighted\", \"fisher_transformed\", \"mean_arithmetic\", \"mean_geometric\", \"mean_harmonic\", \"geo_of_harmonic\". Defaults \"dist_squared_euclid\". Ignored .disattenuate = FALSE .approach_weights PLS-PM. .PLS_ignore_structural_model Logical. structural model ignored calculating inner weights PLS-PM algorithm? Defaults FALSE. Ignored .approach_weights PLS-PM. .PLS_modes Either named list specifying mode used construct form \"construct_name\" = mode, single character string giving mode used constructs, NULL. Possible choices mode : \"modeA\", \"modeB\", \"modeBNNLS\", \"unit\", \"PCA\", single integer vector fixed weights length indicators construct given \"construct_name\". single number provided identical using unit weights, weights rescaled related composite unit variance.  Defaults NULL. NULL appropriate mode according type construct used chosen. Ignored .approach_weight PLS-PM. .PLS_weight_scheme_inner Character string. inner weighting scheme used PLS-PM. One : \"centroid\", \"factorial\", \"path\". Defaults \"path\". Ignored .approach_weight PLS-PM. .reliabilities character vector \"name\" = value pairs, value number 0 1 \"name\" character string corresponding construct name, NULL. Reliabilities may given subset constructs. Defaults NULL case reliabilities estimated csem(). Currently, supported .approach_weights = \"PLS-PM\". .starting_values named list vectors list names construct names whose indicator weights user wishes set. vectors must named vectors \"indicator_name\" = value pairs, value (scaled unscaled) starting weight. Defaults NULL. .resample_method Character string. resampling method use. One : \"none\", \"bootstrap\" \"jackknife\". Defaults \"none\". .resample_method2 Character string. resampling method use resampling resample. One : \"none\", \"bootstrap\" \"jackknife\". \"bootstrap\" number draws provided via .R2. Currently, resampling resample required studentized confidence interval (\"CI_t_interval\") computed infer() function. Defaults \"none\". .R Integer. number bootstrap replications. Defaults 499. .R2 Integer. number bootstrap replications use resampling resample. Defaults 199. .handle_inadmissibles Character string. inadmissible results treated? One \"drop\", \"ignore\", \"replace\". \"drop\", replications/resamples yielding inadmissible result dropped (.e. number results returned potentially less .R). \"ignore\" results returned even replications yielded inadmissible results (.e. number results returned equal .R). \"replace\" resampling continues exactly .R admissible solutions. Depending frequency inadmissible solutions may significantly increase computing time. Defaults \"drop\". .user_funs function (named) list functions apply every resample. functions must take .object first argument (e.g., myFun <- function(.object, ...) {body---function}). Function output preferably (named) vector matrices also accepted. However, output vectorized (columnwise) case. See examples section details. .eval_plan Character string. evaluation plan use. One \"sequential\", \"multicore\", \"multisession\". two latter cases available cores used. Defaults \"sequential\". .seed Integer NULL. random seed use. Defaults NULL case arbitrary seed chosen. Note scope seed limited body function used . Hence, global seed altered! .sign_change_option Character string. sign change option used handle flipping signs resampling? One \"none\",\"individual\", \"individual_reestimate\", \"construct_reestimate\". Defaults \"none\". .tolerance Double. tolerance criterion convergence. Defaults 1e-05.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/csem.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Composite-based SEM — csem","text":"object class cSEMResults methods postestimation generics. Technically, call csem() results object least two class attributes. first class attribute always cSEMResults. second one cSEMResults_default, cSEMResults_multi, cSEMResults_2ndorder depends estimated model /type data provided .model .data arguments. third class attribute cSEMResults_resampled added resampling conducted. details see cSEMResults helpfile .","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/csem.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Composite-based SEM — csem","text":"Estimate linear, nonlinear, hierarchical multigroup structural equation models using composite-based approach. cSEM method approach involves linear compounds (scores/proxies/composites) observables (indicators/items/manifest variables) defined composite-based. See Get started section cSEM website general introduction composite-based SEM cSEM. csem() estimates linear, nonlinear, hierarchical  multigroup structural equation models using composite-based approach.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/csem.html","id":"data-and-model-","dir":"Reference","previous_headings":"","what":"Data and model:","title":"Composite-based SEM — csem","text":".data .model arguments required. .data must given matrix data.frame column names matching indicator names used model description. Alternatively, list data sets (matrices data frames) may provided case estimation repeated data set. Possible column types/classes data provided : \"logical\", \"numeric\" (\"double\" \"integer\"), \"factor\" (\"ordered\" /\"unordered\"), \"character\", mix several types. Character columns treated (unordered) factors. Depending type/class indicator data provided cSEM computes indicator correlation matrix different ways. See calculateIndicatorCor() details. current version .data must contain missing values. Future versions likely handle missing values well. provide model use lavaan model syntax. Note, however, cSEM currently supports \"standard\" lavaan model syntax (Types 1, 2, 3, 7 described help page). Therefore, specifying e.g., threshold scaling factors ignored. Alternatively, standardized (possibly incomplete) cSEMModel-list may supplied. See parseModel() details.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/csem.html","id":"weights-and-path-coefficients-","dir":"Reference","previous_headings":"","what":"Weights and path coefficients:","title":"Composite-based SEM — csem","text":"default weights estimated using partial least squares path modeling algorithm (\"PLS-PM\"). range alternative weighting algorithms may supplied .approach_weights. Currently, following approaches implemented (Default) Partial least squares path modeling (\"PLS-PM\"). algorithm can customized. See calculateWeightsPLS() details. Generalized structured component analysis (\"GSCA\") generalized structured component analysis uniqueness terms (GSCAm). algorithms can customized. See calculateWeightsGSCA() calculateWeightsGSCAm() details. Note GSCAm called indirectly model contains constructs modeled common factors .disattenuate = TRUE. See . Generalized canonical correlation analysis (GCCA), including \"SUMCORR\", \"MAXVAR\", \"SSQCORR\", \"MINVAR\", \"GENVAR\". Principal component analysis (\"PCA\") Factor score regression using sum scores (\"unit\"), regression (\"regression\") Bartlett scores (\"bartlett\") possible supply starting values weighting algorithm via .starting_values. argument accepts named list vectors list names construct names whose indicator weights user wishes set. vectors must named vectors \"indicator_name\" = value pairs, value starting weight. See examples section details. Composite-indicator composite-composite correlations properly disattenuated default yield consistent loadings, construct correlations, path coefficients concepts modeled common factor. PLS-PM disattenuation done using PLSc (Dijkstra Henseler 2015) . GSCA disattenuation done implicitly using GSCAm (Hwang et al. 2017) . Weights obtained GCCA, unit, regression, bartlett PCA disattenuated using Croon's approach (Croon 2002) . Disattenuation suppressed setting .disattenuate = FALSE. Note, however, quantities case inconsistent estimates construct level counterparts constructs structural model modeled common factor! default path coefficients estimated using ordinary least squares (.approach_path = \"OLS\"). linear models, two-stage least squares (\"2SLS\") available, however, instruments internal, .e., part structural model. Future versions add support external instruments possible. Instruments must supplied .instruments named list names list elements names dependent constructs structural equations whose explanatory variables believed endogenous. list consists vectors names instruments corresponding equation. Note exogenous variables given equation must supplied instruments . reliabilities known can supplied \"name\" = value pairs .reliabilities, value numeric value 0 1. Currently, supported \"PLS-PM\".","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/csem.html","id":"nonlinear-models-","dir":"Reference","previous_headings":"","what":"Nonlinear models:","title":"Composite-based SEM — csem","text":"model contains nonlinear terms csem() estimates polynomial structural equation model using non-iterative method moments approach described Dijkstra Schermelleh-Engel (2014) . Nonlinear terms include interactions exponential terms. latter described model syntax \"interaction \", e.g., xi^3 = xi.xi.xi. Currently exponential terms power three (e.g., three-way interactions cubic terms) allowed: - Single, e.g., eta1 - Quadratic, e.g., eta1.eta1 - Cubic, e.g., eta1.eta1.eta1 - Two-way interaction, e.g., eta1.eta2 - Three-way interaction, e.g., eta1.eta2.eta3 - Quadratic two-way interaction, e.g., eta1.eta1.eta3 current version package allows two kinds estimation: estimation reduced form equation (.approach_nl = \"replace\") sequential estimation (.approach_nl = \"sequential\", default). latter allow multivariate normality exogenous variables, .e., latent variables error terms. Distributional assumptions kept minimum (..d. sample population finite moments relevant order); higher order models, go beyond interaction, work version assumption far relevant moments concerned certain combinations measurement errors behave Gaussian. details see: Dijkstra Schermelleh-Engel (2014) .","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/csem.html","id":"models-containing-second-order-constructs","dir":"Reference","previous_headings":"","what":"Models containing second-order constructs","title":"Composite-based SEM — csem","text":"Second-order constructs specified using operators =~ <~. operators usually used indicators right-hand side. second-order constructs right-hand side variables constructs instead. c1, c2 constructs forming measuring higher-order construct, model look like : Currently, two approaches explicitly implemented: (Default) \"2stage\". (disjoint) two-stage approach proposed Agarwal Karahanna (2000) . Note default correction attenuation applied common factors involved modeling second-order constructs. instance, three-stage approach proposed Van Riel et al. (2017)  applied case second-order construct specified composite common factors. hand, common factors involved two-stage approach applied proposed Schuberth et al. (2020) . \"mixed\". mixed repeated indicators/two-stage approach proposed Ringle et al. (2012) . repeated indicators approach proposed Joereskog Wold (1982)  extension proposed Becker et al. (2012)  directly implemented simply require respecification  model. example repeated indicators approach require change model append repeated indicators data supplied .data. Note indicators need renamed case csem() allow one indicator attached multiple constructs. According extended approach indirect effects QUAL VAL via c1 c2 specified well.","code":"my_model <- \" # Structural model SAT  ~ QUAL VAL  ~ SAT  # Measurement/composite model QUAL =~ qual1 + qual2 SAT  =~ sat1 + sat2  c1 =~ x11 + x12 c2 =~ x21 + x22  # Second-order construct (in this case a second-order composite build by common # factors) VAL <~ c1 + c2 \" my_model <- \" # Structural model SAT  ~ QUAL VAL  ~ SAT  VAL ~ c1 + c2  # Measurement/composite model QUAL =~ qual1 + qual2 SAT  =~ sat1 + sat2 VAL  =~ x11_temp + x12_temp + x21_temp + x22_temp  c1 =~ x11 + x12 c2 =~ x21 + x22 \""},{"path":"https://floschuberth.github.io/cSEM/reference/csem.html","id":"multigroup-analysis","dir":"Reference","previous_headings":"","what":"Multigroup analysis","title":"Composite-based SEM — csem","text":"perform multigroup analysis provide either list data sets one data set containing group-identifier-column whose column name must provided .id. Values column taken levels factor interpreted group identifiers. csem() split data levels column run estimation level separately. Note, levels group-identifier-column , estimation runs required. can considerably slow estimation, especially resampling requested. latter generally faster use .eval_plan = \"multisession\" .eval_plan = \"multicore\".","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/csem.html","id":"inference-","dir":"Reference","previous_headings":"","what":"Inference:","title":"Composite-based SEM — csem","text":"Inference done via resampling. See resamplecSEMResults() infer() details.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/csem.html","id":"postestimation","dir":"Reference","previous_headings":"","what":"Postestimation","title":"Composite-based SEM — csem","text":"assess() Assess results using common quality criteria, e.g., reliability, fit measures, HTMT, R2 etc. infer() Calculate common inferential quantities, e.g., standard errors, confidence intervals. plot() Creates plot model. help file see plot.cSEMResults_default(). predict() Predict endogenous indicator scores compute common prediction metrics. summarize() Summarize results. Mainly called side-effect print method. verify() Verify/Check admissibility estimates. Tests performed using test-family functions. Currently following tests implemented: testCVPAT() Cross-validated predictive ability test proposed Liengaard et al. (2021) testOMF() Bootstrap-based test overall model fit based Beran Srivastava (1985) . testMICOM() Permutation-based test measurement invariance composites proposed Henseler et al. (2016) . testMGD() Several (mainly) permutation-based tests multi-group comparisons. testHausman() Regression-based Hausman test test endogeneity. miscellaneous postestimation functions belong -family functions. Currently three functions implemented: doIPMA() Performs importance-performance matrix analysis (IPMA). doNonlinearEffectsAnalysis() Perform nonlinear effects analysis described e.g., Spiller et al. (2013) doRedundancyAnalysis() Perform redundancy analysis (RA) proposed Hair et al. (2016)  reference Chin (1998)","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/csem.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Composite-based SEM — csem","text":"Agarwal R, Karahanna E (2000). “Time Flies Fun: Cognitive Absorption Beliefs Information Technology Usage.” MIS Quarterly, 24(4), 665. Becker J, Klein K, Wetzels M (2012). “Hierarchical Latent Variable Models PLS-SEM: Guidelines Using Reflective-Formative Type Models.” Long Range Planning, 45(5-6), 359–394. doi:10.1016/j.lrp.2012.10.001 . Beran R, Srivastava MS (1985). “Bootstrap Tests Confidence Regions Functions Covariance Matrix.” Annals Statistics, 13(1), 95–115. doi:10.1214/aos/1176346579 . Chin WW (1998). “Modern Methods Business Research.” Marcoulides GA (ed.), chapter Partial Least Squares Approach Structural Equation Modeling, 295–358. Mahwah, NJ: Lawrence Erlbaum. Croon MA (2002). “Using predicted latent scores general latent structure models.” Marcoulides GA, Moustaki (eds.), Latent Variable Latent Structure Models, chapter 10, 195–224. Lawrence Erlbaum. ISBN 080584046X, Pagination: 288. Dijkstra TK, Henseler J (2015). “Consistent Asymptotically Normal PLS Estimators Linear Structural Equations.” Computational Statistics & Data Analysis, 81, 10–23. Dijkstra TK, Schermelleh-Engel K (2014). “Consistent Partial Least Squares Nonlinear Structural Equation Models.” Psychometrika, 79(4), 585–604. Hair JF, Hult GTM, Ringle C, Sarstedt M (2016). Primer Partial Least Squares Structural Equation Modeling (PLS-SEM). Sage publications. Henseler J, Ringle CM, Sarstedt M (2016). “Testing Measurement Invariance Composites Using Partial Least Squares.” International Marketing Review, 33(3), 405–431. doi:10.1108/imr-09-2014-0304 . Hwang H, Takane Y, Jung K (2017). “Generalized structured component analysis uniqueness terms accommodating measurement error.” Frontiers Psychology, 8(2137), 1–12. Joereskog KG, Wold HO (1982). Systems Indirect Observation: Causality, Structure, Prediction - Part II, volume 139. North Holland. Liengaard BD, Sharma PN, Hult GTM, Jensen MB, Sarstedt M, Hair JF, Ringle CM (2021). “Prediction: Coveted, Yet Forsaken? Introducing Cross-Validated Predictive Ability Test Partial Least Squares Path Modeling.” Decision Sciences, 52(2), 362–392. Ringle CM, Sarstedt M, Straub D (2012). “Critical Look Use PLS-SEM MIS Quarterly.” MIS Quarterly, 36(1), iii–xiv. Schuberth F, Rademaker , Henseler J (2020). “Estimating assessing second-order constructs using PLS-PM: case composites composites.” Industrial Management & Data Systems, 120(12), 2211-2241. doi:10.1108/imds-12-2019-0642 . Spiller SA, Fitzsimons GJ, Lynch JG, Mcclelland GH (2013). “Spotlights, Floodlights, Magic Number Zero: Simple Effects Tests Moderated Regression.” Journal Marketing Research, 50(2), 277–288. doi:10.1509/jmr.12.0420 . Van Riel ACR, Henseler J, Kemeny , Sasovova Z (2017). “Estimating hierarchical constructs using Partial Least Squares: case second order composites factors.” Industrial Management & Data Systems, 117(3), 459–477. doi:10.1108/IMDS-07-2016-0286 .","code":""},{"path":[]},{"path":"https://floschuberth.github.io/cSEM/reference/csem.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Composite-based SEM — csem","text":"","code":"# =========================================================================== # Basic usage # =========================================================================== ### Linear model ------------------------------------------------------------ # Most basic usage requires a dataset and a model. We use the  #  `threecommonfactors` dataset.   ## Take a look at the dataset #?threecommonfactors  ## Specify the (correct) model model <- \" # Structural model eta2 ~ eta1 eta3 ~ eta1 + eta2  # (Reflective) measurement model eta1 =~ y11 + y12 + y13 eta2 =~ y21 + y22 + y23 eta3 =~ y31 + y32 + y33 \"  ## Estimate res <- csem(threecommonfactors, model)  ## Postestimation verify(res) #> ________________________________________________________________________________ #>  #> Verify admissibility: #>  #> \t admissible #>  #> Details: #>  #>   Code   Status    Description #>   1      ok        Convergence achieved                                    #>   2      ok        All absolute standardized loading estimates <= 1        #>   3      ok        Construct VCV is positive semi-definite                 #>   4      ok        All reliability estimates <= 1                          #>   5      ok        Model-implied indicator VCV is positive semi-definite   #> ________________________________________________________________________________ summarize(res)   #> ________________________________________________________________________________ #> ----------------------------------- Overview ----------------------------------- #>  #> \tGeneral information: #> \t------------------------ #> \tEstimation status                  = Ok #> \tNumber of observations             = 500 #> \tWeight estimator                   = PLS-PM #> \tInner weighting scheme             = \"path\" #> \tType of indicator correlation      = Pearson #> \tPath model estimator               = OLS #> \tSecond-order approach              = NA #> \tType of path model                 = Linear #> \tDisattenuated                      = Yes (PLSc) #>  #> \tConstruct details: #> \t------------------ #> \tName  Modeled as     Order         Mode       #>  #> \teta1  Common factor  First order   \"modeA\"    #> \teta2  Common factor  First order   \"modeA\"    #> \teta3  Common factor  First order   \"modeA\"    #>  #> ----------------------------------- Estimates ---------------------------------- #>  #> Estimated path coefficients: #> ============================ #>   Path           Estimate  Std. error   t-stat.   p-value #>   eta2 ~ eta1      0.6713          NA        NA        NA #>   eta3 ~ eta1      0.4585          NA        NA        NA #>   eta3 ~ eta2      0.3052          NA        NA        NA #>  #> Estimated loadings: #> =================== #>   Loading        Estimate  Std. error   t-stat.   p-value #>   eta1 =~ y11      0.6631          NA        NA        NA #>   eta1 =~ y12      0.6493          NA        NA        NA #>   eta1 =~ y13      0.7613          NA        NA        NA #>   eta2 =~ y21      0.5165          NA        NA        NA #>   eta2 =~ y22      0.7554          NA        NA        NA #>   eta2 =~ y23      0.7997          NA        NA        NA #>   eta3 =~ y31      0.8223          NA        NA        NA #>   eta3 =~ y32      0.6581          NA        NA        NA #>   eta3 =~ y33      0.7474          NA        NA        NA #>  #> Estimated weights: #> ================== #>   Weight         Estimate  Std. error   t-stat.   p-value #>   eta1 <~ y11      0.3956          NA        NA        NA #>   eta1 <~ y12      0.3873          NA        NA        NA #>   eta1 <~ y13      0.4542          NA        NA        NA #>   eta2 <~ y21      0.3058          NA        NA        NA #>   eta2 <~ y22      0.4473          NA        NA        NA #>   eta2 <~ y23      0.4735          NA        NA        NA #>   eta3 <~ y31      0.4400          NA        NA        NA #>   eta3 <~ y32      0.3521          NA        NA        NA #>   eta3 <~ y33      0.3999          NA        NA        NA #>  #> ------------------------------------ Effects ----------------------------------- #>  #> Estimated total effects: #> ======================== #>   Total effect    Estimate  Std. error   t-stat.   p-value #>   eta2 ~ eta1       0.6713          NA        NA        NA #>   eta3 ~ eta1       0.6634          NA        NA        NA #>   eta3 ~ eta2       0.3052          NA        NA        NA #>  #> Estimated indirect effects: #> =========================== #>   Indirect effect    Estimate  Std. error   t-stat.   p-value #>   eta3 ~ eta1          0.2049          NA        NA        NA #> ________________________________________________________________________________ assess(res) #> ________________________________________________________________________________ #>  #> \tConstruct        AVE           R2          R2_adj     #> \teta1           0.4803          NA            NA       #> \teta2           0.4923        0.4507        0.4496     #> \teta3           0.5559        0.4912        0.4892     #>  #> -------------- Common (internal consistency) reliability estimates ------------- #>  #> \tConstruct Cronbachs_alpha   Joereskogs_rho   Dijkstra-Henselers_rho_A  #> \teta1        0.7318           0.7339                0.7388           #> \teta2        0.7281           0.7380                0.7647           #> \teta3        0.7860           0.7884                0.7964           #>  #> ----------- Alternative (internal consistency) reliability estimates ----------- #>  #> \tConstruct       RhoC         RhoC_mm    RhoC_weighted #> \teta1           0.7339        0.7341        0.7388     #> \teta2           0.7380        0.7361        0.7647     #> \teta3           0.7884        0.7875        0.7964     #>  #> \tConstruct  RhoC_weighted_mm     RhoT      RhoT_weighted #> \teta1           0.7388        0.7318        0.7288     #> \teta2           0.7647        0.7281        0.7095     #> \teta3           0.7964        0.7860        0.7820     #>  #> --------------------------- Distance and fit measures -------------------------- #>  #> \tGeodesic distance             = 0.006013595 #> \tSquared Euclidean distance    = 0.01121567 #> \tML distance                   = 0.03203348 #>  #> \tChi_square       = 15.9847 #> \tChi_square_df    = 0.6660294 #> \tCFI              = 1 #> \tCN               = 1137.78 #> \tGFI              = 0.9920803 #> \tIFI              = 1.005614 #> \tNFI              = 0.9889886 #> \tNNFI             = 1 #> \tRMSEA            = 0 #> \tRMS_theta        = 0.1050618 #> \tSRMR             = 0.01578725 #>  #> \tDegrees of freedom       = 24 #>  #> --------------------------- Model selection criteria --------------------------- #>  #> \tConstruct        AIC          AICc          AICu      #> \teta2          -296.5459     205.5025      -294.5419   #> \teta3          -332.8544     169.2264      -329.8454   #>  #> \tConstruct        BIC           FPE           GM       #> \teta2          -288.1166      0.5526       511.4292    #> \teta3          -320.2106      0.5139       517.6438    #>  #> \tConstruct        HQ            HQc       Mallows_Cp   #> \teta2          -293.2383     -293.1793      3.0000     #> \teta3          -327.8930     -327.7823      5.0000     #>  #> ----------------------- Variance inflation factors (VIFs) ---------------------- #>  #>   Dependent construct: 'eta3' #>  #> \tIndependent construct    VIF value  #> \teta1                      1.8205    #> \teta2                      1.8205    #>  #> -------------------------- Effect sizes (Cohen's f^2) -------------------------- #>  #>   Dependent construct: 'eta2' #>  #> \tIndependent construct       f^2     #> \teta1                      0.8205    #>  #>   Dependent construct: 'eta3' #>  #> \tIndependent construct       f^2     #> \teta1                      0.2270    #> \teta2                      0.1005    #>  #> ----------------------- Discriminant validity assessment ----------------------- #>  #> \tHeterotrait-monotrait ratio of correlations matrix (HTMT matrix) #>  #>           eta1      eta2 eta3 #> eta1 1.0000000 0.0000000    0 #> eta2 0.6782752 1.0000000    0 #> eta3 0.6668841 0.6124418    1 #>  #>  #> \tAdvanced heterotrait-monotrait ratio of correlations matrix (HTMT2 matrix) #>  #>           eta1      eta2 eta3 #> eta1 1.0000000 0.0000000    0 #> eta2 0.6724003 1.0000000    0 #> eta3 0.6652760 0.5958725    1 #>  #>  #> \tFornell-Larcker matrix #>  #>           eta1      eta2      eta3 #> eta1 0.4802903 0.4506886 0.4400530 #> eta2 0.4506886 0.4922660 0.3757225 #> eta3 0.4400530 0.3757225 0.5559458 #>  #>  #> ------------------------------------ Effects ----------------------------------- #>  #> Estimated total effects: #> ======================== #>   Total effect    Estimate  Std. error   t-stat.   p-value #>   eta2 ~ eta1       0.6713          NA        NA        NA #>   eta3 ~ eta1       0.6634          NA        NA        NA #>   eta3 ~ eta2       0.3052          NA        NA        NA #>  #> Estimated indirect effects: #> =========================== #>   Indirect effect    Estimate  Std. error   t-stat.   p-value #>   eta3 ~ eta1          0.2049          NA        NA        NA #> ________________________________________________________________________________  # Notes:  #   1. By default no inferential quantities (e.g. Std. errors, p-values, or #      confidence intervals) are calculated. Use resampling to obtain #      inferential quantities. See \"Resampling\" in the \"Extended usage\" #      section below. #   2. `summarize()` prints the full output by default. For a more condensed #       output use: print(summarize(res), .full_output = FALSE) #> ________________________________________________________________________________ #> ----------------------------------- Overview ----------------------------------- #>  #> \tGeneral information: #> \t------------------------ #> \tEstimation status                  = Ok #> \tNumber of observations             = 500 #> \tWeight estimator                   = PLS-PM #> \tInner weighting scheme             = \"path\" #> \tType of indicator correlation      = Pearson #> \tPath model estimator               = OLS #> \tSecond-order approach              = NA #> \tType of path model                 = Linear #> \tDisattenuated                      = Yes (PLSc) #>  #> \tConstruct details: #> \t------------------ #> \tName  Modeled as     Order         Mode       #>  #> \teta1  Common factor  First order   \"modeA\"    #> \teta2  Common factor  First order   \"modeA\"    #> \teta3  Common factor  First order   \"modeA\"    #>  #> ----------------------------------- Estimates ---------------------------------- #>  #> Estimated path coefficients: #> ============================ #>   Path           Estimate  Std. error   t-stat.   p-value #>   eta2 ~ eta1      0.6713          NA        NA        NA #>   eta3 ~ eta1      0.4585          NA        NA        NA #>   eta3 ~ eta2      0.3052          NA        NA        NA #>  #> Estimated loadings: #> =================== #>   Loading        Estimate  Std. error   t-stat.   p-value #>   eta1 =~ y11      0.6631          NA        NA        NA #>   eta1 =~ y12      0.6493          NA        NA        NA #>   eta1 =~ y13      0.7613          NA        NA        NA #>   eta2 =~ y21      0.5165          NA        NA        NA #>   eta2 =~ y22      0.7554          NA        NA        NA #>   eta2 =~ y23      0.7997          NA        NA        NA #>   eta3 =~ y31      0.8223          NA        NA        NA #>   eta3 =~ y32      0.6581          NA        NA        NA #>   eta3 =~ y33      0.7474          NA        NA        NA #>  #> Estimated weights: #> ================== #>   Weight         Estimate  Std. error   t-stat.   p-value #>   eta1 <~ y11      0.3956          NA        NA        NA #>   eta1 <~ y12      0.3873          NA        NA        NA #>   eta1 <~ y13      0.4542          NA        NA        NA #>   eta2 <~ y21      0.3058          NA        NA        NA #>   eta2 <~ y22      0.4473          NA        NA        NA #>   eta2 <~ y23      0.4735          NA        NA        NA #>   eta3 <~ y31      0.4400          NA        NA        NA #>   eta3 <~ y32      0.3521          NA        NA        NA #>   eta3 <~ y33      0.3999          NA        NA        NA #> ________________________________________________________________________________  ## Dealing with endogeneity -------------------------------------------------  # See: ?testHausman()  ### Models containing second constructs-------------------------------------- ## Take a look at the dataset #?dgp_2ndorder_cf_of_c  model <- \" # Path model / Regressions  c4   ~ eta1 eta2 ~ eta1 + c4  # Reflective measurement model c1   <~ y11 + y12  c2   <~ y21 + y22 + y23 + y24 c3   <~ y31 + y32 + y33 + y34 + y35 + y36 + y37 + y38 eta1 =~ y41 + y42 + y43 eta2 =~ y51 + y52 + y53  # Composite model (second order) c4   =~ c1 + c2 + c3 \"  res_2stage <- csem(dgp_2ndorder_cf_of_c, model, .approach_2ndorder = \"2stage\") res_mixed  <- csem(dgp_2ndorder_cf_of_c, model, .approach_2ndorder = \"mixed\")  # The standard repeated indicators approach is done by 1.) respecifying the model # and 2.) adding the repeated indicators to the data set  # 1.) Respecify the model model_RI <- \" # Path model / Regressions  c4   ~ eta1 eta2 ~ eta1 + c4 c4   ~ c1 + c2 + c3  # Reflective measurement model c1   <~ y11 + y12  c2   <~ y21 + y22 + y23 + y24 c3   <~ y31 + y32 + y33 + y34 + y35 + y36 + y37 + y38 eta1 =~ y41 + y42 + y43 eta2 =~ y51 + y52 + y53  # c4 is a common factor measured by composites c4 =~ y11_temp + y12_temp + y21_temp + y22_temp + y23_temp + y24_temp +       y31_temp + y32_temp + y33_temp + y34_temp + y35_temp + y36_temp +        y37_temp + y38_temp \"  # 2.) Update data set data_RI <- dgp_2ndorder_cf_of_c coln <- c(colnames(data_RI), paste0(colnames(data_RI), \"_temp\")) data_RI <- data_RI[, c(1:ncol(data_RI), 1:ncol(data_RI))] colnames(data_RI) <- coln  # Estimate res_RI <- csem(data_RI, model_RI) summarize(res_RI) #> ________________________________________________________________________________ #> ----------------------------------- Overview ----------------------------------- #>  #> \tGeneral information: #> \t------------------------ #> \tEstimation status                  = Not ok! #> \tNumber of observations             = 500 #> \tWeight estimator                   = PLS-PM #> \tInner weighting scheme             = \"path\" #> \tType of indicator correlation      = Pearson #> \tPath model estimator               = OLS #> \tSecond-order approach              = NA #> \tType of path model                 = Linear #> \tDisattenuated                      = Yes (PLSc) #>  #> \tConstruct details: #> \t------------------ #> \tName  Modeled as     Order         Mode       #>  #> \teta1  Common factor  First order   \"modeA\"    #> \tc1    Composite      First order   \"modeB\"    #> \tc2    Composite      First order   \"modeB\"    #> \tc3    Composite      First order   \"modeB\"    #> \tc4    Common factor  First order   \"modeA\"    #> \teta2  Common factor  First order   \"modeA\"    #>  #> ----------------------------------- Estimates ---------------------------------- #>  #> Estimated path coefficients: #> ============================ #>   Path           Estimate  Std. error   t-stat.   p-value #>   c4 ~ eta1        0.0029          NA        NA        NA #>   c4 ~ c1          0.2333          NA        NA        NA #>   c4 ~ c2          0.4381          NA        NA        NA #>   c4 ~ c3          0.5448          NA        NA        NA #>   eta2 ~ eta1      0.0345          NA        NA        NA #>   eta2 ~ c4        0.5128          NA        NA        NA #>  #> Estimated loadings: #> =================== #>   Loading           Estimate  Std. error   t-stat.   p-value #>   eta1 =~ y41         0.9416          NA        NA        NA #>   eta1 =~ y42         0.7374          NA        NA        NA #>   eta1 =~ y43         0.5285          NA        NA        NA #>   c1 =~ y11           0.8999          NA        NA        NA #>   c1 =~ y12           0.7204          NA        NA        NA #>   c2 =~ y21           0.8041          NA        NA        NA #>   c2 =~ y22           0.7090          NA        NA        NA #>   c2 =~ y23           0.6563          NA        NA        NA #>   c2 =~ y24           0.6739          NA        NA        NA #>   c3 =~ y31           0.5380          NA        NA        NA #>   c3 =~ y32           0.6091          NA        NA        NA #>   c3 =~ y33           0.6759          NA        NA        NA #>   c3 =~ y34           0.4268          NA        NA        NA #>   c3 =~ y35           0.3482          NA        NA        NA #>   c3 =~ y36           0.6089          NA        NA        NA #>   c3 =~ y37           0.4549          NA        NA        NA #>   c3 =~ y38           0.6092          NA        NA        NA #>   c4 =~ y11_temp      0.6249          NA        NA        NA #>   c4 =~ y12_temp      0.4750          NA        NA        NA #>   c4 =~ y21_temp      0.6808          NA        NA        NA #>   c4 =~ y22_temp      0.5885          NA        NA        NA #>   c4 =~ y23_temp      0.5291          NA        NA        NA #>   c4 =~ y24_temp      0.5771          NA        NA        NA #>   c4 =~ y31_temp      0.4817          NA        NA        NA #>   c4 =~ y32_temp      0.5415          NA        NA        NA #>   c4 =~ y33_temp      0.5586          NA        NA        NA #>   c4 =~ y34_temp      0.3624          NA        NA        NA #>   c4 =~ y35_temp      0.3157          NA        NA        NA #>   c4 =~ y36_temp      0.5154          NA        NA        NA #>   c4 =~ y37_temp      0.4129          NA        NA        NA #>   c4 =~ y38_temp      0.5111          NA        NA        NA #>   eta2 =~ y51         0.7991          NA        NA        NA #>   eta2 =~ y52         0.8477          NA        NA        NA #>   eta2 =~ y53         0.7304          NA        NA        NA #>  #> Estimated weights: #> ================== #>   Weight            Estimate  Std. error   t-stat.   p-value #>   eta1 <~ y41         0.5052          NA        NA        NA #>   eta1 <~ y42         0.3957          NA        NA        NA #>   eta1 <~ y43         0.2836          NA        NA        NA #>   c1 <~ y11           0.7392          NA        NA        NA #>   c1 <~ y12           0.4648          NA        NA        NA #>   c2 <~ y21           0.4487          NA        NA        NA #>   c2 <~ y22           0.3168          NA        NA        NA #>   c2 <~ y23           0.2773          NA        NA        NA #>   c2 <~ y24           0.3452          NA        NA        NA #>   c3 <~ y31           0.2758          NA        NA        NA #>   c3 <~ y32           0.2653          NA        NA        NA #>   c3 <~ y33           0.2202          NA        NA        NA #>   c3 <~ y34           0.1587          NA        NA        NA #>   c3 <~ y35           0.1682          NA        NA        NA #>   c3 <~ y36           0.2495          NA        NA        NA #>   c3 <~ y37           0.2784          NA        NA        NA #>   c3 <~ y38           0.2238          NA        NA        NA #>   c4 <~ y11_temp      0.1510          NA        NA        NA #>   c4 <~ y12_temp      0.1148          NA        NA        NA #>   c4 <~ y21_temp      0.1645          NA        NA        NA #>   c4 <~ y22_temp      0.1422          NA        NA        NA #>   c4 <~ y23_temp      0.1279          NA        NA        NA #>   c4 <~ y24_temp      0.1395          NA        NA        NA #>   c4 <~ y31_temp      0.1164          NA        NA        NA #>   c4 <~ y32_temp      0.1309          NA        NA        NA #>   c4 <~ y33_temp      0.1350          NA        NA        NA #>   c4 <~ y34_temp      0.0876          NA        NA        NA #>   c4 <~ y35_temp      0.0763          NA        NA        NA #>   c4 <~ y36_temp      0.1246          NA        NA        NA #>   c4 <~ y37_temp      0.0998          NA        NA        NA #>   c4 <~ y38_temp      0.1235          NA        NA        NA #>   eta2 <~ y51         0.3873          NA        NA        NA #>   eta2 <~ y52         0.4109          NA        NA        NA #>   eta2 <~ y53         0.3540          NA        NA        NA #>  #> Estimated construct correlations: #> ================================= #>   Correlation    Estimate  Std. error   t-stat.   p-value #>   eta1 ~~ c1       0.2882          NA        NA        NA #>   eta1 ~~ c2       0.2527          NA        NA        NA #>   eta1 ~~ c3       0.2871          NA        NA        NA #>   c1 ~~ c2         0.5772          NA        NA        NA #>   c1 ~~ c3         0.6242          NA        NA        NA #>   c2 ~~ c3         0.7480          NA        NA        NA #>  #> Estimated indicator correlations: #> ================================= #>   Correlation    Estimate  Std. error   t-stat.   p-value #>   y11 ~~ y12       0.3459          NA        NA        NA #>   y21 ~~ y22       0.4341          NA        NA        NA #>   y21 ~~ y23       0.3805          NA        NA        NA #>   y21 ~~ y24       0.3255          NA        NA        NA #>   y22 ~~ y23       0.3260          NA        NA        NA #>   y22 ~~ y24       0.3102          NA        NA        NA #>   y23 ~~ y24       0.3043          NA        NA        NA #>   y31 ~~ y32       0.1558          NA        NA        NA #>   y31 ~~ y33       0.2728          NA        NA        NA #>   y31 ~~ y34      -0.1472          NA        NA        NA #>   y31 ~~ y35       0.1617          NA        NA        NA #>   y31 ~~ y36       0.3372          NA        NA        NA #>   y31 ~~ y37       0.0961          NA        NA        NA #>   y31 ~~ y38       0.2059          NA        NA        NA #>   y32 ~~ y33       0.2355          NA        NA        NA #>   y32 ~~ y34       0.4146          NA        NA        NA #>   y32 ~~ y35       0.2228          NA        NA        NA #>   y32 ~~ y36       0.2184          NA        NA        NA #>   y32 ~~ y37       0.2684          NA        NA        NA #>   y32 ~~ y38       0.0736          NA        NA        NA #>   y33 ~~ y34       0.2908          NA        NA        NA #>   y33 ~~ y35      -0.0586          NA        NA        NA #>   y33 ~~ y36       0.3445          NA        NA        NA #>   y33 ~~ y37       0.2018          NA        NA        NA #>   y33 ~~ y38       0.6233          NA        NA        NA #>   y34 ~~ y35       0.1723          NA        NA        NA #>   y34 ~~ y36       0.1704          NA        NA        NA #>   y34 ~~ y37       0.0729          NA        NA        NA #>   y34 ~~ y38       0.1916          NA        NA        NA #>   y35 ~~ y36       0.1125          NA        NA        NA #>   y35 ~~ y37      -0.1425          NA        NA        NA #>   y35 ~~ y38       0.3285          NA        NA        NA #>   y36 ~~ y37       0.1102          NA        NA        NA #>   y36 ~~ y38       0.2499          NA        NA        NA #>   y37 ~~ y38       0.0858          NA        NA        NA #>  #> ------------------------------------ Effects ----------------------------------- #>  #> Estimated total effects: #> ======================== #>   Total effect    Estimate  Std. error   t-stat.   p-value #>   c4 ~ eta1         0.0029          NA        NA        NA #>   c4 ~ c1           0.2333          NA        NA        NA #>   c4 ~ c2           0.4381          NA        NA        NA #>   c4 ~ c3           0.5448          NA        NA        NA #>   eta2 ~ eta1       0.0359          NA        NA        NA #>   eta2 ~ c1         0.1197          NA        NA        NA #>   eta2 ~ c2         0.2247          NA        NA        NA #>   eta2 ~ c3         0.2794          NA        NA        NA #>   eta2 ~ c4         0.5128          NA        NA        NA #>  #> Estimated indirect effects: #> =========================== #>   Indirect effect    Estimate  Std. error   t-stat.   p-value #>   eta2 ~ eta1          0.0015          NA        NA        NA #>   eta2 ~ c1            0.1197          NA        NA        NA #>   eta2 ~ c2            0.2247          NA        NA        NA #>   eta2 ~ c3            0.2794          NA        NA        NA #> ________________________________________________________________________________  ### Multigroup analysis -----------------------------------------------------  # See: ?testMGD()  # =========================================================================== # Extended usage # =========================================================================== # `csem()` provides defaults for all arguments except `.data` and `.model`. #   Below some common options/tasks that users are likely to be interested in. #   We use the threecommonfactors data set again:  model <- \" # Structural model eta2 ~ eta1 eta3 ~ eta1 + eta2  # (Reflective) measurement model eta1 =~ y11 + y12 + y13 eta2 =~ y21 + y22 + y23 eta3 =~ y31 + y32 + y33 \"  ### PLS vs PLSc and disattenuation # In the model all concepts are modeled as common factors. If  #   .approach_weights = \"PLS-PM\", csem() uses PLSc to disattenuate composite-indicator  #   and composite-composite correlations. res_plsc <- csem(threecommonfactors, model, .approach_weights = \"PLS-PM\") res$Information$Model$construct_type # all common factors #>            eta1            eta2            eta3  #> \"Common factor\" \"Common factor\" \"Common factor\"   # To obtain \"original\" (inconsistent) PLS estimates use `.disattenuate = FALSE` res_pls <- csem(threecommonfactors, model,                  .approach_weights = \"PLS-PM\",                 .disattenuate = FALSE                 )  s_plsc <- summarize(res_plsc) s_pls  <- summarize(res_pls)  # Compare data.frame(   \"Path\"      = s_plsc$Estimates$Path_estimates$Name,   \"Pop_value\" = c(0.6, 0.4, 0.35), # see ?threecommonfactors   \"PLSc\"      = s_plsc$Estimates$Path_estimates$Estimate,   \"PLS\"       = s_pls$Estimates$Path_estimates$Estimate   ) #>          Path Pop_value      PLSc       PLS #> 1 eta2 ~ eta1      0.60 0.6713334 0.5046062 #> 2 eta3 ~ eta1      0.40 0.4585068 0.3588557 #> 3 eta3 ~ eta2      0.35 0.3051511 0.2972680  ### Resampling -------------------------------------------------------------- if (FALSE) { # \\dontrun{ ## Basic resampling res_boot <- csem(threecommonfactors, model, .resample_method = \"bootstrap\") res_jack <- csem(threecommonfactors, model, .resample_method = \"jackknife\")  # See ?resamplecSEMResults for more examples  ### Choosing a different weightning scheme ----------------------------------  res_gscam  <- csem(threecommonfactors, model, .approach_weights = \"GSCA\") res_gsca   <- csem(threecommonfactors, model,                     .approach_weights = \"GSCA\",                    .disattenuate = FALSE )  s_gscam <- summarize(res_gscam) s_gsca  <- summarize(res_gsca)  # Compare data.frame(   \"Path\"      = s_gscam$Estimates$Path_estimates$Name,   \"Pop_value\" = c(0.6, 0.4, 0.35), # see ?threecommonfactors   \"GSCAm\"      = s_gscam$Estimates$Path_estimates$Estimate,   \"GSCA\"       = s_gsca$Estimates$Path_estimates$Estimate )} # } ### Fine-tuning a weighting scheme ------------------------------------------ ## Setting starting values  sv <- list(\"eta1\" = c(\"y12\" = 10, \"y13\" = 4, \"y11\" = 1)) res <- csem(threecommonfactors, model, .starting_values = sv)  ## Choosing a different inner weighting scheme  #?args_csem_dotdotdot  res <- csem(threecommonfactors, model, .PLS_weight_scheme_inner = \"factorial\",             .PLS_ignore_structural_model = TRUE)   ## Choosing different modes for PLS # By default, concepts modeled as common factors uses PLS Mode A weights. modes <- list(\"eta1\" = \"unit\", \"eta2\" = \"modeB\", \"eta3\" = \"unit\") res   <- csem(threecommonfactors, model, .PLS_modes = modes) summarize(res)  #> ________________________________________________________________________________ #> ----------------------------------- Overview ----------------------------------- #>  #> \tGeneral information: #> \t------------------------ #> \tEstimation status                  = Not ok! #> \tNumber of observations             = 500 #> \tWeight estimator                   = PLS-PM #> \tInner weighting scheme             = \"path\" #> \tType of indicator correlation      = Pearson #> \tPath model estimator               = OLS #> \tSecond-order approach              = NA #> \tType of path model                 = Linear #> \tDisattenuated                      = Yes (PLSc) #>  #> \tConstruct details: #> \t------------------ #> \tName  Modeled as     Order         Mode       #>  #> \teta1  Common factor  First order   \"unit\"     #> \teta2  Common factor  First order   \"modeB\"    #> \teta3  Common factor  First order   \"unit\"     #>  #> ----------------------------------- Estimates ---------------------------------- #>  #> Estimated path coefficients: #> ============================ #>   Path           Estimate  Std. error   t-stat.   p-value #>   eta2 ~ eta1      0.5700          NA        NA        NA #>   eta3 ~ eta1      0.2869          NA        NA        NA #>   eta3 ~ eta2      0.3840          NA        NA        NA #>  #> Estimated loadings: #> =================== #>   Loading        Estimate  Std. error   t-stat.   p-value #>   eta1 =~ y11      0.8017          NA        NA        NA #>   eta1 =~ y12      0.7907          NA        NA        NA #>   eta1 =~ y13      0.8278          NA        NA        NA #>   eta2 =~ y21      0.5143          NA        NA        NA #>   eta2 =~ y22      0.7570          NA        NA        NA #>   eta2 =~ y23      0.7999          NA        NA        NA #>   eta3 =~ y31      0.8603          NA        NA        NA #>   eta3 =~ y32      0.8216          NA        NA        NA #>   eta3 =~ y33      0.8286          NA        NA        NA #>  #> Estimated weights: #> ================== #>   Weight         Estimate  Std. error   t-stat.   p-value #>   eta1 <~ y11      0.4132          NA        NA        NA #>   eta1 <~ y12      0.4132          NA        NA        NA #>   eta1 <~ y13      0.4132          NA        NA        NA #>   eta2 <~ y21      0.1593          NA        NA        NA #>   eta2 <~ y22      0.4538          NA        NA        NA #>   eta2 <~ y23      0.5722          NA        NA        NA #>   eta3 <~ y31      0.3983          NA        NA        NA #>   eta3 <~ y32      0.3983          NA        NA        NA #>   eta3 <~ y33      0.3983          NA        NA        NA #>  #> ------------------------------------ Effects ----------------------------------- #>  #> Estimated total effects: #> ======================== #>   Total effect    Estimate  Std. error   t-stat.   p-value #>   eta2 ~ eta1       0.5700          NA        NA        NA #>   eta3 ~ eta1       0.5057          NA        NA        NA #>   eta3 ~ eta2       0.3840          NA        NA        NA #>  #> Estimated indirect effects: #> =========================== #>   Indirect effect    Estimate  Std. error   t-stat.   p-value #>   eta3 ~ eta1          0.2189          NA        NA        NA #> ________________________________________________________________________________"},{"path":"https://floschuberth.github.io/cSEM/reference/csem_arguments.html","id":null,"dir":"Reference","previous_headings":"","what":"cSEMArguments — csem_arguments","title":"cSEMArguments — csem_arguments","text":"alphabetical list arguments used functions cSEM package including description defaults. Mainly used internal purposes (parameter inheritance). list arguments defaults, use args_default(). list arguments possible choices, use args_default(.choices = TRUE).","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/csem_arguments.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"cSEMArguments — csem_arguments","text":".alpha integer numeric vector significance levels. Defaults 0.05. .absolute Logical. absolute HTMT values returned? Defaults TRUE . .approach_gcca Character string. Kettenring approach use GCCA. One \"SUMCORR\", \"MAXVAR\", \"SSQCORR\", \"MINVAR\" \"GENVAR\". Defaults \"SUMCORR\". .approach_2ndorder Character string. Approach used models containing second-order constructs. One : \"2stage\", \"mixed\". Defaults \"2stage\". .approach_alpha_adjust Character string. Approach used adjust significance level accommodate multiple testing. One \"none\" \"bonferroni\". Defaults \"none\". .approach_cor_robust Character string. Approach used obtain robust indicator correlation matrix. One : \"none\" case standard Bravais-Pearson correlation used, \"spearman\" Spearman rank correlation, \"mcd\" via MASS::cov.rob() robust correlation matrix. Defaults \"none\". Note many postestimation procedures (testOMF() fit() implicitly assume continuous indicator correlation matrix (e.g. Bravais-Pearson correlation matrix). use know . .approach_mgd Character string vector character strings. Approach used multi-group comparison. One : \"\", \"Klesel\", \"Chin\", \"Sarstedt\", \"Keil, \"Nitzl\", \"Henseler\", \"CI_para\", \"CI_overlap\". Default \"\" case approaches computed (possible). .approach_nl Character string. Approach used estimate nonlinear structural relationships. One : \"sequential\" \"replace\". Defaults \"sequential\". .approach_predict Character string. approach used predictions? One \"earliest\" \"direct\". \"earliest\" predictions indicators associated endogenous constructs performed using indicators associated exogenous constructs. \"direct\", predictions indicators associated endogenous constructs based indicators associated direct antecedents. Defaults \"earliest\". .approach_p_adjust Character string vector character strings. Approach used adjust p-value multiple testing. See methods argument stats::p.adjust() list choices description. Defaults \"none\". .approach_paths Character string. Approach used estimate structural coefficients. One : \"OLS\" \"2SLS\". \"2SLS\", instruments need supplied .instruments. Defaults \"OLS\". .approach_score_benchmark Character string. aggregation estimates truncated normal distribution done benchmark predictions? Ignored OrdPLS OrdPLSc used obtain benchmark predictions. One \"mean\", \"median\", \"mode\" \"round\". \"round\", benchmark predictions obtained using traditional prediction algorithm PLS-PM rounded categorical indicators. \"mean\", mean estimated endogenous indicators calculated. \"median\", mean estimated endogenous indicators calculated. \"mode\", maximum empirical density intervals defined thresholds used. .treat_as_continuous = TRUE indicators continuous scale, .approach_score_benchmark ignored. Defaults \"round\". .approach_score_target Character string. aggregation estimates truncated normal distribution predictions using OrdPLS/OrdPLSc done? One \"mean\", \"median\" \"mode\". \"mean\", mean estimated endogenous indicators calculated. \"median\", mean estimated endogenous indicators calculated. \"mode\", maximum empirical density intervals defined thresholds used. Defaults \"mean\". .approach_weights Character string. Approach used obtain composite weights. One : \"PLS-PM\", \"SUMCORR\", \"MAXVAR\", \"SSQCORR\", \"MINVAR\", \"GENVAR\", \"GSCA\", \"PCA\", \"unit\", \"bartlett\", \"regression\". Defaults \"PLS-PM\". .args_used list function argument names whose value modified user. .attrbutes Character string. Variables used attributes IPMA. .benchmark Character string. procedure obtain benchmark predictions. One \"lm\", \"unit\", \"PLS-PM\", \"GSCA\", \"PCA\", \"MAXVAR\", \"NA\". Default \"lm\". .bias_corrected Logical. standard tStat confidence interval bias-corrected using bootstrapped bias estimate? TRUE confidence interval estimated parameter theta centered 2*theta - theta*_hat, theta*_hat average .R bootstrap estimates theta. Defaults TRUE .by_equation criteria computed structural model equation separately? Defaults TRUE. .C (J x J) composite variance-covariance matrix. .check_errors Logical. model parse checked correctness sense necessary components estimate model given? Defaults TRUE. .choices Logical. candidate values arguments returned? Defaults FALSE. .ci vector character strings naming confidence interval compute. possible choices see infer(). .ci_colnames Internal argument used several print helper functions. .closed_form_ci Logical. closed-form confidence interval computed? Defaults FALSE. .conv_criterion Character string. criterion use convergence check. One : \"diff_absolute\", \"diff_squared\", \"diff_relative\". Defaults \"diff_absolute\". .csem_model (possibly incomplete) cSEMModel-list. .csem_resample list resulting call resamplecSEMResults(). .cv_folds Integer. number cross-validation folds use. Setting .cv_folds N (number observations) produces leave-one-cross-validation samples. Defaults 10. .data data.frame matrix standardized unstandardized data (indicators/items/manifest variables). Possible column types classes data provided : \"logical\", \"numeric\" (\"double\" \"integer\"), \"factor\" (\"ordered\" /\"unordered\"), \"character\" (converted factor), mix several types. .dependent Character string. name dependent variable. .disattenuate Logical. composite/proxy correlations disattenuated yield consistent loadings path estimates least one construct modeled common factor? Defaults TRUE. .dist Character string. distribution use critical value. One \"t\" Student's t-distribution \"z\" standard normal distribution. Defaults \"z\". .distance Character string. distance measure. One : \"geodesic\" \"squared_euclidean\". Defaults \"geodesic\". .df Character string. method obtaining degrees freedom. Choices \"type1\" \"type2\". Defaults \"type1\" . .dominant_indicators character vector \"construct_name\" = \"indicator_name\" pairs, \"indicator_name\" character string giving name dominant indicator \"construct_name\" character string corresponding construct name. Dominant indicators may specified subset constructs. Default NULL. .E (J x J) matrix inner weights. .effect Internal argument used helper printEffects(). .estimate_structural Logical. structural coefficients estimated? Defaults TRUE. .eval_plan Character string. evaluation plan use. One \"sequential\", \"multicore\", \"multisession\". two latter cases available cores used. Defaults \"sequential\". .filename Character string. file name. .first_resample list containing .R resamples based original data obtained resamplecSEMResults(). .fit_measures Logical. (EXPERIMENTAL) additional fit measures included? Defaults FALSE. .force Logical. .object resampled even contains resamples already?. Defaults FALSE. .full_output Logical. full output summarize printed. Defaults TRUE. .graph_attrs Character string. Additional attributes passed DiagrammeR syntax, e.g., c(\"rankdir=LR\", \"ranksep=1.0\"). Defaults c(\"rankdir=LR\"). .H (N x J) matrix construct scores. .handle_inadmissibles Character string. inadmissible results treated? One \"drop\", \"ignore\", \"replace\". \"drop\", replications/resamples yielding inadmissible result dropped (.e. number results returned potentially less .R). \"ignore\" results returned even replications yielded inadmissible results (.e. number results returned equal .R). \"replace\" resampling continues exactly .R admissible solutions. Depending frequency inadmissible solutions may significantly increase computing time. Defaults \"drop\". .id Character string integer. character string giving name integer position column .data whose levels used split .data groups. Defaults NULL. .inference Logical. critical values computed? Defaults FALSE. .independent Character string. name independent variable. .instruments named list vectors instruments. names list elements names dependent (LHS) constructs structural equation whose explanatory variables endogenous. vectors contain names instruments corresponding equation. Note exogenous variables given equation must supplied instruments . Defaults NULL. .iter_max Integer. maximum number iterations allowed. iter_max = 1 .approach_weights = \"PLS-PM\" one-step weights returned. algorithm exceeds specified number, weights iteration step .iter_max - 1  returned warning. Defaults 100. .level Character. Used plot.cSEMIPMA indicate whether IPMA done constructs indicators. .matrix1 matrix compare. .matrix2 matrix compare. .matrices list least two matrices. .metrics Character string vector character strings. prediction metrics displayed? One : \"MAE\", \"RMSE\", \"Q2\", \"MER\", \"MAPE, \"MSE2\", \"U1\", \"U2\", \"UM\", \"UR\", \"UD\". Default c(\"MAE\", \"RMSE\", \"Q2\"). .model model lavaan model syntax cSEMModel list. .moderator Character string. name moderator variable. .modes vector giving mode construct form \"name\" = \"mode\". used internally. .ms_criterion Character string. Either single character string vector character strings naming model selection criterion compute. Defaults \"\". .n Integer. number observations original data. .n_steps Integer. value giving number steps (spotlights, .e., values .moderator surface analysis floodlight analysis) minimum maximum value moderator. Defaults 100. .normality Logical. joint normality \\([\\eta_{1:p}; \\zeta; \\epsilon]\\) assumed nonlinear model? See (Dijkstra Schermelleh-Engel 2014)  details. Defaults FALSE. Ignored model nonlinear. .nr_comparisons Integer. number comparisons. Defaults NULL. .null_model Logical. degrees freedom null model computed? Defaults FALSE. .object R object class cSEMResults resulting call csem(). .object1 R object class cSEMResults resulting call csem(). .object2 R object class cSEMResults resulting call csem(). .only_common_factors Logical. concepts modeled common factors included calculating one following quality criteria: AVE, Fornell-Larcker criterion, HTMT, reliability estimates. Defaults TRUE. .only_structural log-likelihood based structural model? Ignored .by_equation == TRUE. Defaults TRUE. .original_arguments list arguments used within csem(). .output_type Character string. type output return. One \"complete\" \"structured\". See Value section details. Defaults \"complete\". .P (J x J) construct variance-covariance matrix (possibly disattenuated). .parameters_to_compare model lavaan model syntax indicating parameters (.e, path (~), loadings (=~), weights (<~), correlations (~~)) compared across groups. Defaults NULL case weights, loadings path coefficients originally specified model compared. .path Character string. Path directory save file . Defaults NULL. .path_coefficients List. list contains resampled original path coefficient estimates. Typically part cSEMResults_resampled object. Defaults NULL. .PLS_approach_cf Character string. Approach used obtain correction factors PLSc. One : \"dist_squared_euclid\", \"dist_euclid_weighted\", \"fisher_transformed\", \"mean_arithmetic\", \"mean_geometric\", \"mean_harmonic\", \"geo_of_harmonic\". Defaults \"dist_squared_euclid\". Ignored .disattenuate = FALSE .approach_weights PLS-PM. .plot_correlations Character string. Specify correlations plotted, .e., exogenous constructs (exo), exogenous constructs indicators (), (none). Defaults exo. .plot_labels Logical. Whether display edge labels. Defaults TRUE. .plot_package Character string. Indicates packages used plotting. .plot_significances Logical. p-values form stars plotted? Defaults TRUE. .plot_structural_model_only Logical. structural model, .e., constructs relationships plotted? Defaults FALSE. .plot_type Character string. Indicates type plot produced. .PLS_ignore_structural_model Logical. structural model ignored calculating inner weights PLS-PM algorithm? Defaults FALSE. Ignored .approach_weights PLS-PM. .PLS_modes Either named list specifying mode used construct form \"construct_name\" = mode, single character string giving mode used constructs, NULL. Possible choices mode : \"modeA\", \"modeB\", \"modeBNNLS\", \"unit\", \"PCA\", single integer vector fixed weights length indicators construct given \"construct_name\". single number provided identical using unit weights, weights rescaled related composite unit variance.  Defaults NULL. NULL appropriate mode according type construct used chosen. Ignored .approach_weight PLS-PM. .PLS_weight_scheme_inner Character string. inner weighting scheme used PLS-PM. One : \"centroid\", \"factorial\", \"path\". Defaults \"path\". Ignored .approach_weight PLS-PM. .probs vector probabilities. .postestimation_object object resulting call one cSEM's postestimation functions (e.g. summarize()). .quality_criterion Character string. single character string vector character strings naming quality criterion compute. See Details section list possible candidates. Defaults \"\" case possible quality criteria computed. .quantity Character string. statistic returned? One \"\", \"mean\", \"sd\", \"bias\", \"CI_standard_z\", \"CI_standard_t\", \"CI_percentile\", \"CI_basic\", \"CI_bc\", \"CI_bca\", \"CI_t_interval\" Defaults \"\" case quantities require additional resampling returned, .e., quantities \"CI_bca\", \"CI_t_interval\". .Q vector composite-construct correlations element names equal names J construct names used measurement model. Note Q^2 also called reliability coefficient. .reliabilities character vector \"name\" = value pairs, value number 0 1 \"name\" character string corresponding construct name, NULL. Reliabilities may given subset constructs. Defaults NULL case reliabilities estimated csem(). Currently, supported .approach_weights = \"PLS-PM\". .resample_method Character string. resampling method use. One : \"none\", \"bootstrap\" \"jackknife\". Defaults \"none\". .resample_method2 Character string. resampling method use resampling resample. One : \"none\", \"bootstrap\" \"jackknife\". \"bootstrap\" number draws provided via .R2. Currently, resampling resample required studentized confidence interval (\"CI_t_interval\") computed infer() function. Defaults \"none\". `.resample_object` R object class cSEMResults_resampled obtained resamplecSEMResults() setting .resample_method = \"bootstrap\" \"jackknife\" calling csem(). .resample_sarstedt matrix containing parameter estimates potentially compared id column indicating group adherence row. .r Integer. number repetitions use. Defaults 1. .R Integer. number bootstrap replications. Defaults 499. .R2 Integer. number bootstrap replications use resampling resample. Defaults 199. .R_bootstrap Integer. number bootstrap runs. Ignored .object contains resamples. Defaults 499 .R_permutation Integer. number permutations. Defaults 499 .S (K x K) empirical indicator correlation matrix. .saturated Logical. saturated structural model used? Defaults FALSE. .second_resample list containing .R2 resamples .R resamples first run. .seed Integer NULL. random seed use. Defaults NULL case arbitrary seed chosen. Note scope seed limited body function used . Hence, global seed altered! .sign_change_option Character string. sign change option used handle flipping signs resampling? One \"none\",\"individual\", \"individual_reestimate\", \"construct_reestimate\". Defaults \"none\". .sim_points Integer. many samples truncated normal distribution simulated estimate exogenous construct scores? Defaults \"100\". .stage Character string. stage model needed . One \"first\" \"second\". Defaults \"first\". .standardized Logical. standardized scores returned? Defaults TRUE. .starting_values named list vectors list names construct names whose indicator weights user wishes set. vectors must named vectors \"indicator_name\" = value pairs, value (scaled unscaled) starting weight. Defaults NULL. .steps_mod numeric vector. Steps used moderator variable calculating simple effects independent variable dependent variable. Defaults NULL. .terms vector construct names classified. .test_data matrix test data column names training data. .testtype Character string. One \"twosided\" (H1: models perform equally predicting indicators belonging endogenous constructs)\" onesided\" (H1: Model 1 performs better predicting indicators belonging .title Character string. Title object. Defaults \"\". .tolerance Double. tolerance criterion convergence. Defaults 1e-05. .treat_as_continuous Logical. indicators benchmark predictions treated continuous? TRUE indicators treated continuous PLS-PM/PLSc applied. FALSE OrdPLS/OrdPLSc applied. Defaults TRUE. .type_gfi Character string. fitting function GFI based ? One \"ML\" maximum likelihood fitting function, \"GLS\" generalized least squares fitting function \"ULS\" unweighted least squares fitting function (squared Euclidean distance). Defaults \"ML\". .type_ci Character string. confidence interval calculated? possible choices, see .quantity argument infer() function. used .approch_mgd one \"CI_para\" \"CI_overlap\". Ignored otherwise. Defaults \"CI_percentile\". .type_htmt Character string indicating type HTMT calculated, .e., original HTMT (\"htmt\") HTMT2 (\"htmt2\"). Defaults \"htmt\" .type_vcv Character string. model-implied correlation matrix calculated? One \"indicator\" \"construct\". Defaults \"indicator\". .verbose Logical. information (e.g., progress bar) printed console? Defaults TRUE. .user_funs function (named) list functions apply every resample. functions must take .object first argument (e.g., myFun <- function(.object, ...) {body---function}). Function output preferably (named) vector matrices also accepted. However, output vectorized (columnwise) case. See examples section details. .value_independent Integer. required floodlight analysis; value independent variable case appears higher-order term. .values_moderator numeric vector. values moderator simple effects analysis. Typically difference mean (=0) measured standard deviations. Defaults c(-2, -1, 0, 1, 2). .vcv_asymptotic Logical. asymptotic variance-covariance matrix used, .e., VCV(b0) - VCV(b1)= VCV(b1-b0), VCV(b1-b0) computed directly? Defaults FALSE. .vector1 vector numeric values. .vector2 vector numeric values. .W (J x K) matrix weights. .Internal argument used several print helper functions. .W_new (J x K) matrix weights. .W_old (J x K) matrix weights. .weighted Logical. estimation based score uses weights weight approach used obtain .object?. Defaults FALSE. .X matrix processed data (scaled, cleaned ordered). .X_cleaned data.frame processed data (cleaned ordered). Note: X_cleaned may scaled!","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/csem_model.html","id":null,"dir":"Reference","previous_headings":"","what":"cSEMModel — csem_model","title":"cSEMModel — csem_model","text":"cSEMModel","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/csem_model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"cSEMModel — csem_model","text":"object class cSEMModel standardized list containing following components. J stands number constructs K number indicators. $structural matrix mimicking structural relationship constructs. constructs linearly related, structural dimension (J x J) row- column names equal construct names. structural model contains nonlinear relationships structural (J x (J + J*)) J* number nonlinear terms. Rows ordered exogenous constructs always first, followed constructs depend exogenous constructs /previously ordered constructs. $measurement (J x K) matrix mimicking measurement/composite relationship constructs related indicators. Rows order matrix $structural row names equal construct names. order columns $measurement forms block diagonal matrix. $error_cor (K x K) matrix mimicking measurement error correlation relationship. row column order identical column order $measurement. $cor_specified matrix indicating correlation relationships variables model specified user. Mainly internal purposes. Note $cor_specified may also contain inadmissible correlations correlation measurement errors indicators constructs. $construct_type named vector containing names construct respective type (\"Common factor\" \"Composite\"). $construct_order named vector containing names construct respective order (\"First order\" \"Second order\"). $model_type type model (\"Linear\" \"Nonlinear\"). $instruments instruments supplied: list structural equations relating endogenous RHS variables instruments. $indicators names indicators (.e., observed variables /first-order constructs) $cons_exo names exogenous constructs structural model (.e., variables appear LHS structural equation) $cons_endo names endogenous constructs structural model (.e., variables appear LHS least one structural equation) $vars_2nd names constructs modeled second orders. $vars_attached_to_2nd names constructs forming building second order construct. $vars_not_attached_to_2nd names constructs forming building second order construct. possible supply incomplete list parseModel(), resulting incomplete cSEMModel list can passed functions require .csem_model mandatory argument. Currently, structural measurement matrix required. However, specifying incomplete cSEMModel list may lead unexpected behavior errors. Use care.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/csem_model.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"cSEMModel — csem_model","text":"standardized list containing model-related information. convert model written lavaan model syntax cSEMModel list use parseModel().","code":""},{"path":[]},{"path":"https://floschuberth.github.io/cSEM/reference/csem_results.html","id":null,"dir":"Reference","previous_headings":"","what":"cSEMResults — csem_results","title":"cSEMResults — csem_results","text":"call csem() results object least two class attributes. first class attribute always cSEMResults matter type data model provided. second one cSEMResults_default, cSEMResults_multi, cSEMResults_2ndorder depends estimated model /type data provided .model .data arguments csem(). third class attribute cSEMResults_resampled added resampling conducted.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/csem_results.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"cSEMResults — csem_results","text":"Depending type data /model provided three different output types exists. _default structure vast majority applications. data single matrix data.frame id-column, result list elements: $Estimates list containing list estimated quantities. $Information list containing list additional information. resulting object classes cSEMResults cSEMResults_default. _multi data provided single matrix data.frame containing id-column split data G group levels list G datasets provided, resulting object list G lists, G equal number groups number datasets list datasets provided. G list elements cSEMResults_default object. Hence structure identical structure described _default. resulting object classes cSEMResults cSEMResults_multi. _2ndorder special output generated model estimate contains hierarchical constructs \"2stage\" \"mixed\" approach used estimate model. case resulting object list containing two elements First_stage  Second_stage. list element cSEMResults_default object. Hence structure identical structure described _default. .resample_method = \"bootstrap\" .resample_method = \"jackknife\", resamples attached object. objects class cSEMResults_default resamples attached .object$Estimates$Estimates_resample. objects class cSEMResults_multi done group. objects class cSEMResults_2ndorder resamples attached .object$Second_stage$Information$Resamples. objects containing elements gain cSEMResults_resampled class.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/csem_summary.html","id":null,"dir":"Reference","previous_headings":"","what":"cSEMSummarize — csem_summary","title":"cSEMSummarize — csem_summary","text":"cSEMSummarize","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/csem_summary.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"cSEMSummarize — csem_summary","text":"object class cSEMSummary. Technically cSEMSummary named list containing following list elements: `... finished yet.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/csem_test.html","id":null,"dir":"Reference","previous_headings":"","what":"cSEMTest — csem_test","title":"cSEMTest — csem_test","text":"cSEMTest","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/csem_test.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"cSEMTest — csem_test","text":"standardized list class cSEMTest. Technically cSEMTest named list containing following list elements: $Test_statistic value test statistic(s). $Critical_value critical value(s). $Decision test decision. One : Reject reject $Number_admissibles number admissible runs. See verify() constitutes inadmissible run.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/dgp_2ndorder_cf_of_c.html","id":null,"dir":"Reference","previous_headings":"","what":"Data: Second order common factor of composites — dgp_2ndorder_cf_of_c","title":"Data: Second order common factor of composites — dgp_2ndorder_cf_of_c","text":"dataset containing 500 standardized observations 19 indicator generated population model 6 concepts, three (c1-c3) composites forming second order common factor (c4). remaining two (eta1, eta2) concepts modeled common factors .","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/dgp_2ndorder_cf_of_c.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Data: Second order common factor of composites — dgp_2ndorder_cf_of_c","text":"","code":"dgp_2ndorder_cf_of_c"},{"path":"https://floschuberth.github.io/cSEM/reference/dgp_2ndorder_cf_of_c.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Data: Second order common factor of composites — dgp_2ndorder_cf_of_c","text":"matrix 500 rows 19 variables: y11-y12 Indicators attached  c1. Population weights : 0.8; 0.4. Population loadings : 0.925; 0.65 y21-y24 Indicators attached  c2. Population weights : 0.5; 0.3; 0.2; 0.4. Population loadings : 0.804; 0.68; 0.554; 0.708 y31-y38 Indicators attached  c3. Population weights : 0.3; 0.3; 0.1; 0.1; 0.2; 0.3; 0.4; 0.2. Population loadings : 0.496; 0.61; 0.535; 0.391; 0.391; 0.6; 0.5285; 0.53 y41-y43 Indicators attached  eta1. Population loadings : 0.8; 0.7; 0.7 y51-y53 Indicators attached  eta1. Population loadings : 0.8; 0.8; 0.7 model : $$`c4` = gamma1 * `eta1` + zeta1$$ $$`eta2` = gamma2 * `eta1` + beta * `c4` + zeta2$$ population values gamma1 = 0.6, gamma2 = 0.4 beta = 0.35. second order common factor $$`c4` = lambdac1 * `c1` + lambdac2 * `c2` + lambdac3 * `c3` + epsilon$$","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/distance_measures.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate difference between S and Sigma_hat — distance_measures","title":"Calculate difference between S and Sigma_hat — distance_measures","text":"Calculate difference empirical (S) model-implied indicator variance-covariance matrix (Sigma_hat) using different distance measures.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/distance_measures.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate difference between S and Sigma_hat — distance_measures","text":"","code":"calculateDG(   .object = NULL,   .matrix1 = NULL,   .matrix2 = NULL,   .saturated = FALSE,   ... )  calculateDL(   .object = NULL,   .matrix1 = NULL,   .matrix2 = NULL,   .saturated = FALSE,   ... )  calculateDML(   .object = NULL,   .matrix1 = NULL,   .matrix2 = NULL,   .saturated = FALSE,   ... )"},{"path":"https://floschuberth.github.io/cSEM/reference/distance_measures.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate difference between S and Sigma_hat — distance_measures","text":".object R object class cSEMResults resulting call csem(). .matrix1 matrix compare. .matrix2 matrix compare. .saturated Logical. saturated structural model used? Defaults FALSE. ... Ignored.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/distance_measures.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate difference between S and Sigma_hat — distance_measures","text":"single numeric value giving distance two matrices.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/distance_measures.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Calculate difference between S and Sigma_hat — distance_measures","text":"distances may also computed two matrices B supplying B directly via .matrix1 .matrix2 arguments. B supplied .object ignored.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/distance_measures.html","id":"functions","dir":"Reference","previous_headings":"","what":"Functions","title":"Calculate difference between S and Sigma_hat — distance_measures","text":"calculateDG(): geodesic distance (dG). calculateDL(): squared Euclidean distance calculateDML(): distance measure (fit function) used ML","code":""},{"path":[]},{"path":"https://floschuberth.github.io/cSEM/reference/doIPMA.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Do an importance-performance matrix analysis — doIPMA","text":"","code":"doIPMA(.object)"},{"path":"https://floschuberth.github.io/cSEM/reference/doIPMA.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Do an importance-performance matrix analysis — doIPMA","text":".object cSEMResults object.`","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/doIPMA.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Do an importance-performance matrix analysis — doIPMA","text":"list class cSEMIPA corresponding method plot(). See: plot.cSEMIPMA().","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/doIPMA.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Do an importance-performance matrix analysis — doIPMA","text":"Performs importance-performance matrix analysis (IPMA). calculate performance importance, weights indicators unstandardized using standard deviation original indicators normed length 1. Normed construct scores calculated based original indicators unstandardized weights. importance calculated mean original indicators unstandardized construct scores, respectively. performance calculated unstandardized total effect .level == \"construct\" normed weight times unstandardized total effect .level == \"indicator\". literature recommends use estimation input `doIPMA() based normed indicators, e.g., scaling indicators 0 100, see e.g., Henseler (2021); Ringle Sarstedt (2016) . Note, indicators normed internally, theoretical maximum/minimum can differ empirical maximum/minimum lead incorrect normalization.","code":""},{"path":[]},{"path":[]},{"path":"https://floschuberth.github.io/cSEM/reference/doNonlinearEffectsAnalysis.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Do a nonlinear effects analysis — doNonlinearEffectsAnalysis","text":"","code":"doNonlinearEffectsAnalysis(  .object            = NULL,  .dependent         = NULL,   .independent       = NULL,  .moderator         = NULL,  .n_steps           = 100,  .values_moderator  = c(-2, -1, 0, 1, 2),  .value_independent = 0,  .alpha             = 0.05  )"},{"path":"https://floschuberth.github.io/cSEM/reference/doNonlinearEffectsAnalysis.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Do a nonlinear effects analysis — doNonlinearEffectsAnalysis","text":".object R object class cSEMResults resulting call csem(). .dependent Character string. name dependent variable. .independent Character string. name independent variable. .moderator Character string. name moderator variable. .n_steps Integer. value giving number steps (spotlights, .e., values .moderator surface analysis floodlight analysis) minimum maximum value moderator. Defaults 100. .values_moderator numeric vector. values moderator simple effects analysis. Typically difference mean (=0) measured standard deviations. Defaults c(-2, -1, 0, 1, 2). .value_independent Integer. required floodlight analysis; value independent variable case appears higher-order term. .alpha integer numeric vector significance levels. Defaults 0.05.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/doNonlinearEffectsAnalysis.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Do a nonlinear effects analysis — doNonlinearEffectsAnalysis","text":"list class cSEMNonlinearEffects corresponding method plot(). See: plot.cSEMNonlinearEffects().","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/doNonlinearEffectsAnalysis.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Do a nonlinear effects analysis — doNonlinearEffectsAnalysis","text":"Calculate expected value dependent variable conditional values independent variables moderator variable. variables model assumed zero, .e., fixed mean levels. Moreover, produces input floodlight analysis.","code":""},{"path":[]},{"path":"https://floschuberth.github.io/cSEM/reference/doNonlinearEffectsAnalysis.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Do a nonlinear effects analysis — doNonlinearEffectsAnalysis","text":"","code":"if (FALSE) { # \\dontrun{ model_Int <- \" # Measurement models INV =~ INV1 + INV2 + INV3 +INV4 SAT =~ SAT1 + SAT2 + SAT3 INT =~ INT1 + INT2  # Structrual model containing an interaction term. INT ~ INV + SAT + INV.SAT \"    # Estimate model out <- csem(.data = Switching, .model = model_Int,             # ADANCO settings             .PLS_weight_scheme_inner = 'factorial',             .tolerance = 1e-06,             .resample_method = 'bootstrap' )    # Do nonlinear effects analysis neffects <- doNonlinearEffectsAnalysis(out,                                         .dependent = 'INT',                                        .moderator = 'INV',                                        .independent = 'SAT')   # Get an overview neffects  # Simple effects plot plot(neffects, .plot_type = 'simpleeffects')  # Surface plot using plotly plot(neffects, .plot_type = 'surface', .plot_package = 'plotly')  # Surface plot using persp plot(neffects, .plot_type = 'surface', .plot_package = 'persp')  # Floodlight analysis plot(neffects, .plot_type = 'floodlight') } # }"},{"path":[]},{"path":"https://floschuberth.github.io/cSEM/reference/doRedundancyAnalysis.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Do a redundancy analysis — doRedundancyAnalysis","text":"","code":"doRedundancyAnalysis(.object = NULL)"},{"path":"https://floschuberth.github.io/cSEM/reference/doRedundancyAnalysis.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Do a redundancy analysis — doRedundancyAnalysis","text":".object R object class cSEMResults resulting call csem().","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/doRedundancyAnalysis.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Do a redundancy analysis — doRedundancyAnalysis","text":"named numeric vector correlations. weighting approach used obtain .object \"PLS-PM\" non PLS outer modes mode B, function silently returns NA.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/doRedundancyAnalysis.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Do a redundancy analysis — doRedundancyAnalysis","text":"Perform redundancy analysis (RA) proposed Hair et al. (2016)  reference Chin (1998) . RA confined PLS-PM, specifically PLS-PM least one construct whose weights obtained mode B. cSEM case construct modeled composite argument .PLS_modes explicitly set mode B least one construct. Hence RA conducted .approach_weights = \"PLS-PM\" least one construct's mode mode B. principal idea RA take two different measures construct regress scores obtained measure . similar likely measure \"thing\" taken evidence measurement models actually measure supposed measure (validity). several issues terminology  reasoning behind logic. RA therefore implemented since reviewers likely demand computation, however, actual application validity assessment discouraged. Currently, function applicable models containing second-order constructs.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/doRedundancyAnalysis.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Do a redundancy analysis — doRedundancyAnalysis","text":"Chin WW (1998). “Modern Methods Business Research.” Marcoulides GA (ed.), chapter Partial Least Squares Approach Structural Equation Modeling, 295–358. Mahwah, NJ: Lawrence Erlbaum. Hair JF, Hult GTM, Ringle C, Sarstedt M (2016). Primer Partial Least Squares Structural Equation Modeling (PLS-SEM). Sage publications.","code":""},{"path":[]},{"path":"https://floschuberth.github.io/cSEM/reference/estimatePath.html","id":null,"dir":"Reference","previous_headings":"","what":"Internal: Estimate the structural coefficients — estimatePath","title":"Internal: Estimate the structural coefficients — estimatePath","text":"Estimates coefficients structural model (nonlinear linear) using OLS, 2SLS. latter currently work linear models .","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/estimatePath.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Internal: Estimate the structural coefficients — estimatePath","text":"","code":"estimatePath(  .approach_nl      = args_default()$.approach_nl,  .approach_paths   = args_default()$.approach_paths,  .csem_model       = args_default()$.csem_model,  .H                = args_default()$.H,  .normality        = args_default()$.normality,  .P                = args_default()$.P,  .Q                = args_default()$.Q  )"},{"path":"https://floschuberth.github.io/cSEM/reference/estimatePath.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Internal: Estimate the structural coefficients — estimatePath","text":".approach_nl Character string. Approach used estimate nonlinear structural relationships. One : \"sequential\" \"replace\". Defaults \"sequential\". .approach_paths Character string. Approach used estimate structural coefficients. One : \"OLS\" \"2SLS\". \"2SLS\", instruments need supplied .instruments. Defaults \"OLS\". .csem_model (possibly incomplete) cSEMModel-list. .H (N x J) matrix construct scores. .normality Logical. joint normality \\([\\eta_{1:p}; \\zeta; \\epsilon]\\) assumed nonlinear model? See (Dijkstra Schermelleh-Engel 2014)  details. Defaults FALSE. Ignored model nonlinear. .P (J x J) construct variance-covariance matrix (possibly disattenuated). .Q vector composite-construct correlations element names equal names J construct names used measurement model. Note Q^2 also called reliability coefficient.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/estimatePath.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Internal: Estimate the structural coefficients — estimatePath","text":"named list containing estimated structural coefficients, R2, adjusted R2, VIFs regression.","code":""},{"path":[]},{"path":"https://floschuberth.github.io/cSEM/reference/exportToExcel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Export to Excel (.xlsx) — exportToExcel","text":"","code":"exportToExcel(   .postestimation_object = NULL,    .filename              = \"results.xlsx\",   .path                  = NULL   )"},{"path":"https://floschuberth.github.io/cSEM/reference/exportToExcel.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Export to Excel (.xlsx) — exportToExcel","text":".postestimation_object object resulting call one cSEM's postestimation functions (e.g. summarize()). .filename Character string. file name. .path Character string. Path directory save file . Defaults NULL.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/exportToExcel.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Export to Excel (.xlsx) — exportToExcel","text":"Export results postestimation functions assess(), predict(), summarize() testOMF() .xlsx (Excel) file. function uses openxlsx package depend Java! function deliberately kept simple: takes relevant elements .postestimation_object writes (worksheet worksheet) .xlsx file named .filename directory given .path (current working directory default). .postestimation_object class attribute _2ndorder two .xlsx files named \".filename_first_stage.xlsx\" \".filename_second_stage.xlsx\" created. .postestimation_object list appropriate objects, one file list elements created. Note: rerunning exportToExcel() without changing .filename .path overwrites file!","code":""},{"path":[]},{"path":"https://floschuberth.github.io/cSEM/reference/firstOrderMeasurementEdges.html","id":null,"dir":"Reference","previous_headings":"","what":"Internal: firstOrderMeasurementEdges — firstOrderMeasurementEdges","title":"Internal: firstOrderMeasurementEdges — firstOrderMeasurementEdges","text":"Build measurement edges first–order model.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/firstOrderMeasurementEdges.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Internal: firstOrderMeasurementEdges — firstOrderMeasurementEdges","text":"","code":"firstOrderMeasurementEdges(     construct,     weights,     loadings,     weight_p_values,     loading_p_values,     plot_signif,     plot_labels,     constructTypes     )"},{"path":"https://floschuberth.github.io/cSEM/reference/firstOrderMeasurementEdges.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Internal: firstOrderMeasurementEdges — firstOrderMeasurementEdges","text":"plot_labels Logical. Whether display edge labels. Defaults TRUE.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/firstOrderMeasurementEdges.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Internal: firstOrderMeasurementEdges — firstOrderMeasurementEdges","text":"Character string containing DOT code.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/fit.html","id":null,"dir":"Reference","previous_headings":"","what":"Model-implied indicator or construct variance-covariance matrix — fit","title":"Model-implied indicator or construct variance-covariance matrix — fit","text":"Calculate model-implied indicator construct variance-covariance (VCV) matrix. Currently model-implied VCV recursive linear models implemented (including models containing second order constructs).","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/fit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Model-implied indicator or construct variance-covariance matrix — fit","text":"","code":"fit(   .object    = NULL,    .saturated = args_default()$.saturated,   .type_vcv  = args_default()$.type_vcv   )"},{"path":"https://floschuberth.github.io/cSEM/reference/fit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Model-implied indicator or construct variance-covariance matrix — fit","text":".object R object class cSEMResults resulting call csem(). .saturated Logical. saturated structural model used? Defaults FALSE. .type_vcv Character string. model-implied correlation matrix calculated? One \"indicator\" \"construct\". Defaults \"indicator\".","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/fit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Model-implied indicator or construct variance-covariance matrix — fit","text":"Either (K x K) matrix (J x J) matrix depending type_vcv.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/fit.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Model-implied indicator or construct variance-covariance matrix — fit","text":"Notation taken Bollen (1989) . .saturated = TRUE model-implied variance-covariance matrix calculated saturated structural model (.e., VCV constructs replaced correlation matrix). Hence: V(eta) = WSW' (possibly disattenuated).","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/fit.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Model-implied indicator or construct variance-covariance matrix — fit","text":"Bollen KA (1989). Structural Equations Latent Variables. Wiley-Interscience. ISBN 978-0471011712.","code":""},{"path":[]},{"path":"https://floschuberth.github.io/cSEM/reference/fit_measures.html","id":null,"dir":"Reference","previous_headings":"","what":"Model fit measures — fit_measures","title":"Model fit measures — fit_measures","text":"Calculate fit measures.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/fit_measures.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Model fit measures — fit_measures","text":"","code":"calculateChiSquare(.object, .saturated = FALSE)  calculateChiSquareDf(.object)  calculateCFI(.object)  calculateGFI(.object, .type_gfi = c(\"ML\", \"GLS\", \"ULS\"), ...)  calculateCN(.object, .alpha = 0.05, ...)  calculateIFI(.object)  calculateNFI(.object)  calculateNNFI(.object)  calculateRMSEA(.object)  calculateRMSTheta(.object)  calculateSRMR(   .object = NULL,   .matrix1 = NULL,   .matrix2 = NULL,   .saturated = FALSE,   ... )"},{"path":"https://floschuberth.github.io/cSEM/reference/fit_measures.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Model fit measures — fit_measures","text":".object R object class cSEMResults resulting call csem(). .saturated Logical. saturated structural model used? Defaults FALSE. .type_gfi Character string. fitting function GFI based ? One \"ML\" maximum likelihood fitting function, \"GLS\" generalized least squares fitting function \"ULS\" unweighted least squares fitting function (squared Euclidean distance). Defaults \"ML\". ... Ignored. .alpha integer numeric vector significance levels. Defaults 0.05. .matrix1 matrix compare. .matrix2 matrix compare.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/fit_measures.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Model fit measures — fit_measures","text":"single numeric value.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/fit_measures.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Model fit measures — fit_measures","text":"See Fit indices section cSEM website details implementation.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/fit_measures.html","id":"functions","dir":"Reference","previous_headings":"","what":"Functions","title":"Model fit measures — fit_measures","text":"calculateChiSquare(): chi square statistic. calculateChiSquareDf(): Chi square statistic divided degrees freedom. calculateCFI(): comparative fit index (CFI). calculateGFI(): goodness fit index (GFI). calculateCN(): Hoelter index alias Hoelter's (critical) N (CN). calculateIFI(): incremental fit index (IFI). calculateNFI(): normed fit index (NFI). calculateNNFI(): non-normed fit index (NNFI). Also called Tucker-Lewis index (TLI). calculateRMSEA(): root mean square error approximation (RMSEA). calculateRMSTheta(): root mean squared residual covariance matrix outer model residuals (RMS theta). calculateSRMR(): standardized root mean square residual (SRMR).","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/foreman.html","id":null,"dir":"Reference","previous_headings":"","what":"Internal: Composite-based SEM — foreman","title":"Internal: Composite-based SEM — foreman","text":"central hub cSEM package. acts like foreman collecting (estimation) tasks, distributing lower level package functions, eventually recollecting results. called csem() manage actual calculations. may called directly user, however, cases likely convenient use csem() instead.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/foreman.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Internal: Composite-based SEM — foreman","text":"","code":"foreman(   .data                        = args_default()$.data,   .model                       = args_default()$.model,   .approach_cor_robust         = args_default()$.approach_cor_robust,   .approach_nl                 = args_default()$.approach_nl,   .approach_paths              = args_default()$.approach_paths,   .approach_weights            = args_default()$.approach_weights,   .conv_criterion              = args_default()$.conv_criterion,   .disattenuate                = args_default()$.disattenuate,   .dominant_indicators         = args_default()$.dominant_indicators,   .estimate_structural         = args_default()$.estimate_structural,   .id                          = args_default()$.id,   .instruments                 = args_default()$.instruments,   .iter_max                    = args_default()$.iter_max,   .normality                   = args_default()$.normality,   .PLS_approach_cf             = args_default()$.PLS_approach_cf,   .PLS_ignore_structural_model = args_default()$.PLS_ignore_structural_model,   .PLS_modes                   = args_default()$.PLS_modes,   .PLS_weight_scheme_inner     = args_default()$.PLS_weight_scheme_inner,   .reliabilities               = args_default()$.reliabilities,   .starting_values             = args_default()$.starting_values,   .tolerance                   = args_default()$.tolerance   )"},{"path":"https://floschuberth.github.io/cSEM/reference/foreman.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Internal: Composite-based SEM — foreman","text":".data data.frame matrix standardized unstandardized data (indicators/items/manifest variables). Possible column types classes data provided : \"logical\", \"numeric\" (\"double\" \"integer\"), \"factor\" (\"ordered\" /\"unordered\"), \"character\" (converted factor), mix several types. .model model lavaan model syntax cSEMModel list. .approach_cor_robust Character string. Approach used obtain robust indicator correlation matrix. One : \"none\" case standard Bravais-Pearson correlation used, \"spearman\" Spearman rank correlation, \"mcd\" via MASS::cov.rob() robust correlation matrix. Defaults \"none\". Note many postestimation procedures (testOMF() fit() implicitly assume continuous indicator correlation matrix (e.g. Bravais-Pearson correlation matrix). use know . .approach_nl Character string. Approach used estimate nonlinear structural relationships. One : \"sequential\" \"replace\". Defaults \"sequential\". .approach_paths Character string. Approach used estimate structural coefficients. One : \"OLS\" \"2SLS\". \"2SLS\", instruments need supplied .instruments. Defaults \"OLS\". .approach_weights Character string. Approach used obtain composite weights. One : \"PLS-PM\", \"SUMCORR\", \"MAXVAR\", \"SSQCORR\", \"MINVAR\", \"GENVAR\", \"GSCA\", \"PCA\", \"unit\", \"bartlett\", \"regression\". Defaults \"PLS-PM\". .conv_criterion Character string. criterion use convergence check. One : \"diff_absolute\", \"diff_squared\", \"diff_relative\". Defaults \"diff_absolute\". .disattenuate Logical. composite/proxy correlations disattenuated yield consistent loadings path estimates least one construct modeled common factor? Defaults TRUE. .dominant_indicators character vector \"construct_name\" = \"indicator_name\" pairs, \"indicator_name\" character string giving name dominant indicator \"construct_name\" character string corresponding construct name. Dominant indicators may specified subset constructs. Default NULL. .estimate_structural Logical. structural coefficients estimated? Defaults TRUE. .id Character string integer. character string giving name integer position column .data whose levels used split .data groups. Defaults NULL. .instruments named list vectors instruments. names list elements names dependent (LHS) constructs structural equation whose explanatory variables endogenous. vectors contain names instruments corresponding equation. Note exogenous variables given equation must supplied instruments . Defaults NULL. .iter_max Integer. maximum number iterations allowed. iter_max = 1 .approach_weights = \"PLS-PM\" one-step weights returned. algorithm exceeds specified number, weights iteration step .iter_max - 1  returned warning. Defaults 100. .normality Logical. joint normality \\([\\eta_{1:p}; \\zeta; \\epsilon]\\) assumed nonlinear model? See (Dijkstra Schermelleh-Engel 2014)  details. Defaults FALSE. Ignored model nonlinear. .PLS_approach_cf Character string. Approach used obtain correction factors PLSc. One : \"dist_squared_euclid\", \"dist_euclid_weighted\", \"fisher_transformed\", \"mean_arithmetic\", \"mean_geometric\", \"mean_harmonic\", \"geo_of_harmonic\". Defaults \"dist_squared_euclid\". Ignored .disattenuate = FALSE .approach_weights PLS-PM. .PLS_ignore_structural_model Logical. structural model ignored calculating inner weights PLS-PM algorithm? Defaults FALSE. Ignored .approach_weights PLS-PM. .PLS_modes Either named list specifying mode used construct form \"construct_name\" = mode, single character string giving mode used constructs, NULL. Possible choices mode : \"modeA\", \"modeB\", \"modeBNNLS\", \"unit\", \"PCA\", single integer vector fixed weights length indicators construct given \"construct_name\". single number provided identical using unit weights, weights rescaled related composite unit variance.  Defaults NULL. NULL appropriate mode according type construct used chosen. Ignored .approach_weight PLS-PM. .PLS_weight_scheme_inner Character string. inner weighting scheme used PLS-PM. One : \"centroid\", \"factorial\", \"path\". Defaults \"path\". Ignored .approach_weight PLS-PM. .reliabilities character vector \"name\" = value pairs, value number 0 1 \"name\" character string corresponding construct name, NULL. Reliabilities may given subset constructs. Defaults NULL case reliabilities estimated csem(). Currently, supported .approach_weights = \"PLS-PM\". .starting_values named list vectors list names construct names whose indicator weights user wishes set. vectors must named vectors \"indicator_name\" = value pairs, value (scaled unscaled) starting weight. Defaults NULL. .tolerance Double. tolerance criterion convergence. Defaults 1e-05.","code":""},{"path":[]},{"path":[]},{"path":"https://floschuberth.github.io/cSEM/reference/getConstructScores.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get construct scores — getConstructScores","text":"","code":"getConstructScores(  .object        = NULL,  .standardized  = TRUE  )"},{"path":"https://floschuberth.github.io/cSEM/reference/getConstructScores.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get construct scores — getConstructScores","text":".object R object class cSEMResults resulting call csem(). .standardized Logical. standardized scores returned? Defaults TRUE.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/getConstructScores.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get construct scores — getConstructScores","text":"list three elements Construct_scores, W_used, Indicators_used.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/getConstructScores.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Get construct scores — getConstructScores","text":"Get standardized unstandardized construct scores.","code":""},{"path":[]},{"path":"https://floschuberth.github.io/cSEM/reference/getParameterNames.html","id":null,"dir":"Reference","previous_headings":"","what":"Internal: Parameter names — getParameterNames","title":"Internal: Parameter names — getParameterNames","text":"Based model lavaan model syntax, returns names parameters structural model, measurement/composite model weight relationship. Used testMGD() extract names parameters compare across groups according test proposed Chin Dibbern (2010) .","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/getParameterNames.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Internal: Parameter names — getParameterNames","text":"","code":"getParameterNames(            .object  = args_default()$.object,            .model   = args_default()$.model   )"},{"path":"https://floschuberth.github.io/cSEM/reference/getParameterNames.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Internal: Parameter names — getParameterNames","text":".object R object class cSEMResults resulting call csem(). .model model lavaan model syntax indicating parameters (.e, path (~), loadings (=~), weights (<~)) compared across groups. Defaults NULL case parameters model compared.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/getParameterNames.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Internal: Parameter names — getParameterNames","text":"list elements names_path, names_loadings, names_weights containing names structural parameters, loadings, weight compare across groups.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/getParameterNames.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Internal: Parameter names — getParameterNames","text":"Chin WW, Dibbern J (2010). “Introduction Permutation Based Procedure Multi-Group PLS Analysis: Results Tests Differences Simulated Data Cross Cultural Analysis Sourcing Information System Services Germany USA.” Handbook Partial Least Squares, 171–193. Springer Berlin Heidelberg. doi:10.1007/978-3-540-32827-8_8 .","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/getRelevantParameters.html","id":null,"dir":"Reference","previous_headings":"","what":"Internal: Extract relevant parameters from several cSEMResults_multi — getRelevantParameters","title":"Internal: Extract relevant parameters from several cSEMResults_multi — getRelevantParameters","text":"Extract relevant parameters cSEMResult_multi object .object.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/getRelevantParameters.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Internal: Extract relevant parameters from several cSEMResults_multi — getRelevantParameters","text":"","code":"getRelevantParameters(   .object     = args_default()$.object,   .model      = args_default()$.model )"},{"path":"https://floschuberth.github.io/cSEM/reference/getRelevantParameters.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Internal: Extract relevant parameters from several cSEMResults_multi — getRelevantParameters","text":".object R object class cSEMResults resulting call csem(). .model model lavaan model syntax indicating parameters (.e., path (~), loadings (=~), weights (<~)) compared across groups. Defaults NULL case parameters model compared.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/getRelevantParameters.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Internal: Extract relevant parameters from several cSEMResults_multi — getRelevantParameters","text":"list length equal number groups .object. list element list three. first list element contains relevant parameter estimates structural model, second list element relevant estimated loadings, third relevant estimated weights.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/getValuesFloodlight.html","id":null,"dir":"Reference","previous_headings":"","what":"Internal: Helper for doNonlinearEffectsAnalysis() — getValuesFloodlight","title":"Internal: Helper for doNonlinearEffectsAnalysis() — getValuesFloodlight","text":"Function calculates values required floodlight analysis, namely 1) partial effect independent variable dependent variable bootstrap run original estimation step moderator 2) alpha/2 1-alpha/2 quantile bootstrap estimates.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/getValuesFloodlight.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Internal: Helper for doNonlinearEffectsAnalysis() — getValuesFloodlight","text":"","code":"getValuesFloodlight(   .model = NULL,   .path_coefficients = args_default()$.path_coefficients,   .dependent = args_default()$.dependent,   .independent = args_default()$.independent,   .moderator = args_default()$.moderator,   .steps_mod = args_default()$.steps_mod,   .value_independent = args_default()$.value_independent,   .alpha = args_default()$.alpha )"},{"path":"https://floschuberth.github.io/cSEM/reference/getValuesFloodlight.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Internal: Helper for doNonlinearEffectsAnalysis() — getValuesFloodlight","text":".model model lavaan model syntax cSEMModel list. .path_coefficients List. list contains resampled original path coefficient estimates. Typically part cSEMResults_resampled object. Defaults NULL. .dependent Character string. name dependent variable. .independent Character string. name independent variable. .moderator Character string. name moderator variable. .steps_mod numeric vector. Steps used moderator variable calculating simple effects independent variable dependent variable. Defaults NULL. .value_independent Integer. required floodlight analysis; value independent variable case appears higher-order term. .alpha integer numeric vector significance levels. Defaults 0.05.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/getValuesFloodlight.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Internal: Helper for doNonlinearEffectsAnalysis() — getValuesFloodlight","text":"variables comprise independent variable taken account. contains variable independent variable moderator effect set zero variables evaluated means (=0), hence effect zero.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/get_significance_stars.html","id":null,"dir":"Reference","previous_headings":"","what":"Internal: get significance stars — get_significance_stars","title":"Internal: get significance stars — get_significance_stars","text":"Transforms p-value stars.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/get_significance_stars.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Internal: get significance stars — get_significance_stars","text":"","code":"get_significance_stars( .pvalue )"},{"path":"https://floschuberth.github.io/cSEM/reference/get_significance_stars.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Internal: get significance stars — get_significance_stars","text":"Character string. p-value transformed star.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/get_significance_stars.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Internal: get significance stars — get_significance_stars","text":".pvalue Numeric. p-value transformed significance stars.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/handleArgs.html","id":null,"dir":"Reference","previous_headings":"","what":"Internal: Handle arguments — handleArgs","title":"Internal: Handle arguments — handleArgs","text":"Internal helper function handle arguments passed function within cSEM.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/handleArgs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Internal: Handle arguments — handleArgs","text":"","code":"handleArgs(.args_used)"},{"path":"https://floschuberth.github.io/cSEM/reference/handleArgs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Internal: Handle arguments — handleArgs","text":".args_used list argument names user picked values.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/handleArgs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Internal: Handle arguments — handleArgs","text":"args_default list, default values changed values given user.","code":""},{"path":[]},{"path":"https://floschuberth.github.io/cSEM/reference/infer.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Inference — infer","text":"","code":"infer(  .object            = NULL,  .quantity          = c(\"all\", \"mean\", \"sd\", \"bias\", \"CI_standard_z\",                          \"CI_standard_t\", \"CI_percentile\", \"CI_basic\",                          \"CI_bc\", \"CI_bca\", \"CI_t_interval\"),  .alpha             = 0.05,  .bias_corrected    = TRUE )"},{"path":"https://floschuberth.github.io/cSEM/reference/infer.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Inference — infer","text":".object R object class cSEMResults resulting call csem(). .quantity Character string. statistic returned? One \"\", \"mean\", \"sd\", \"bias\", \"CI_standard_z\", \"CI_standard_t\", \"CI_percentile\", \"CI_basic\", \"CI_bc\", \"CI_bca\", \"CI_t_interval\" Defaults \"\" case quantities require additional resampling returned, .e., quantities \"CI_bca\", \"CI_t_interval\". .alpha integer numeric vector significance levels. Defaults 0.05. .bias_corrected Logical. standard tStat confidence interval bias-corrected using bootstrapped bias estimate? TRUE confidence interval estimated parameter theta centered 2*theta - theta*_hat, theta*_hat average .R bootstrap estimates theta. Defaults TRUE","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/infer.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Inference — infer","text":"list class cSEMInfer.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/infer.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Inference — infer","text":"Calculate common inferential quantities. users interested estimated standard errors, t-values, p-values /confidences intervals path, weight loading estimates, calling summarize() directly usually convenient much user-friendly print method. infer() useful comparing different confidence interval estimates. infer() convenience wrapper around number internal functions compute particular inferential quantity, .e., value set values used statistical inference. cSEM relies resampling (bootstrap jackknife) basis computation e.g., standard errors confidence intervals. Consequently, infer() requires resamples work. Technically, cSEMResults object used call infer() must therefore also class attribute cSEMResults_resampled. object provided user contain resamples yet, infer() obtain bootstrap resamples first. Naturally, computation take longer case. infer() much possible  background. Hence, every time infer() called cSEMResults object quantities chosen user automatically computed every estimated parameter contained object. default possible quantities computed (.quantity = ). following table list available inferential quantities alongside brief description. Implementation terminology confidence intervals based Hesterberg (2015)  Davison Hinkley (1997) . \"mean\", \"sd\" mean standard deviation M resample estimates generic statistic parameter. \"bias\" difference resample mean original estimate generic statistic parameter. \"CI_standard_z\" \"CI_standard_t\" standard confidence interval generic statistic parameter standard errors estimated resample standard deviation. \"CI_standard_z\" assumes standard normally distributed statistic, \"CI_standard_t\" assumes t-statistic N - 1 degrees freedom. \"CI_percentile\" percentile confidence interval. lower upper bounds confidence interval estimated alpha 1-alpha quantiles distribution resample estimates. \"CI_basic\" basic confidence interval also called reverse bootstrap percentile confidence interval. See Hesterberg (2015)  details. \"CI_bc\" bias corrected (Bc) confidence interval. See Davison Hinkley (1997)  details. \"CI_bca\" bias-corrected accelerated (Bca) confidence interval. Requires additional jackknife resampling compute influence values. See Davison Hinkley (1997)  details. \"CI_t_interval\" \"studentized\" t-confidence interval. based bootstrap resamples interval also called bootstrap t-interval confidence interval. See Hesterberg (2015)  page 381. Requires resamples resamples. See resamplecSEMResults(). default, studendized t-interval confidence interval bias-corrected accelerated confidence interval calculated. reason excluding quantities default require additional resampling step. former requires jackknife estimates compute influence values latter requires double bootstrap. can potentially time consuming. Hence, computation triggered explicitly chosen.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/infer.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Inference — infer","text":"Davison AC, Hinkley DV (1997). Bootstrap Methods Application. Cambridge University Press. doi:10.1017/cbo9780511802843 . Hesterberg TC (2015). “Teachers Know Bootstrap: Resampling Undergraduate Statistics Curriculum.” American Statistician, 69(4), 371–386. doi:10.1080/00031305.2015.1089789 .","code":""},{"path":[]},{"path":"https://floschuberth.github.io/cSEM/reference/infer.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Inference — infer","text":"","code":"model <- \" # Structural model QUAL ~ EXPE EXPE ~ IMAG SAT  ~ IMAG + EXPE + QUAL + VAL LOY  ~ IMAG + SAT VAL  ~ EXPE + QUAL  # Measurement model EXPE =~ expe1 + expe2 + expe3 + expe4 + expe5 IMAG =~ imag1 + imag2 + imag3 + imag4 + imag5 LOY  =~ loy1  + loy2  + loy3  + loy4 QUAL =~ qual1 + qual2 + qual3 + qual4 + qual5 SAT  =~ sat1  + sat2  + sat3  + sat4 VAL  =~ val1  + val2  + val3  + val4 \"    ## Estimate the model with bootstrap resampling  a <- csem(satisfaction, model, .resample_method = \"bootstrap\", .R = 20,           .handle_inadmissibles = \"replace\")  ## Compute inferential quantities inf <- infer(a)  inf$Path_estimates$CI_basic #>      EXPE ~ IMAG QUAL ~ EXPE VAL ~ EXPE VAL ~ QUAL SAT ~ IMAG SAT ~ EXPE #> 95%L   0.5700903    1.003007  -5.330185   4.238106 -0.1207778  0.2539345 #> 95%U   0.7556364    1.054425  -3.374719   6.217029  0.3181663  2.6611737 #>      SAT ~ QUAL SAT ~ VAL LOY ~ IMAG LOY ~ SAT #> 95%L -3.6242147  1.106262  0.0614160 0.3334153 #> 95%U -0.6734842  2.160072  0.5038873 0.7921834 inf$Indirect_effect$sd #> QUAL ~ IMAG  VAL ~ IMAG  VAL ~ EXPE  SAT ~ IMAG  SAT ~ EXPE  SAT ~ QUAL  #>  0.05891166  0.05807792  0.55306374  0.09238226  0.63375409  0.95475450  #>  LOY ~ IMAG  LOY ~ EXPE  LOY ~ QUAL   LOY ~ VAL  #>  0.07019098  0.12160435  0.47444117  0.23936610   ### Compute the bias-corrected and accelerated and/or the studentized t-inverval. ## For the studentied t-interval confidence interval a double bootstrap is required. ## This is pretty time consuming. if (FALSE) { # \\dontrun{   inf <- infer(a, .quantity = c(\"all\", \"CI_bca\")) # requires jackknife estimates     ## Estimate the model with double bootstrap resampling: # Notes: #   1. The .resample_method2 arguments triggers a bootstrap of each bootstrap sample #   2. The double bootstrap is is very time consuming, consider setting  #      `.eval_plan = \"multisession`.  a1 <- csem(satisfaction, model, .resample_method = \"bootstrap\", .R = 499,           .resample_method2 = \"bootstrap\", .R2 = 199, .handle_inadmissibles = \"replace\")  infer(a1, .quantity = \"CI_t_interval\")} # }"},{"path":"https://floschuberth.github.io/cSEM/reference/inference_helper.html","id":null,"dir":"Reference","previous_headings":"","what":"Internal: Helper for infer() — inference_helper","title":"Internal: Helper for infer() — inference_helper","text":"Collection various functions compute inferential quantity.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/inference_helper.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Internal: Helper for infer() — inference_helper","text":"","code":"MeanResample(.first_resample)  SdResample(.first_resample, .resample_method, .n)  BiasResample(.first_resample, .resample_method, .n)  StandardCIResample(   .first_resample,   .bias_corrected,   .dist = c(\"z\", \"t\"),   .df = c(\"type1\", \"type2\"),   .resample_method,   .n,   .probs )  PercentilCIResample(.first_resample, .probs)  BasicCIResample(.first_resample, .bias_corrected, .probs)  TStatCIResample(   .first_resample,   .second_resample,   .bias_corrected,   .resample_method,   .resample_method2,   .n,   .probs )  BcCIResample(.first_resample, .probs)  BcaCIResample(.object, .first_resample, .probs)"},{"path":"https://floschuberth.github.io/cSEM/reference/inference_helper.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Internal: Helper for infer() — inference_helper","text":".first_resample list containing .R resamples based original data obtained resamplecSEMResults(). .resample_method Character string. resampling method use. One : \"none\", \"bootstrap\" \"jackknife\". Defaults \"none\". .n Integer. number observations original data. .bias_corrected Logical. standard tStat confidence interval bias-corrected using bootstrapped bias estimate? TRUE confidence interval estimated parameter theta centered 2*theta - theta*_hat, theta*_hat average .R bootstrap estimates theta. Defaults TRUE .dist Character string. distribution use critical value. One \"t\" Student's t-distribution \"z\" standard normal distribution. Defaults \"z\". .df Character string. method obtaining degrees freedom. Choices \"type1\" \"type2\". Defaults \"type1\" . .probs vector probabilities. .second_resample list containing .R2 resamples .R resamples first run. .resample_method2 Character string. resampling method use resampling resample. One : \"none\", \"bootstrap\" \"jackknife\". \"bootstrap\" number draws provided via .R2. Currently, resampling resample required studentized confidence interval (\"CI_t_interval\") computed infer() function. Defaults \"none\". .object R object class cSEMResults resulting call csem().","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/inference_helper.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Internal: Helper for infer() — inference_helper","text":"Implementation terminology confidence intervals based Hesterberg (2015)  Davison Hinkley (1997) .","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/inference_helper.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Internal: Helper for infer() — inference_helper","text":"Davison AC, Hinkley DV (1997). Bootstrap Methods Application. Cambridge University Press. doi:10.1017/cbo9780511802843 . Hesterberg TC (2015). “Teachers Know Bootstrap: Resampling Undergraduate Statistics Curriculum.” American Statistician, 69(4), 371–386. doi:10.1080/00031305.2015.1089789 .","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/moments.html","id":null,"dir":"Reference","previous_headings":"","what":"Internal: Calculate consistent moments of a nonlinear model — moments","title":"Internal: Calculate consistent moments of a nonlinear model — moments","text":"Collection various moment estimators. See classifyConstructs list possible moments.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/moments.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Internal: Calculate consistent moments of a nonlinear model — moments","text":"","code":"SingleSingle(.i, .j, .Q, .H)  SingleQuadratic(.i, .j, .Q, .H)  SingleCubic(.i, .j, .Q, .H)  SingleTwInter(.i, .j, .Q, .H)  SingleThrwInter(.i, .j, .Q, .H)  SingleQuadTwInter(.i, .j, .Q, .H)  QuadraticQuadratic(.i, .j, .Q, .H)  QuadraticCubic(.i, .j, .Q, .H)  QuadraticTwInter(.i, .j, .Q, .H)  QuadraticThrwInter(.i, .j, .Q, .H)  QuadraticQuadTwInter(.i, .j, .Q, .H)  CubicCubic(.i, .j, .Q, .H)  CubicTwInter(.i, .j, .Q, .H)  CubicThrwInter(.i, .j, .Q, .H)  CubicQuadTwInter(.i, .j, .Q, .H)  TwInterTwInter(.i, .j, .Q, .H)  TwInterThrwInter(.i, .j, .Q, .H)  TwInterQuadTwInter(.i, .j, .Q, .H)  ThrwInterThrwInter(.i, .j, .Q, .H)  ThrwInterQuadTwInter(.i, .j, .Q, .H)  QuadTwInercQuadTwInter(.i, .j, .Q, .H)"},{"path":"https://floschuberth.github.io/cSEM/reference/moments.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Internal: Calculate consistent moments of a nonlinear model — moments","text":".Row index .j Column index .Q vector composite-construct correlations element names equal names J construct names used measurement model. Note Q^2 also called reliability coefficient. .H (N x J) matrix construct scores.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/moments.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Internal: Calculate consistent moments of a nonlinear model — moments","text":"M matrix sample counterparts (estimates) left-hand side terms Equation (21) - (24) (Dijkstra Schermelleh-Engel 2014) . label \"M\" appear paper used package. Similar suggested Wall Amemiya (2000)  using classical factor scores.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/moments.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Internal: Calculate consistent moments of a nonlinear model — moments","text":"Dijkstra TK, Schermelleh-Engel K (2014). “Consistent Partial Least Squares Nonlinear Structural Equation Models.” Psychometrika, 79(4), 585–604. Wall MM, Amemiya Y (2000). “Estimation polynomial structural equation models.” Journal American Statistical Association, 95(451), 929–940.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/nonlinear_estimation_utilities.html","id":null,"dir":"Reference","previous_headings":"","what":"Internal: Utility functions for the estimation of nonlinear models — nonlinear_estimation_utilities","title":"Internal: Utility functions for the estimation of nonlinear models — nonlinear_estimation_utilities","text":"Internal: Utility functions estimation nonlinear models","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/nonlinear_estimation_utilities.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Internal: Utility functions for the estimation of nonlinear models — nonlinear_estimation_utilities","text":"","code":"f1(.i, .j)  f2(.i, .j, .select_from, .Q, .H)  f3(.i, .j, .Q, .H)  f4(.i, .j, .Q, .H, .var_struc_error, .temp = NULL)  f5(.i, .j, .H, .Q, .var_struc_error)"},{"path":"https://floschuberth.github.io/cSEM/reference/nonlinear_estimation_utilities.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Internal: Utility functions for the estimation of nonlinear models — nonlinear_estimation_utilities","text":".Row index .j Column index .select_from matrix select .Q vector composite-construct correlations element names equal names J construct names used measurement model. Note Q^2 also called reliability coefficient. .H (N x J) matrix construct scores.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/parseModel.html","id":null,"dir":"Reference","previous_headings":"","what":"Parse lavaan model — parseModel","title":"Parse lavaan model — parseModel","text":"Turns model written lavaan model syntax cSEMModel list.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/parseModel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Parse lavaan model — parseModel","text":"","code":"parseModel(   .model        = NULL,    .instruments  = NULL,    .check_errors = TRUE   )"},{"path":"https://floschuberth.github.io/cSEM/reference/parseModel.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parse lavaan model — parseModel","text":".model model lavaan model syntax cSEMModel list. .instruments named list vectors instruments. names list elements names dependent (LHS) constructs structural equation whose explanatory variables endogenous. vectors contain names instruments corresponding equation. Note exogenous variables given equation must supplied instruments . Defaults NULL. .check_errors Logical. model parse checked correctness sense necessary components estimate model given? Defaults TRUE.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/parseModel.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Parse lavaan model — parseModel","text":"object class cSEMModel standardized list containing following components. J stands number constructs K number indicators. $structural matrix mimicking structural relationship constructs. constructs linearly related, structural dimension (J x J) row- column names equal construct names. structural model contains nonlinear relationships structural (J x (J + J*)) J* number nonlinear terms. Rows ordered exogenous constructs always first, followed constructs depend exogenous constructs /previously ordered constructs. $measurement (J x K) matrix mimicking measurement/composite relationship constructs related indicators. Rows order matrix $structural row names equal construct names. order columns $measurement forms block diagonal matrix. $error_cor (K x K) matrix mimicking measurement error correlation relationship. row column order identical column order $measurement. $cor_specified matrix indicating correlation relationships variables model specified user. Mainly internal purposes. Note $cor_specified may also contain inadmissible correlations correlation measurement errors indicators constructs. $construct_type named vector containing names construct respective type (\"Common factor\" \"Composite\"). $construct_order named vector containing names construct respective order (\"First order\" \"Second order\"). $model_type type model (\"Linear\" \"Nonlinear\"). $instruments instruments supplied: list structural equations relating endogenous RHS variables instruments. $indicators names indicators (.e., observed variables /first-order constructs) $cons_exo names exogenous constructs structural model (.e., variables appear LHS structural equation) $cons_endo names endogenous constructs structural model (.e., variables appear LHS least one structural equation) $vars_2nd names constructs modeled second orders. $vars_attached_to_2nd names constructs forming building second order construct. $vars_not_attached_to_2nd names constructs forming building second order construct. possible supply incomplete list parseModel(), resulting incomplete cSEMModel list can passed functions require .csem_model mandatory argument. Currently, structural measurement matrix required. However, specifying incomplete cSEMModel list may lead unexpected behavior errors. Use care.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/parseModel.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Parse lavaan model — parseModel","text":"Instruments must supplied separately named list vectors instruments. names list elements names dependent constructs structural equation whose explanatory variables endogenous. vectors contain names instruments corresponding equation. Note exogenous variables given equation must supplied instruments . default parseModel() attempts check model provided correct sense necessary components required estimate model specified (e.g., construct structural model least 1 item). prevent checking errors use .check_errors = FALSE.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/parseModel.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Parse lavaan model — parseModel","text":"","code":"# =========================================================================== # Providing a model in lavaan syntax  # =========================================================================== model <- \" # Structural model y1 ~ y2 + y3  # Measurement model y1 =~ x1 + x2 + x3 y2 =~ x4 + x5 y3 =~ x6 + x7  # Error correlation x1 ~~ x2 \"  m <- parseModel(model) m #> $structural #>    y2 y3 y1 #> y2  0  0  0 #> y3  0  0  0 #> y1  1  1  0 #>  #> $measurement #>    x4 x5 x6 x7 x1 x2 x3 #> y2  1  1  0  0  0  0  0 #> y3  0  0  1  1  0  0  0 #> y1  0  0  0  0  1  1  1 #>  #> $error_cor #>    x4 x5 x6 x7 x1 x2 x3 #> x4  0  0  0  0  0  0  0 #> x5  0  0  0  0  0  0  0 #> x6  0  0  0  0  0  0  0 #> x7  0  0  0  0  0  0  0 #> x1  0  0  0  0  0  1  0 #> x2  0  0  0  0  1  0  0 #> x3  0  0  0  0  0  0  0 #>  #> $cor_specified #>    x1 x2 #> x1  0  1 #> x2  1  0 #>  #> $construct_type #>              y2              y3              y1  #> \"Common factor\" \"Common factor\" \"Common factor\"  #>  #> $construct_order #>            y2            y3            y1  #> \"First order\" \"First order\" \"First order\"  #>  #> $model_type #> [1] \"Linear\" #>  #> $indicators #> [1] \"x4\" \"x5\" \"x6\" \"x7\" \"x1\" \"x2\" \"x3\" #>  #> $cons_exo #> [1] \"y2\" \"y3\" #>  #> $cons_endo #> [1] \"y1\" #>  #> $vars_2nd #> character(0) #>  #> $vars_attached_to_2nd #> character(0) #>  #> $vars_not_attached_to_2nd #> [1] \"y1\" \"y2\" \"y3\" #>  #> attr(,\"class\") #> [1] \"cSEMModel\"  # =========================================================================== # Providing a complete model in cSEM format (class cSEMModel) # =========================================================================== # If the model is already a cSEMModel object, the model is returned as is:  identical(m, parseModel(m)) # TRUE #> [1] TRUE  # =========================================================================== # Providing a list  # =========================================================================== # It is possible to provide a list that contains at least the # elements \"structural\" and \"measurement\". This is generally discouraged # as this may cause unexpected errors.  m_incomplete <- m[c(\"structural\", \"measurement\", \"construct_type\")] parseModel(m_incomplete) #> $structural #>    y2 y3 y1 #> y2  0  0  0 #> y3  0  0  0 #> y1  1  1  0 #>  #> $measurement #>    x4 x5 x6 x7 x1 x2 x3 #> y2  1  1  0  0  0  0  0 #> y3  0  0  1  1  0  0  0 #> y1  0  0  0  0  1  1  1 #>  #> $construct_type #>              y2              y3              y1  #> \"Common factor\" \"Common factor\" \"Common factor\"  #>  #> attr(,\"class\") #> [1] \"cSEMModel\"  # Providing a list containing list names that are not part of a `cSEMModel` # causes an error:  if (FALSE) { # \\dontrun{ m_incomplete[c(\"name_a\", \"name_b\")] <- c(\"hello world\", \"hello universe\") parseModel(m_incomplete) } # }  # Failing to provide \"structural\" or \"measurement\" also causes an error:  if (FALSE) { # \\dontrun{ m_incomplete <- m[c(\"structural\", \"construct_type\")] parseModel(m_incomplete) } # }"},{"path":"https://floschuberth.github.io/cSEM/reference/plot.cSEMIPMA.html","id":null,"dir":"Reference","previous_headings":"","what":"cSEMIPMA method for plot() — plot.cSEMIPMA","title":"cSEMIPMA method for plot() — plot.cSEMIPMA","text":"Plot importance-performance matrix.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/plot.cSEMIPMA.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"cSEMIPMA method for plot() — plot.cSEMIPMA","text":"","code":"# S3 method for class 'cSEMIPMA' plot(   x = NULL,   .dependent = NULL,   .attributes = NULL,   .level = c(\"construct\", \"indicator\"),   ... )"},{"path":"https://floschuberth.github.io/cSEM/reference/plot.cSEMIPMA.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"cSEMIPMA method for plot() — plot.cSEMIPMA","text":"x R object class cSEMIPMA. .dependent Character string. Name target construct importance-performance matrix created. .attributes Character string. vector containing indicator/construct names plotted importance-performance matrix. must least length 2. .level Character string. Indicates level importance-performance matrix plotted. One \"construct\" \"indicator\". Defaults \"construct\". ... Currently ignored.","code":""},{"path":[]},{"path":"https://floschuberth.github.io/cSEM/reference/plot.cSEMNonlinearEffects.html","id":null,"dir":"Reference","previous_headings":"","what":"cSEMNonlinearEffects method for plot() — plot.cSEMNonlinearEffects","title":"cSEMNonlinearEffects method for plot() — plot.cSEMNonlinearEffects","text":"plot method can used create plots analyze non-linear models depth. following plot types can selected: .plot_type = \"simpleeffects\": plot simple effects analysis displays predicted value dependent variable different values independent variable moderator. levels moderator levels provided doNonlinearEffectsAnalysis() function used. Since constructs standardized values moderator equals deviation mean measured standard deviations. .plot_type = \"surface\": plot surface analysis displays predicted values independent variable (z). values predicted based values moderator independent variable including higher-order terms. values moderator independent variable steps minimum maximum values  used. .plot_type = \"floodlight\": plot floodlight analysis displays direct effect continuous independent variable (z) dependent variable (y) conditional values continuous moderator variable (x), including confidence interval Johnson-Neyman points. noted floodlight plot moderation taken account higher order terms ignored. details, see Spiller et al. (2013) . Plot predicted values independent variable (z) values predicted based certain moderator certain independent variable including higher-order terms.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/plot.cSEMNonlinearEffects.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"cSEMNonlinearEffects method for plot() — plot.cSEMNonlinearEffects","text":"","code":"# S3 method for class 'cSEMNonlinearEffects' plot(x, .plot_type = \"simpleeffects\", .plot_package = \"plotly\", ...)"},{"path":"https://floschuberth.github.io/cSEM/reference/plot.cSEMNonlinearEffects.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"cSEMNonlinearEffects method for plot() — plot.cSEMNonlinearEffects","text":"x R object class cSEMNonlinearEffects. .plot_type character string indicating type plot produced. Options \"simpleeffects\", \"surface\", \"floodlight\". Defaults \"simpleeffects\". .plot_package character vector indicating plot package used. Options \"plotly\", \"persp\". Defaults \"plotly\". ... Additional parameters can passed graphics::persp, e.g., rotate plot.","code":""},{"path":[]},{"path":"https://floschuberth.github.io/cSEM/reference/plot.cSEMPredict.html","id":null,"dir":"Reference","previous_headings":"","what":"cSEMPredict method for plot() — plot.cSEMPredict","title":"cSEMPredict method for plot() — plot.cSEMPredict","text":"cSEMPredict method generic function plot().","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/plot.cSEMPredict.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"cSEMPredict method for plot() — plot.cSEMPredict","text":"","code":"# S3 method for class 'cSEMPredict' plot(x, ...)"},{"path":"https://floschuberth.github.io/cSEM/reference/plot.cSEMPredict.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"cSEMPredict method for plot() — plot.cSEMPredict","text":"x R object class cSEMPredict. ... Currently ignored.","code":""},{"path":[]},{"path":[]},{"path":"https://floschuberth.github.io/cSEM/reference/plot.cSEMResults_2ndorder.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"cSEMResults method for plot() for second-order models. — plot.cSEMResults_2ndorder","text":"","code":"# S3 method for class 'cSEMResults_2ndorder' plot(   x,   .title = args_default()$.title,   .plot_significances = args_default()$.plot_significances,   .plot_correlations = args_default()$.plot_correlations,   .plot_structural_model_only = args_default()$.plot_structural_model_only,   .plot_labels = args_default()$.plot_labels,   .graph_attrs = args_default()$.graph_attrs,   ... )"},{"path":"https://floschuberth.github.io/cSEM/reference/plot.cSEMResults_2ndorder.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"cSEMResults method for plot() for second-order models. — plot.cSEMResults_2ndorder","text":"x R object class cSEMResults_2ndorder object. .title Character string. Title object. Defaults \"\". .plot_significances Logical. p-values form stars plotted? Defaults TRUE. .plot_correlations Character string. Specify correlations plotted, .e., exogenous constructs (exo), exogenous constructs indicators (), (none). Defaults exo. .plot_structural_model_only Logical. structural model, .e., constructs relationships plotted? Defaults FALSE. .plot_labels Logical. Whether display edge labels node R² values. Defaults TRUE. .graph_attrs Character string. Additional attributes passed DiagrammeR syntax, e.g., c(\"rankdir=LR\", \"ranksep=1.0\"). Defaults c(\"rankdir=LR\"). ... Currently ignored.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/plot.cSEMResults_2ndorder.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"cSEMResults method for plot() for second-order models. — plot.cSEMResults_2ndorder","text":"Creates plot cSEMResults_2ndorder object using grViz function. details customizing plot, see https://rpubs.com/nguyen_mot/1275413.","code":""},{"path":[]},{"path":[]},{"path":"https://floschuberth.github.io/cSEM/reference/plot.cSEMResults_default.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"cSEMResults method for plot() — plot.cSEMResults_default","text":"","code":"# S3 method for class 'cSEMResults_default' plot(   x = NULL,   .title = args_default()$.title,   .plot_significances = args_default()$.plot_significances,   .plot_correlations = args_default()$.plot_correlations,   .plot_structural_model_only = args_default()$.plot_structural_model_only,   .plot_labels = args_default()$.plot_labels,   .graph_attrs = args_default()$.graph_attrs,   ... )"},{"path":"https://floschuberth.github.io/cSEM/reference/plot.cSEMResults_default.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"cSEMResults method for plot() — plot.cSEMResults_default","text":"x R object class cSEMResults_default object. .title Character string. Title object. Defaults \"\". .plot_significances Logical. p-values form stars plotted? Defaults TRUE. .plot_correlations Character string. Specify correlations plotted, .e., exogenous constructs (exo), exogenous constructs indicators (), (none). Defaults exo. .plot_structural_model_only Logical. structural model, .e., constructs relationships plotted? Defaults FALSE. .plot_labels Logical. Whether display edge labels R² values nodes. Defaults TRUE (.e. original plot). .graph_attrs Character string. Additional attributes passed DiagrammeR syntax, e.g., c(\"rankdir=LR\", \"ranksep=1.0\"). Defaults c(\"rankdir=LR\"). ... Currently ignored.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/plot.cSEMResults_default.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"cSEMResults method for plot() — plot.cSEMResults_default","text":"Creates plot cSEMResults object using grViz function. details customizing plot, see https://rpubs.com/nguyen_mot/1275413.","code":""},{"path":[]},{"path":"https://floschuberth.github.io/cSEM/reference/plot.cSEMResults_default.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"cSEMResults method for plot() — plot.cSEMResults_default","text":"","code":"if (FALSE) { # \\dontrun{ model_Bergami_int=\"   # Common factor and composite models   OrgPres <~ cei1 + cei2 + cei3 + cei4 + cei5 + cei6 + cei7 + cei8    OrgIden =~ ma1 + ma2 + ma3 + ma4 + ma5 + ma6   AffJoy =~ orgcmt1 + orgcmt2 + orgcmt3 + orgcmt7   AffLove  =~ orgcmt5 + orgcmt6 + orgcmt8    # Structural model    OrgIden ~ OrgPres    AffLove ~ OrgPres+OrgIden+OrgPres.OrgIden   AffJoy  ~ OrgPres+OrgIden   \"      outBergamiInt <- csem(.data = BergamiBagozzi2000,.model = model_Bergami_int,                         .disattenuate = T,                         .PLS_weight_scheme_inner = 'factorial',                         .tolerance = 1e-6,                         .resample_method = 'none')      outPlot <- plot(outBergamiInt)   outPlot   savePlot(outPlot,.file='plot.pdf')   savePlot(outPlot,.file='plot.png')   savePlot(outPlot,.file='plot.svg')   savePlot(outPlot,.file='plot.dot') } # }"},{"path":[]},{"path":"https://floschuberth.github.io/cSEM/reference/plot.cSEMResults_multi.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"cSEMResults method for plot() for multiple groups. — plot.cSEMResults_multi","text":"","code":"# S3 method for class 'cSEMResults_multi' plot(   x = NULL,   .title = args_default()$.title,   .plot_significances = args_default()$.plot_significances,   .plot_correlations = args_default()$.plot_correlations,   .plot_structural_model_only = args_default()$.plot_structural_model_only,   .plot_labels = args_default()$.plot_labels,   .graph_attrs = args_default()$.graph_attrs,   ... )"},{"path":"https://floschuberth.github.io/cSEM/reference/plot.cSEMResults_multi.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"cSEMResults method for plot() for multiple groups. — plot.cSEMResults_multi","text":"x R object class cSEMResults_multi object. .title Character string. Title object. Defaults \"\". .plot_significances Logical. p-values form stars plotted? Defaults TRUE. .plot_correlations Character string. Specify correlations plotted, .e., exogenous constructs (exo), exogenous constructs indicators (), (none). Defaults exo. .plot_structural_model_only Logical. structural model, .e., constructs relationships plotted? Defaults FALSE. .plot_labels Logical. Whether display edge labels node R² values. Defaults TRUE. .graph_attrs Character string. Additional attributes passed DiagrammeR syntax, e.g., c(\"rankdir=LR\", \"ranksep=1.0\"). Defaults c(\"rankdir=LR\"). ... Currently ignored.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/plot.cSEMResults_multi.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"cSEMResults method for plot() for multiple groups. — plot.cSEMResults_multi","text":"Creates plot cSEMResults object using grViz function. details customizing plot, see https://rpubs.com/nguyen_mot/1275413.","code":""},{"path":[]},{"path":[]},{"path":"https://floschuberth.github.io/cSEM/reference/predict.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Predict indicator scores — predict","text":"","code":"predict(  .object                   = NULL,  .benchmark                = c(\"lm\", \"unit\", \"PLS-PM\", \"GSCA\", \"PCA\", \"MAXVAR\", \"NA\"),  .approach_predict         = c(\"earliest\", \"direct\"),  .cv_folds                 = 10,  .handle_inadmissibles     = c(\"stop\", \"ignore\", \"set_NA\"),  .r                        = 1,  .test_data                = NULL,  .approach_score_target    = c(\"mean\", \"median\", \"mode\"),  .sim_points               = 100,  .disattenuate             = TRUE,  .treat_as_continuous      = TRUE,  .approach_score_benchmark = c(\"mean\", \"median\", \"mode\", \"round\"),  .seed                     = NULL  )"},{"path":"https://floschuberth.github.io/cSEM/reference/predict.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Predict indicator scores — predict","text":".object R object class cSEMResults resulting call csem(). .benchmark Character string. procedure obtain benchmark predictions. One \"lm\", \"unit\", \"PLS-PM\", \"GSCA\", \"PCA\", \"MAXVAR\", \"NA\". Default \"lm\". .approach_predict Character string. approach used perform predictions? One \"earliest\" \"direct\". \"earliest\" predictions indicators associated endogenous constructs performed using indicators associated exogenous constructs. \"direct\", predictions indicators associated endogenous constructs based indicators associated direct antecedents. Defaults \"earliest\". .cv_folds Integer. number cross-validation folds use. Setting .cv_folds N (number observations) produces leave-one-cross-validation samples. Defaults 10. .handle_inadmissibles Character string. inadmissible results treated? One \"stop\", \"ignore\", \"set_NA\". \"stop\", predict() stop immediately estimation yields inadmissible result. \"ignore\" results returned even estimates yielded inadmissible results. \"set_NA\" predictions based inadmissible parameter estimates set NA. Defaults \"stop\" .r Integer. number repetitions use. Defaults 1. .test_data matrix test data column names training data. .approach_score_target Character string. aggregation estimates truncated normal distribution predictions using OrdPLS/OrdPLSc done? One \"mean\", \"median\" \"mode\". \"mean\", mean estimated endogenous indicators calculated. \"median\", mean estimated endogenous indicators calculated. \"mode\", maximum empirical density intervals defined thresholds used. Defaults \"mean\". .sim_points Integer. many samples truncated normal distribution simulated estimate exogenous construct scores? Defaults \"100\". .disattenuate Logical. benchmark predictions based disattenuated parameter estimates? Defaults TRUE. .treat_as_continuous Logical. indicators benchmark predictions treated continuous? TRUE indicators treated continuous PLS-PM/PLSc applied. FALSE OrdPLS/OrdPLSc applied. Defaults TRUE. .approach_score_benchmark Character string. aggregation estimates truncated normal distribution done benchmark predictions? Ignored OrdPLS OrdPLSc used obtain benchmark predictions. One \"mean\", \"median\", \"mode\" \"round\". \"round\", benchmark predictions obtained using traditional prediction algorithm PLS-PM rounded categorical indicators. \"mean\", mean estimated endogenous indicators calculated. \"median\", mean estimated endogenous indicators calculated. \"mode\", maximum empirical density intervals defined thresholds used. .treat_as_continuous = TRUE indicators continuous scale, .approach_score_benchmark ignored. Defaults \"round\". .seed Integer NULL. random seed use. Defaults NULL case arbitrary seed chosen. Note scope seed limited body function used . Hence, global seed altered!","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/predict.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Predict indicator scores — predict","text":"object class cSEMPredict print plot methods. Technically, cSEMPredict named list containing following list elements: $Actual matrix actual values/indicator scores endogenous constructs. $Prediction_target list containing matrices predicted indicator scores endogenous constructs based target model repetition .r. Target refers procedure used estimate parameters .object. $Residuals_target list matrices residual indicator scores endogenous constructs based target model repetition .r. $Residuals_benchmark list matrices residual indicator scores endogenous constructs based model estimated procedure given .benchmark repetition .r. $Prediction_metrics data frame containing predictions metrics MAE, RMSE, Q2_predict, misclassification error rate (MER), MAPE, MSE2, Theil's forecast accuracy (U1), Theil's forecast quality (U2), Bias proportion MSE (UM), Regression proportion MSE (UR), disturbance proportion MSE (UD) (Hora Campos 2015; Watson Teelucksingh 2002) . $Information list elements Target, Benchmark, Number_of_observations_training, Number_of_observations_test, Number_of_folds, Number_of_repetitions, Handle_inadmissibles.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/predict.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Predict indicator scores — predict","text":"predict function implements procedure introduced Shmueli et al. (2016)  PLS context known \"PLSPredict\" (Shmueli et al. 2019)  including variants PLScPredcit, OrdPLSpredict OrdPLScpredict. used predict indicator scores endogenous constructs evaluate --sample predictive power model. purpose, predict function uses k-fold cross-validation randomly split data training test datasets, subsequently predicts values test data based model parameter estimates obtained training data. number cross-validation folds 10 default may changed using .cv_folds argument. default, procedure repeated (.r = 1). may choose repeat cross-validation setting higher .r sure particular (unfortunate) split. See Shmueli et al. (2019)  details. Typically .r = 1 sufficient though. Alternatively, users may supply test dataset matrix data frame .test_data column names data used obtain .object (training data). case, arguments .cv_folds .r ignored predict uses estimated coefficients .object predict values columns .test_data. Shmueli et al. (2016)  PLS-based predictions indicator compared predictions based multiple regression indicator available exogenous indicators (.benchmark = \"lm\") simple mean-based prediction summarized Q2_predict metric. predict() general allows users compare predictions based -called target model/specification predictions based alternative benchmark. Available benchmarks include predictions based linear model, PLS-PM weights, unit weights (.e. sum scores), GSCA weights, PCA weights, MAXVAR weights. estimation run checked admissibility using verify(). estimation yields inadmissible results, predict() stops error (\"stop\"). Users may choose \"ignore\" inadmissible results simply set predictions NA (\"set_NA\") particular run failed.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/predict.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Predict indicator scores — predict","text":"Hora J, Campos P (2015). “review performance criteria validate simulation models.” Expert Systems, 32(5), 578–595. doi:10.1111/exsy.12111 . Shmueli G, Ray S, Estrada JMV, Chatla SB (2016). “Elephant Room: Predictive Performance PLS Models.” Journal Business Research, 69(10), 4552–4564. doi:10.1016/j.jbusres.2016.03.049 . Shmueli G, Sarstedt M, Hair JF, Cheah J, Ting H, Vaithilingam S, Ringle CM (2019). “Predictive Model Assessment PLS-SEM: Guidelines Using PLSpredict.” European Journal Marketing, 53(11), 2322–2347. doi:10.1108/ejm-02-2019-0189 . Watson PK, Teelucksingh SS (2002). practical introduction econometric methods: Classical modern. University West Indies Press, Mona, Jamaica.","code":""},{"path":[]},{"path":"https://floschuberth.github.io/cSEM/reference/predict.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Predict indicator scores — predict","text":"","code":"### Anime example taken from https://github.com/ISS-Analytics/pls-predict/  # Load data data(Anime) # data is similar to the Anime.csv found on              # https://github.com/ISS-Analytics/pls-predict/ but with irrelevant             # columns removed  # Split into training and data the same way as it is done on  # https://github.com/ISS-Analytics/pls-predict/ set.seed(123)  index     <- sample.int(dim(Anime)[1], 83, replace = FALSE) dat_train <- Anime[-index, ] dat_test  <- Anime[index, ]  # Specify model model <- \" # Structural model  ApproachAvoidance ~ PerceivedVisualComplexity + Arousal  # Measurement/composite model  ApproachAvoidance         =~ AA0 + AA1 + AA2 + AA3 PerceivedVisualComplexity <~ VX0 + VX1 + VX2 + VX3 + VX4 Arousal                   <~ Aro1 + Aro2 + Aro3 + Aro4 \"  # Estimate (replicating the results of the `simplePLS()` function) res <- csem(dat_train,              model,              .disattenuate = FALSE, # original PLS             .iter_max = 300,              .tolerance = 1e-07,              .PLS_weight_scheme_inner = \"factorial\" )  # Predict using a user-supplied training data set pp <- predict(res, .test_data = dat_test) #> Warning: The following warning occured in the `predict()` function: #> Disattenuation is not applicable to benchmark `lm` and ignored. pp #> ________________________________________________________________________________ #> ----------------------------------- Overview ----------------------------------- #>  #> \tNumber of obs. training            = 100 #> \tNumber of obs. test                = 83 #> \tNumber of cv folds                 = NA #> \tNumber of repetitions              = 1 #> \tHandle inadmissibles               = stop #> \tEstimator target                   = 'PLS-PM' #> \tEstimator benchmark                = 'lm' #> \tDisattenuation target              = 'FALSE' #> \tDisattenuation benchmark           = 'FALSE' #> \tApproach to predict                = 'earliest' #>  #> ------------------------------ Prediction metrics ------------------------------ #>  #>  #>   Name    MAE target  MAE benchmark  RMSE target RMSE benchmark   Q2_predict #>   AA0         1.2125         1.1621       1.5575         1.5045       0.4625 #>   AA1         1.5319         1.5711       1.9005         1.9829       0.2794 #>   AA2         0.9891         0.9804       1.3993         1.4029       0.4396 #>   AA3         1.0564         1.0472       1.4434         1.4787       0.3656 #> ________________________________________________________________________________  ### Compute prediction metrics  ------------------------------------------------ res2 <- csem(Anime, # whole data set             model,              .disattenuate = FALSE, # original PLS             .iter_max = 300,              .tolerance = 1e-07,              .PLS_weight_scheme_inner = \"factorial\" )  # Predict using 10-fold cross-validation if (FALSE) { # \\dontrun{ pp2 <- predict(res, .benchmark = \"lm\") pp2 ## There is a plot method available plot(pp2)} # }  ### Example using OrdPLScPredict ----------------------------------------------- # Transform the numerical indicators into factors if (FALSE) { # \\dontrun{ data(\"BergamiBagozzi2000\") data_new <- data.frame(cei1    = as.ordered(BergamiBagozzi2000$cei1),                        cei2    = as.ordered(BergamiBagozzi2000$cei2),                        cei3    = as.ordered(BergamiBagozzi2000$cei3),                        cei4    = as.ordered(BergamiBagozzi2000$cei4),                        cei5    = as.ordered(BergamiBagozzi2000$cei5),                        cei6    = as.ordered(BergamiBagozzi2000$cei6),                        cei7    = as.ordered(BergamiBagozzi2000$cei7),                        cei8    = as.ordered(BergamiBagozzi2000$cei8),                        ma1     = as.ordered(BergamiBagozzi2000$ma1),                        ma2     = as.ordered(BergamiBagozzi2000$ma2),                        ma3     = as.ordered(BergamiBagozzi2000$ma3),                        ma4     = as.ordered(BergamiBagozzi2000$ma4),                        ma5     = as.ordered(BergamiBagozzi2000$ma5),                        ma6     = as.ordered(BergamiBagozzi2000$ma6),                        orgcmt1 = as.ordered(BergamiBagozzi2000$orgcmt1),                        orgcmt2 = as.ordered(BergamiBagozzi2000$orgcmt2),                        orgcmt3 = as.ordered(BergamiBagozzi2000$orgcmt3),                        orgcmt5 = as.ordered(BergamiBagozzi2000$orgcmt5),                        orgcmt6 = as.ordered(BergamiBagozzi2000$orgcmt6),                        orgcmt7 = as.ordered(BergamiBagozzi2000$orgcmt7),                        orgcmt8 = as.ordered(BergamiBagozzi2000$orgcmt8))  model <- \" # Measurement models OrgPres =~ cei1 + cei2 + cei3 + cei4 + cei5 + cei6 + cei7 + cei8 OrgIden =~ ma1 + ma2 + ma3 + ma4 + ma5 + ma6 AffJoy  =~ orgcmt1 + orgcmt2 + orgcmt3 + orgcmt7 AffLove =~ orgcmt5 + orgcmt 6 + orgcmt8  # Structural model OrgIden ~ OrgPres AffLove ~ OrgIden AffJoy  ~ OrgIden  \" # Estimate using cSEM; note: the fact that indicators are factors triggers OrdPLSc res <- csem(.model = model, .data = data_new[1:250,]) summarize(res)  # Predict using OrdPLSPredict set.seed(123) pred <- predict(   .object = res,    .benchmark = \"PLS-PM\",   .test_data = data_new[(251):305,],    .treat_as_continuous = TRUE, .approach_score_target = \"median\"   )  pred  round(pred$Prediction_metrics[, -1], 4)} # }"},{"path":"https://floschuberth.github.io/cSEM/reference/print.cSEMAssess.html","id":null,"dir":"Reference","previous_headings":"","what":"cSEMAssess method for print() — print.cSEMAssess","title":"cSEMAssess method for print() — print.cSEMAssess","text":"cSEMAssess method generic function print().","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/print.cSEMAssess.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"cSEMAssess method for print() — print.cSEMAssess","text":"","code":"# S3 method for class 'cSEMAssess' print(x, ...)"},{"path":[]},{"path":"https://floschuberth.github.io/cSEM/reference/print.cSEMNonlinearEffects.html","id":null,"dir":"Reference","previous_headings":"","what":"cSEMNonlinearEffectsAnalysis method for print() — print.cSEMNonlinearEffects","title":"cSEMNonlinearEffectsAnalysis method for print() — print.cSEMNonlinearEffects","text":"cSEMNonlinearEffectsAnalysis method generic function print().","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/print.cSEMNonlinearEffects.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"cSEMNonlinearEffectsAnalysis method for print() — print.cSEMNonlinearEffects","text":"","code":"# S3 method for class 'cSEMNonlinearEffects' print(x, ...)"},{"path":[]},{"path":"https://floschuberth.github.io/cSEM/reference/print.cSEMPlotPredict.html","id":null,"dir":"Reference","previous_headings":"","what":"cSEMPlotPredict method for print() — print.cSEMPlotPredict","title":"cSEMPlotPredict method for print() — print.cSEMPlotPredict","text":"cSEMPlotPredict method generic function print().","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/print.cSEMPlotPredict.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"cSEMPlotPredict method for print() — print.cSEMPlotPredict","text":"","code":"# S3 method for class 'cSEMPlotPredict' print(x, ...)"},{"path":"https://floschuberth.github.io/cSEM/reference/print.cSEMPlotPredict.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"cSEMPlotPredict method for print() — print.cSEMPlotPredict","text":"x R object class cSEMPlotPredict. ... Currently ignored.","code":""},{"path":[]},{"path":"https://floschuberth.github.io/cSEM/reference/print.cSEMPredict.html","id":null,"dir":"Reference","previous_headings":"","what":"cSEMPredict method for print() — print.cSEMPredict","title":"cSEMPredict method for print() — print.cSEMPredict","text":"cSEMPredict method generic function print().","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/print.cSEMPredict.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"cSEMPredict method for print() — print.cSEMPredict","text":"","code":"# S3 method for class 'cSEMPredict' print(x, .metrics = c(\"MAE\", \"RMSE\", \"Q2\"), ...)"},{"path":"https://floschuberth.github.io/cSEM/reference/print.cSEMPredict.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"cSEMPredict method for print() — print.cSEMPredict","text":".metrics Character string vector character strings. prediction metrics displayed? One : \"MAE\", \"RMSE\", \"Q2\", \"MER\", \"MAPE, \"MSE2\", \"U1\", \"U2\", \"UM\", \"UR\", \"UD\". Default c(\"MAE\", \"RMSE\", \"Q2\").","code":""},{"path":[]},{"path":"https://floschuberth.github.io/cSEM/reference/print.cSEMResults.html","id":null,"dir":"Reference","previous_headings":"","what":"cSEMResults method for print() — print.cSEMResults","title":"cSEMResults method for print() — print.cSEMResults","text":"cSEMResults method generic function print().","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/print.cSEMResults.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"cSEMResults method for print() — print.cSEMResults","text":"","code":"# S3 method for class 'cSEMResults' print(x, ...)"},{"path":[]},{"path":"https://floschuberth.github.io/cSEM/reference/print.cSEMSummarize.html","id":null,"dir":"Reference","previous_headings":"","what":"cSEMSummarize method for print() — print.cSEMSummarize","title":"cSEMSummarize method for print() — print.cSEMSummarize","text":"cSEMSummary method generic function print().","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/print.cSEMSummarize.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"cSEMSummarize method for print() — print.cSEMSummarize","text":"","code":"# S3 method for class 'cSEMSummarize' print(x, .full_output = TRUE, ...)"},{"path":"https://floschuberth.github.io/cSEM/reference/print.cSEMSummarize.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"cSEMSummarize method for print() — print.cSEMSummarize","text":".full_output Logical. full output summarize printed. Defaults TRUE.","code":""},{"path":[]},{"path":"https://floschuberth.github.io/cSEM/reference/print.cSEMTestCVPAT.html","id":null,"dir":"Reference","previous_headings":"","what":"cSEMTestCVPAT method for print() — print.cSEMTestCVPAT","title":"cSEMTestCVPAT method for print() — print.cSEMTestCVPAT","text":"cSEMTestCVAT method generic function print().","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/print.cSEMTestCVPAT.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"cSEMTestCVPAT method for print() — print.cSEMTestCVPAT","text":"","code":"# S3 method for class 'cSEMTestCVPAT' print(x, ...)"},{"path":[]},{"path":"https://floschuberth.github.io/cSEM/reference/print.cSEMTestHausman.html","id":null,"dir":"Reference","previous_headings":"","what":"cSEMTestHausman method for print() — print.cSEMTestHausman","title":"cSEMTestHausman method for print() — print.cSEMTestHausman","text":"cSEMTestHausman method generic function print().","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/print.cSEMTestHausman.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"cSEMTestHausman method for print() — print.cSEMTestHausman","text":"","code":"# S3 method for class 'cSEMTestHausman' print(x, ...)"},{"path":[]},{"path":"https://floschuberth.github.io/cSEM/reference/print.cSEMTestMGD.html","id":null,"dir":"Reference","previous_headings":"","what":"cSEMTestMGD method for print() — print.cSEMTestMGD","title":"cSEMTestMGD method for print() — print.cSEMTestMGD","text":"cSEMTestMGD method generic function print().","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/print.cSEMTestMGD.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"cSEMTestMGD method for print() — print.cSEMTestMGD","text":"","code":"# S3 method for class 'cSEMTestMGD' print(   x,   .approach_mgd = c(\"none\", \"Klesel\", \"Chin\", \"Sarstedt\", \"Keil\", \"Nitzl\", \"Henseler\",     \"CI_para\", \"CI_overlap\"),   ... )"},{"path":"https://floschuberth.github.io/cSEM/reference/print.cSEMTestMGD.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"cSEMTestMGD method for print() — print.cSEMTestMGD","text":".approach_mgd Character string vector character strings. approach details displayed? One : \"none\", \"Klesel\", \"Chin\", \"Sarstedt\", \"Keil, \"Nitzl\", \"Henseler\", \"CI_para\", \"CI_overlap\". Default \"none\" case details displayed.","code":""},{"path":[]},{"path":"https://floschuberth.github.io/cSEM/reference/print.cSEMTestMICOM.html","id":null,"dir":"Reference","previous_headings":"","what":"cSEMTestMICOM method for print() — print.cSEMTestMICOM","title":"cSEMTestMICOM method for print() — print.cSEMTestMICOM","text":"cSEMTestMICOM method generic function print().","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/print.cSEMTestMICOM.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"cSEMTestMICOM method for print() — print.cSEMTestMICOM","text":"","code":"# S3 method for class 'cSEMTestMICOM' print(x, ...)"},{"path":[]},{"path":"https://floschuberth.github.io/cSEM/reference/print.cSEMTestOMF.html","id":null,"dir":"Reference","previous_headings":"","what":"cSEMTestOMF method for print() — print.cSEMTestOMF","title":"cSEMTestOMF method for print() — print.cSEMTestOMF","text":"cSEMTestOMF method generic function print().","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/print.cSEMTestOMF.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"cSEMTestOMF method for print() — print.cSEMTestOMF","text":"","code":"# S3 method for class 'cSEMTestOMF' print(x, ...)"},{"path":[]},{"path":"https://floschuberth.github.io/cSEM/reference/print.cSEMVerify.html","id":null,"dir":"Reference","previous_headings":"","what":"cSEMVerify method for print() — print.cSEMVerify","title":"cSEMVerify method for print() — print.cSEMVerify","text":"cSEMVerify method generic function print().","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/print.cSEMVerify.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"cSEMVerify method for print() — print.cSEMVerify","text":"","code":"# S3 method for class 'cSEMVerify' print(x, ...)"},{"path":[]},{"path":"https://floschuberth.github.io/cSEM/reference/processData.html","id":null,"dir":"Reference","previous_headings":"","what":"Internal: Process data — processData","title":"Internal: Process data — processData","text":"Prepare, standardize, check, clean data provided via .data argument.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/processData.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Internal: Process data — processData","text":"","code":"processData(   .data        = NULL,    .model       = NULL,    .instruments = NULL   )"},{"path":"https://floschuberth.github.io/cSEM/reference/processData.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Internal: Process data — processData","text":".data data.frame matrix standardized unstandardized data (indicators/items/manifest variables). Possible column types classes data provided : \"logical\", \"numeric\" (\"double\" \"integer\"), \"factor\" (\"ordered\" /\"unordered\"), \"character\" (converted factor), mix several types. .model model lavaan model syntax cSEMModel list. .instruments named list vectors instruments. names list elements names dependent (LHS) constructs structural equation whose explanatory variables endogenous. vectors contain names instruments corresponding equation. Note exogenous variables given equation must supplied instruments . Defaults NULL.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/processData.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Internal: Process data — processData","text":"(N x K) data.frame containing standardized data columns ordered according order appear measurement model equations provided via .model argument.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/reliability.html","id":null,"dir":"Reference","previous_headings":"","what":"Reliability — reliability","title":"Reliability — reliability","text":"Compute several reliability estimates. See Reliability section cSEM website details.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/reliability.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reliability — reliability","text":"","code":"calculateRhoC(   .object = NULL,   .model_implied = TRUE,   .only_common_factors = TRUE,   .weighted = FALSE )  calculateRhoT(   .object = NULL,   .alpha = 0.05,   .closed_form_ci = FALSE,   .only_common_factors = TRUE,   .output_type = c(\"vector\", \"data.frame\"),   .weighted = FALSE,   ... )"},{"path":"https://floschuberth.github.io/cSEM/reference/reliability.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reliability — reliability","text":".object R object class cSEMResults resulting call csem(). .model_implied Logical. weights scaled using model-implied indicator correlation matrix? Defaults TRUE. .only_common_factors Logical. concepts modeled common factors included calculating one following quality criteria: AVE, Fornell-Larcker criterion, HTMT, reliability estimates. Defaults TRUE. .weighted Logical. estimation based score uses weights weight approach used obtain .object?. Defaults FALSE. .alpha integer numeric vector significance levels. Defaults 0.05. .closed_form_ci Logical. closed-form confidence interval computed? Defaults FALSE. .output_type Character string. type output. One \"vector\" \"data.frame\". Defaults \"vector\". ... Ignored.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/reliability.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Reliability — reliability","text":"calculateRhoC() calculateRhoT() (.output_type = \"vector\") named numeric vector containing reliability estimates. .output_type = \"data.frame\" calculateRhoT() returns data.frame many rows constructs modeled common factors model (unless .only_common_factors = FALSE case number rows equals total number constructs model). first column contains name construct. second column reliability estimate. .closed_form_ci = TRUE remaining columns contain lower upper bounds (1 - .alpha) confidence interval(s).","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/reliability.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Reliability — reliability","text":"Since reliability defined respect classical true score measurement model concepts modeled common factors considered default. concepts modeled composites reliability may estimated setting .only_common_factors = FALSE, however, unclear interpret reliability case. Reliability traditionally based test score (proxy) based unit weights. compute congeneric tau-equivalent reliability based score uses weights weight approach used obtain .object use .weighted = TRUE instead. tau-equivalent reliability (\"rho_T\" \"cronbachs_alpha\") closed-form confidence interval may computed (Trinchera et al. 2018)  setting .closed_form_ci = TRUE (default FALSE). .alpha vector several CIs returned.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/reliability.html","id":"functions","dir":"Reference","previous_headings":"","what":"Functions","title":"Reliability — reliability","text":"calculateRhoC(): Calculate congeneric reliability calculateRhoT(): Calculate tau-equivalent reliability","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/reliability.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Reliability — reliability","text":"Trinchera L, Marie N, Marcoulides GA (2018). “Distribution Free Interval Estimate Coefficient Alpha.” Structural Equation Modeling: Multidisciplinary Journal, 25(6), 876–887. doi:10.1080/10705511.2018.1431544 .","code":""},{"path":[]},{"path":"https://floschuberth.github.io/cSEM/reference/resampleData.html","id":null,"dir":"Reference","previous_headings":"","what":"Resample data — resampleData","title":"Resample data — resampleData","text":"Resample data data set using common resampling methods. bootstrap jackknife resampling, package users usually need call function directly use resamplecSEMResults() instead.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/resampleData.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Resample data — resampleData","text":"","code":"resampleData(  .object          = NULL,  .data            = NULL,  .resample_method = c(\"bootstrap\", \"jackknife\", \"permutation\",                        \"cross-validation\"),  .cv_folds        = 10,  .id              = NULL,  .R               = 499,  .seed            = NULL )"},{"path":"https://floschuberth.github.io/cSEM/reference/resampleData.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Resample data — resampleData","text":".object R object class cSEMResults resulting call csem(). .data data.frame, matrix list data either type. Possible column types classes data provided : \"logical\", \"numeric\" (\"double\" \"integer\"), \"factor\" (ordered unordered) mix several types. data may also include one character column whose column name must given .id. column assumed contain group identifiers used split data groups. .data provided, .object ignored. Defaults NULL. .resample_method Character string. resampling method use. One : \"bootstrap\", \"jackknife\", \"permutation\", \"cross-validation\". Defaults \"bootstrap\". .cv_folds Integer. number cross-validation folds use. Setting .cv_folds N (number observations) produces leave-one-cross-validation samples. Defaults 10. .id Character string integer. character string giving name integer position column .data whose levels used split .data groups. Defaults NULL. .R Integer. number bootstrap runs, permutation runs cross-validation repetitions use. Defaults 499. .seed Integer NULL. random seed use. Defaults NULL case arbitrary seed chosen. Note scope seed limited body function used . Hence, global seed altered!","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/resampleData.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Resample data — resampleData","text":"structure output depends type input resampling method: Bootstrap matrix data.frame without grouping variable provided (.e., .id = NULL), result list length .R (default 499). element list bootstrap (re)sample. grouping variable specified list data provided (list element assumed contain data one group), resampling done group. Hence, result list length equal number groups list element containing .R bootstrap samples based N_g observations group g. Jackknife matrix data.frame without grouping variable provided (.id = NULL), result list length equal number observations/rows (N) data set provided. element list jackknife (re)sample. grouping variable specified list data provided (list element assumed contain data one group), resampling done group. Hence, result list length equal number group levels list element containing N jackknife samples based N_g observations group g. Permutation matrix data.frame without grouping variable provided error returned permutation simply reorder observations. grouping variable specified list data provided (list element assumed contain data one group), group membership permuted. Hence, result list length .R element list permutation (re)sample. Cross-validation matrix data.frame without grouping variable provided list length .R returned. list element contains list containing k splits/folds subsequently used test training data sets. grouping variable specified list data provided (list element assumed contain data one group), cross-validation repeated .R times group. Hence, result list length equal number groups, containing .R list elements (repetitions) turn contain k splits/folds.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/resampleData.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Resample data — resampleData","text":"function resampleData() general purpose. simply resamples data data set according resampling method provided via .resample_method argument returns list resamples. Currently, bootstrap, jackknife, permutation,  cross-validation (leave-one-(LOOCV) k-fold cross-validation) implemented. user may provide data set resample either explicitly via .data argument implicitly providing cSEMResults objects .object case original data used call created cSEMResults object used resampling. , cSEMResults object data set via .data provided former ignored. csem() accepts single data set, list data sets well data sets contain column name used split data groups, cSEMResults object may contain multiple data sets. case, resampling done data set group. Note depending number data sets/groups provided computation may slower resampling repeated data set/group. split data provided via .data argument groups, column name column index column containing group levels split data must given .id. data contains grouping taken cSEMResults object, .id taken object information. Hence, providing  .id redundant case therefore ignored. number bootstrap permutation runs well number cross-validation repetitions given .R. default 499 increased real applications. See e.g., Hesterberg (2015) , p.380 recommendations concerning bootstrap. jackknife .R ignored based N leave-one-data sets. Choosing resample_method = \"permutation\" ungrouped data causes error permutation simply reorder observations usually meaningful. list data provided list element assumed represent observations belonging one group. case, data pooled group adherence permuted. cross-validation number folds (k) defaults 10. may changed via .cv_folds argument. Setting k = 2 (1!) splits data single training test data set. Setting k = N (N number observations) produces leave-one-cross-validation samples. Note: 1.) least 2 folds required  (k > 1); 2.) k can larger N; 3.) N/k integer last fold less observations. Random number generation (RNG) uses L'Ecuyer-CRMR RGN stream implemented future.apply package (Bengtsson 2018) . See ?future_lapply details. default random seed chosen.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/resampleData.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Resample data — resampleData","text":"Bengtsson H (2018). future.apply: Apply Function Elements Parallel using Futures. R package version 1.0.1, https://CRAN.R-project.org/package=future.apply. Hesterberg TC (2015). “Teachers Know Bootstrap: Resampling Undergraduate Statistics Curriculum.” American Statistician, 69(4), 371–386. doi:10.1080/00031305.2015.1089789 .","code":""},{"path":[]},{"path":"https://floschuberth.github.io/cSEM/reference/resampleData.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Resample data — resampleData","text":"","code":"# =========================================================================== # Using the raw data  # =========================================================================== ### Bootstrap (default) -----------------------------------------------------  res_boot1 <- resampleData(.data = satisfaction) str(res_boot1, max.level = 3, list.len = 3) #> List of 499 #>  $ :'data.frame':\t250 obs. of  27 variables: #>   ..$ imag1: int [1:250] 8 8 4 7 10 7 8 10 10 7 ... #>   ..$ imag2: int [1:250] 6 8 5 7 10 9 8 8 10 7 ... #>   ..$ imag3: int [1:250] 8 8 5 7 10 9 8 8 10 8 ... #>   .. [list output truncated] #>  $ :'data.frame':\t250 obs. of  27 variables: #>   ..$ imag1: int [1:250] 9 10 7 6 10 9 8 8 10 8 ... #>   ..$ imag2: int [1:250] 8 10 7 8 10 8 7 5 10 8 ... #>   ..$ imag3: int [1:250] 9 8 7 8 10 8 8 9 8 3 ... #>   .. [list output truncated] #>  $ :'data.frame':\t250 obs. of  27 variables: #>   ..$ imag1: int [1:250] 10 8 7 9 9 8 10 10 8 9 ... #>   ..$ imag2: int [1:250] 10 7 9 8 8 10 10 10 10 10 ... #>   ..$ imag3: int [1:250] 10 7 9 9 8 9 10 10 10 9 ... #>   .. [list output truncated] #>   [list output truncated]  ## To replicate a bootstrap draw use .seed: res_boot1a <- resampleData(.data = satisfaction, .seed = 2364) res_boot1b <- resampleData(.data = satisfaction, .seed = 2364)                             identical(res_boot1, res_boot1a) # TRUE #> [1] FALSE  ### Jackknife ---------------------------------------------------------------  res_jack <- resampleData(.data = satisfaction, .resample_method = \"jackknife\") str(res_jack, max.level = 3, list.len = 3) #> List of 250 #>  $ :'data.frame':\t249 obs. of  27 variables: #>   ..$ imag1: int [1:249] 9 9 8 10 7 5 9 9 10 2 ... #>   ..$ imag2: int [1:249] 9 8 9 10 8 5 9 8 10 2 ... #>   ..$ imag3: int [1:249] 10 8 8 8 8 5 9 9 10 8 ... #>   .. [list output truncated] #>  $ :'data.frame':\t249 obs. of  27 variables: #>   ..$ imag1: int [1:249] 8 9 8 10 7 5 9 9 10 2 ... #>   ..$ imag2: int [1:249] 8 8 9 10 8 5 9 8 10 2 ... #>   ..$ imag3: int [1:249] 9 8 8 8 8 5 9 9 10 8 ... #>   .. [list output truncated] #>  $ :'data.frame':\t249 obs. of  27 variables: #>   ..$ imag1: int [1:249] 8 9 8 10 7 5 9 9 10 2 ... #>   ..$ imag2: int [1:249] 8 9 9 10 8 5 9 8 10 2 ... #>   ..$ imag3: int [1:249] 9 10 8 8 8 5 9 9 10 8 ... #>   .. [list output truncated] #>   [list output truncated]  ### Cross-validation -------------------------------------------------------- ## Create dataset for illustration: dat <- data.frame(   \"x1\" = rnorm(100),   \"x2\" = rnorm(100),   \"group\" = sample(c(\"male\", \"female\"), size = 100, replace = TRUE),   stringsAsFactors = FALSE)  ## 10-fold cross-validation (repeated 100 times) cv_10a <- resampleData(.data = dat, .resample_method = \"cross-validation\",                        .R = 100) str(cv_10a, max.level = 3, list.len = 3) #> List of 100 #>  $ :List of 10 #>   ..$ 1 :'data.frame':\t10 obs. of  3 variables: #>   .. ..$ x1   : num [1:10] -0.464 -0.242 -1.595 0.619 0.837 ... #>   .. ..$ x2   : num [1:10] -0.535 1.066 -0.265 0.314 0.796 ... #>   .. ..$ group: chr [1:10] \"male\" \"female\" \"female\" \"male\" ... #>   ..$ 2 :'data.frame':\t10 obs. of  3 variables: #>   .. ..$ x1   : num [1:10] -0.489 0.854 -0.23 -0.393 -1.261 ... #>   .. ..$ x2   : num [1:10] 0.709 -0.99 -0.463 0.499 -1.649 ... #>   .. ..$ group: chr [1:10] \"female\" \"male\" \"female\" \"female\" ... #>   ..$ 3 :'data.frame':\t10 obs. of  3 variables: #>   .. ..$ x1   : num [1:10] 0.852 2.15 -0.628 0.603 0.79 ... #>   .. ..$ x2   : num [1:10] -0.947 -1.829 0.736 0.449 1.227 ... #>   .. ..$ group: chr [1:10] \"male\" \"male\" \"male\" \"female\" ... #>   .. [list output truncated] #>  $ :List of 10 #>   ..$ 1 :'data.frame':\t10 obs. of  3 variables: #>   .. ..$ x1   : num [1:10] -0.375 1.234 -0.977 0.603 1.377 ... #>   .. ..$ x2   : num [1:10] -0.868 -0.564 0.693 0.449 1.092 ... #>   .. ..$ group: chr [1:10] \"male\" \"female\" \"male\" \"female\" ... #>   ..$ 2 :'data.frame':\t10 obs. of  3 variables: #>   .. ..$ x1   : num [1:10] -0.242 -1.334 -0.752 0.3 -0.628 ... #>   .. ..$ x2   : num [1:10] 0.667 -1.814 0.463 1.797 0.736 ... #>   .. ..$ group: chr [1:10] \"female\" \"female\" \"male\" \"female\" ... #>   ..$ 3 :'data.frame':\t10 obs. of  3 variables: #>   .. ..$ x1   : num [1:10] -0.393 -0.773 0.629 1.646 1.185 ... #>   .. ..$ x2   : num [1:10] 0.499 0.536 -0.14 -0.973 -0.161 ... #>   .. ..$ group: chr [1:10] \"female\" \"female\" \"male\" \"female\" ... #>   .. [list output truncated] #>  $ :List of 10 #>   ..$ 1 :'data.frame':\t10 obs. of  3 variables: #>   .. ..$ x1   : num [1:10] -2.3483 -0.4889 -0.0062 0.3821 -0.2303 ... #>   .. ..$ x2   : num [1:10] -0.341 0.709 1.845 0.538 -0.463 ... #>   .. ..$ group: chr [1:10] \"male\" \"female\" \"female\" \"female\" ... #>   ..$ 2 :'data.frame':\t10 obs. of  3 variables: #>   .. ..$ x1   : num [1:10] 1.1762 -0.0887 0.0845 -0.0841 -0.2607 ... #>   .. ..$ x2   : num [1:10] -0.126 -1.388 0.786 -3.311 0.286 ... #>   .. ..$ group: chr [1:10] \"female\" \"female\" \"female\" \"female\" ... #>   ..$ 3 :'data.frame':\t10 obs. of  3 variables: #>   .. ..$ x1   : num [1:10] -1.568 0.664 0.794 1.177 0.452 ... #>   .. ..$ x2   : num [1:10] 2.70817 -0.11277 0.36237 0.52896 -0.00514 ... #>   .. ..$ group: chr [1:10] \"male\" \"male\" \"male\" \"male\" ... #>   .. [list output truncated] #>   [list output truncated]  # Cross-validation can be done by group if a group identifyer is provided: cv_10 <- resampleData(.data = dat, .resample_method = \"cross-validation\",                        .id = \"group\", .R = 100) #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: data length is not a multiple of split variable #> Warning: UNRELIABLE VALUE: One of the ‘future.apply’ iterations (‘future_lapply-1’) unexpectedly generated random numbers without declaring so. There is a risk that those random numbers are not statistically sound and the overall results might be invalid. To fix this, specify 'future.seed=TRUE'. This ensures that proper, parallel-safe random numbers are produced via the L'Ecuyer-CMRG method. To disable this check, use 'future.seed = NULL', or set option 'future.rng.onMisuse' to \"ignore\".  ## Leave-one-out-cross-validation (repeated 50 times) cv_loocv  <- resampleData(.data = dat[, -3],                            .resample_method = \"cross-validation\",                            .cv_folds = nrow(dat),                           .R = 50) str(cv_loocv, max.level = 2, list.len = 3) #> List of 50 #>  $ :List of 100 #>   ..$ 1  :'data.frame':\t1 obs. of  2 variables: #>   ..$ 2  :'data.frame':\t1 obs. of  2 variables: #>   ..$ 3  :'data.frame':\t1 obs. of  2 variables: #>   .. [list output truncated] #>  $ :List of 100 #>   ..$ 1  :'data.frame':\t1 obs. of  2 variables: #>   ..$ 2  :'data.frame':\t1 obs. of  2 variables: #>   ..$ 3  :'data.frame':\t1 obs. of  2 variables: #>   .. [list output truncated] #>  $ :List of 100 #>   ..$ 1  :'data.frame':\t1 obs. of  2 variables: #>   ..$ 2  :'data.frame':\t1 obs. of  2 variables: #>   ..$ 3  :'data.frame':\t1 obs. of  2 variables: #>   .. [list output truncated] #>   [list output truncated]  ### Permuation ---------------------------------------------------------------  res_perm <- resampleData(.data = dat, .resample_method = \"permutation\",                          .id = \"group\") str(res_perm, max.level = 2, list.len = 3) #> List of 499 #>  $ :'data.frame':\t100 obs. of  3 variables: #>   ..$ x1: num [1:100] -0.242 -0.468 -0.773 2.15 -1.334 ... #>   ..$ x2: num [1:100] 1.066 -0.536 0.536 -1.829 -1.814 ... #>   ..$ id: chr [1:100] \"female\" \"male\" \"male\" \"male\" ... #>  $ :'data.frame':\t100 obs. of  3 variables: #>   ..$ x1: num [1:100] -0.242 -0.468 -0.773 2.15 -1.334 ... #>   ..$ x2: num [1:100] 1.066 -0.536 0.536 -1.829 -1.814 ... #>   ..$ id: chr [1:100] \"female\" \"female\" \"female\" \"male\" ... #>  $ :'data.frame':\t100 obs. of  3 variables: #>   ..$ x1: num [1:100] -0.242 -0.468 -0.773 2.15 -1.334 ... #>   ..$ x2: num [1:100] 1.066 -0.536 0.536 -1.829 -1.814 ... #>   ..$ id: chr [1:100] \"female\" \"female\" \"female\" \"female\" ... #>   [list output truncated]  # Forgetting to set .id causes an error if (FALSE) { # \\dontrun{ res_perm <- resampleData(.data = dat, .resample_method = \"permutation\") } # }  # =========================================================================== # Using a cSEMResults object # ===========================================================================  model <- \" # Structural model QUAL ~ EXPE EXPE ~ IMAG SAT  ~ IMAG + EXPE + QUAL + VAL LOY  ~ IMAG + SAT VAL  ~ EXPE + QUAL  # Measurement model EXPE =~ expe1 + expe2 + expe3 + expe4 + expe5 IMAG =~ imag1 + imag2 + imag3 + imag4 + imag5 LOY  =~ loy1  + loy2  + loy3  + loy4 QUAL =~ qual1 + qual2 + qual3 + qual4 + qual5 SAT  =~ sat1  + sat2  + sat3  + sat4 VAL  =~ val1  + val2  + val3  + val4 \" a <- csem(satisfaction, model)  # Create bootstrap and jackknife samples res_boot <- resampleData(a, .resample_method = \"bootstrap\", .R = 499) res_jack <- resampleData(a, .resample_method = \"jackknife\")  # Since `satisfaction` is the dataset used the following approaches yield # identical results. res_boot_data   <- resampleData(.data = satisfaction, .seed = 2364) res_boot_object <- resampleData(a, .seed = 2364)  identical(res_boot_data, res_boot_object) # TRUE #> [1] TRUE"},{"path":"https://floschuberth.github.io/cSEM/reference/resamplecSEMResults.html","id":null,"dir":"Reference","previous_headings":"","what":"Resample cSEMResults — resamplecSEMResults","title":"Resample cSEMResults — resamplecSEMResults","text":"Resample cSEMResults object using bootstrap jackknife resampling. function called csem() user sets csem(..., .resample_method = \"bootstrap\") csem(..., .resample_method = \"jackknife\") may also called directly.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/resamplecSEMResults.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Resample cSEMResults — resamplecSEMResults","text":"","code":"resamplecSEMResults(  .object                = NULL,  .resample_method       = c(\"bootstrap\", \"jackknife\"),   .resample_method2      = c(\"none\", \"bootstrap\", \"jackknife\"),   .R                     = 499,  .R2                    = 199,  .handle_inadmissibles  = c(\"drop\", \"ignore\", \"replace\"),  .user_funs             = NULL,  .eval_plan             = c(\"sequential\", \"multicore\", \"multisession\"),  .force                 = FALSE,  .seed                  = NULL,  .sign_change_option    = c(\"none\",\"individual\",\"individual_reestimate\",                             \"construct_reestimate\"),  ... )"},{"path":"https://floschuberth.github.io/cSEM/reference/resamplecSEMResults.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Resample cSEMResults — resamplecSEMResults","text":".object R object class cSEMResults resulting call csem(). .resample_method Character string. resampling method use. One : \"bootstrap\" \"jackknife\". Defaults \"bootstrap\". .resample_method2 Character string. resampling method use resampling resample. One : \"none\", \"bootstrap\" \"jackknife\". \"bootstrap\" number draws provided via .R2. Currently, resampling resample required studentized confidence interval (\"CI_t_interval\") computed infer() function. Defaults \"none\". .R Integer. number bootstrap replications. Defaults 499. .R2 Integer. number bootstrap replications use resampling resample. Defaults 199. .handle_inadmissibles Character string. inadmissible results treated? One \"drop\", \"ignore\", \"replace\". \"drop\", replications/resamples yielding inadmissible result dropped (.e. number results returned potentially less .R). \"ignore\" results returned even replications yielded inadmissible results (.e. number results returned equal .R). \"replace\" resampling continues exactly .R admissible solutions. Depending frequency inadmissible solutions may significantly increase computing time. Defaults \"drop\". .user_funs function (named) list functions apply every resample. functions must take .object first argument (e.g., myFun <- function(.object, ...) {body---function}). Function output preferably (named) vector matrices also accepted. However, output vectorized (columnwise) case. See examples section details. .eval_plan Character string. evaluation plan use. One \"sequential\", \"multicore\", \"multisession\". two latter cases available cores used. Defaults \"sequential\". .force Logical. .object resampled even contains resamples already?. Defaults FALSE. .seed Integer NULL. random seed use. Defaults NULL case arbitrary seed chosen. Note scope seed limited body function used . Hence, global seed altered! .sign_change_option Character string. sign change option used handle flipping signs resampling? One \"none\",\"individual\", \"individual_reestimate\", \"construct_reestimate\". Defaults \"none\". ... arguments passed functions supplied .user_funs.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/resamplecSEMResults.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Resample cSEMResults — resamplecSEMResults","text":"core structure structure .object following elements added: $Estimates_resamples: list containing .R resamples original estimates resampled quantities (Path_estimates, Loading_estimates, Weight_estimates, user defined functions). list element list containing elements $Resamples $Original. $Resamples (.R x K) matrix row representing one resample K parameters/statistics. $Original contains original estimates (vectorized column output user provided function matrix. $Information_resamples: list containing additional information. Use str(<.object>, list.len = 3) resulting object overview.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/resamplecSEMResults.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Resample cSEMResults — resamplecSEMResults","text":"Given M resamples (bootstrap M = .R jackknife M = N, N number observations) based data used compute cSEMResults object provided via .object, resamplecSEMResults() essentially calls csem() resample using arguments original call (ignoring arguments related resampling) returns estimates subset practically useful resampled parameters/statistics computed csem(). Currently, following estimates computed returned default based resample: Path estimates, Loading estimates, Weight estimates. practical application users may need resample specific statistic (e.g, heterotrait-monotrait ratio correlations (HTMT) differences path coefficients beta_1 - beta_2). statistics may provided function fun(.object, ...) list functions via .user_funs argument. first argument functions must always .object. Internally, function applied resample produce desired statistic. Hence, arbitrary complicated statistics may resampled long body function draws elements contained cSEMResults object . Output fun(.object, ...) preferably (named) vector matrices also accepted. However, output vectorized (columnwise) case. See examples section details. resampling original cSEMResults object (call \"first resample\") resampling based resampled cSEMResults object (call \"second resample\") supported. Choices former \"bootstrap\" \"jackknife\". Resampling based resample turned default (.resample_method2 = \"none\") significantly increases computation time (now M * M2 resamples compute, M2 .R2 N). Resamples resample required, e.g., studentized confidence interval computed infer() function. Typically, bootstrap resamples used case (Davison Hinkley 1997) . csem() accepts single data set, list data sets well data sets contain column name used split data groups, cSEMResults object may contain multiple data sets. case, resampling done data set group. Note depending number data sets/groups, computation may considerably slower resampling repeated data set/group. However, apart speed considerations users don need worry type input used compute cSEMResults object resamplecSEMResults() able deal case. number bootstrap runs first second run given .R .R2. default 499 first 199 second run increased real applications. See e.g., Hesterberg (2015) , p.380, Davison Hinkley (1997) , Efron Hastie (2016)  recommendations. jackknife .R .R2 ignored. Resampling may produce inadmissible results (checked verify()). default results dropped however users may choose \"ignore\" \"replace\" inadmissible results resampling continuous necessary number admissible results reached. cSEM package supports (multi)processing via future framework (Bengtsson 2018) . Users may simply choose evaluation plan via .eval_plan package takes care complicated backend issues. Currently, users may choose standard single-core/single-session evaluation (\"sequential\") multiprocessing (\"multisession\" \"multicore\"). future package provides options (e.g., \"cluster\" \"remote\"), however, probably needed context cSEM package simulations usually require high-performance clusters. Depending operating system, future package manage distribute tasks multiple R sessions (Windows) multiple cores. Note multiprocessing necessary always faster \"small\" number replications required overhead initializing new sessions distributing tasks different cores immediately compensated availability multiple sessions/cores. Random number generation (RNG) uses L'Ecuyer-CRMR RGN stream implemented future.apply package (Bengtsson 2018) . independent evaluation plan. Hence, setting e.g., .seed = 123 generate random number replicates .eval_plan = \"sequential\", .eval_plan = \"multisession\", .eval_plan = \"multicore\". See ?future_lapply details.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/resamplecSEMResults.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Resample cSEMResults — resamplecSEMResults","text":"Bengtsson H (2018). future: Unified Parallel Distributed Processing R Everyone. R package version 1.10.0, https://CRAN.R-project.org/package=future. Bengtsson H (2018). future.apply: Apply Function Elements Parallel using Futures. R package version 1.0.1, https://CRAN.R-project.org/package=future.apply. Davison AC, Hinkley DV (1997). Bootstrap Methods Application. Cambridge University Press. doi:10.1017/cbo9780511802843 . Efron B, Hastie T (2016). Computer Age Statistical Inference. Cambridge University Pr. ISBN 1107149894. Hesterberg TC (2015). “Teachers Know Bootstrap: Resampling Undergraduate Statistics Curriculum.” American Statistician, 69(4), 371–386. doi:10.1080/00031305.2015.1089789 .","code":""},{"path":[]},{"path":"https://floschuberth.github.io/cSEM/reference/resamplecSEMResults.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Resample cSEMResults — resamplecSEMResults","text":"","code":"if (FALSE) { # \\dontrun{ # Note: example not run as resampling is time consuming # =========================================================================== # Basic usage # =========================================================================== model <- \" # Structural model QUAL ~ EXPE EXPE ~ IMAG SAT  ~ IMAG + EXPE + QUAL + VAL LOY  ~ IMAG + SAT VAL  ~ EXPE + QUAL  # Measurement model EXPE =~ expe1 + expe2 + expe3 + expe4 + expe5 IMAG =~ imag1 + imag2 + imag3 + imag4 + imag5 LOY  =~ loy1  + loy2  + loy3  + loy4 QUAL =~ qual1 + qual2 + qual3 + qual4 + qual5 SAT  =~ sat1  + sat2  + sat3  + sat4 VAL  =~ val1  + val2  + val3  + val4 \"  ## Estimate the model without resampling  a <- csem(satisfaction, model)  ## Bootstrap and jackknife estimation boot <- resamplecSEMResults(a) jack <- resamplecSEMResults(a, .resample_method = \"jackknife\")   ## Alternatively use .resample_method in csem() boot_csem <- csem(satisfaction, model, .resample_method = \"bootstrap\") jack_csem <- csem(satisfaction, model, .resample_method = \"jackknife\")  # =========================================================================== # Extended usage # =========================================================================== ### Double resampling  ------------------------------------------------------ # The confidence intervals (e.g. the bias-corrected and accelearated CI)  # require double resampling. Use .resample_method2 for this.  boot1 <- resamplecSEMResults(   .object = a,    .resample_method  = \"bootstrap\",    .R                = 50,   .resample_method2 = \"bootstrap\",    .R2               = 20,   .seed             = 1303   )  ## Again, this is identical to using csem  boot1_csem <- csem(   .data             = satisfaction,    .model            = model,    .resample_method  = \"bootstrap\",   .R                = 50,   .resample_method2 = \"bootstrap\",   .R2               = 20,   .seed             = 1303   )  identical(boot1, boot1_csem) # only true if .seed was set  ### Inference --------------------------------------------------------------- # To get inferencial quanitites such as the estimated standard error or # the percentile confidence intervall for each resampled quantity use  # postestimation function infer()  inference <- infer(boot1) inference$Path_estimates$sd inference$Path_estimates$CI_percentile  # As usual summarize() can be called directly summarize(boot1)  # In the example above .R x .R2 = 50 x 20 = 1000. Multiprocessing will be # faster on most systems here and is therefore recommended. Note that multiprocessing # does not affect the random number generation  boot2 <- resamplecSEMResults(   .object           = a,    .resample_method  = \"bootstrap\",    .R                = 50,   .resample_method2 = \"bootstrap\",    .R2               = 20,   .eval_plan        = \"multisession\",    .seed             = 1303   )  identical(boot1, boot2)} # }"},{"path":"https://floschuberth.github.io/cSEM/reference/satisfaction.html","id":null,"dir":"Reference","previous_headings":"","what":"Data: satisfaction — satisfaction","title":"Data: satisfaction — satisfaction","text":"data frame 250 observations 27 variables. Variables 1 27 refer six latent concepts: IMAG=Image, EXPE=Expectations, QUAL=Quality, VAL=Value, SAT=Satisfaction, LOY=Loyalty. imag1-imag5 Indicators attached concept IMAG supposed capture aspects institutions reputation, trustworthiness, seriousness, solidness, caring customer. expe1-expe5 Indicators attached concept EXPE supposed capture aspects concerning products services provided, customer service, providing solutions, expectations overall quality. qual1-qual5 Indicators attached concept QUAL supposed capture aspects concerning reliability products services, range products services, personal advice, overall perceived quality. val1-val4 Indicators attached concept VAL supposed capture aspects related beneficial services products, valuable investments, quality relative price, price relative quality. sat1-sat4 Indicators attached concept SAT supposed capture aspects concerning overall rating satisfaction, fulfillment expectations, satisfaction relative banks, performance relative customer's ideal bank. loy1-loy4 Indicators attached concept LOY supposed capture aspects concerning propensity choose bank , propensity switch bank, intention recommend bank friends, sense loyalty.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/satisfaction.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Data: satisfaction — satisfaction","text":"","code":"satisfaction"},{"path":"https://floschuberth.github.io/cSEM/reference/satisfaction.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Data: satisfaction — satisfaction","text":"object class data.frame 250 rows 27 columns.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/satisfaction.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Data: satisfaction — satisfaction","text":"plspm package (version  0.4.9). Original source according plspm: \"Laboratory Information Analysis Modeling (LIAM). Facultat d'Informatica de Barcelona, Universitat Politecnica de Catalunya\".","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/satisfaction.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Data: satisfaction — satisfaction","text":"dataset contains variables customer satisfaction study Spanish credit institution 250 customers. data identical dataset provided plspm package last column  (gender) removed. looking original dataset use satisfaction_gender dataset.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/satisfaction_gender.html","id":null,"dir":"Reference","previous_headings":"","what":"Data: satisfaction including gender — satisfaction_gender","title":"Data: satisfaction including gender — satisfaction_gender","text":"data frame 250 observations 28 variables. Variables 1 27 refer six latent concepts: IMAG=Image, EXPE=Expectations, QUAL=Quality, VAL=Value, SAT=Satisfaction, LOY=Loyalty. imag1-imag5 Indicators attached concept IMAG supposed capture aspects institutions reputation, trustworthiness, seriousness, solidness, caring customer. expe1-expe5 Indicators attached concept EXPE supposed capture aspects concerning products services provided, customer service, providing solutions, expectations overall quality. qual1-qual5 Indicators attached concept QUAL supposed capture aspects concerning reliability products services, range products services, personal advice, overall perceived quality. val1-val4 Indicators attached concept VAL supposed capture aspects related beneficial services products, valuable investments, quality relative price, price relative quality. sat1-sat4 Indicators attached concept SAT supposed capture aspects concerning overall rating satisfaction, fulfillment expectations, satisfaction relative banks, performance relative customer's ideal bank. loy1-loy4 Indicators attached concept LOY supposed capture aspects concerning propensity choose bank , propensity switch bank, intention recommend bank friends, sense loyalty. gender sex respondent.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/satisfaction_gender.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Data: satisfaction including gender — satisfaction_gender","text":"","code":"satisfaction_gender"},{"path":"https://floschuberth.github.io/cSEM/reference/satisfaction_gender.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Data: satisfaction including gender — satisfaction_gender","text":"object class data.frame 250 rows 28 columns.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/satisfaction_gender.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Data: satisfaction including gender — satisfaction_gender","text":"plspm package (version  0.4.9). Original source according plspm: \"Laboratory Information Analysis Modeling (LIAM). Facultat d'Informatica de Barcelona, Universitat Politecnica de Catalunya\".","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/satisfaction_gender.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Data: satisfaction including gender — satisfaction_gender","text":"data set contains variables customer satisfaction study Spanish credit institution 250 customers. data taken plspm package. convenience, version dataset last column (gender) removed: satisfaction.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/savePlot.html","id":null,"dir":"Reference","previous_headings":"","what":"savePlot — savePlot","title":"savePlot — savePlot","text":"function saves given plot cSEMResults object specified file format.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/savePlot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"savePlot — savePlot","text":"","code":"savePlot(  .plot_object,  .filename,  .path = NULL)"},{"path":"https://floschuberth.github.io/cSEM/reference/savePlot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"savePlot — savePlot","text":".plot_object Object returned one following functions plot.cSEMResults_default(), plot.cSEMResults_multi(), plot.cSEMResults_2ndorder(). .filename Character string. name file save plot (supports 'pdf', 'png', 'svg', 'dot' formats). .path Character string. Path directory save file . Defaults current working directory.","code":""},{"path":[]},{"path":"https://floschuberth.github.io/cSEM/reference/save_single_plot.html","id":null,"dir":"Reference","previous_headings":"","what":"Internal: save_single_plot Helper function to save a single DiagrammeR plot based on the file extension — save_single_plot","title":"Internal: save_single_plot Helper function to save a single DiagrammeR plot based on the file extension — save_single_plot","text":"diagrammer_obj DiagrammeR plot object saved. out_file name file save plot (supports 'pdf', 'png', 'svg', 'dot' formats).","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/save_single_plot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Internal: save_single_plot Helper function to save a single DiagrammeR plot based on the file extension — save_single_plot","text":"","code":"save_single_plot( diagrammer_obj,  out_file, .path = NULL)"},{"path":"https://floschuberth.github.io/cSEM/reference/save_single_plot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Internal: save_single_plot Helper function to save a single DiagrammeR plot based on the file extension — save_single_plot","text":".path Character string. Path directory save file . Defaults NULL.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/save_single_plot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Internal: save_single_plot Helper function to save a single DiagrammeR plot based on the file extension — save_single_plot","text":"NULL.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/scaleWeights.html","id":null,"dir":"Reference","previous_headings":"","what":"Internal: Scale weights — scaleWeights","title":"Internal: Scale weights — scaleWeights","text":"Scale weights formed composite unit variance.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/scaleWeights.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Internal: Scale weights — scaleWeights","text":"","code":"scaleWeights(   .S = args_default()$.S,    .W = args_default()$.W   )"},{"path":"https://floschuberth.github.io/cSEM/reference/scaleWeights.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Internal: Scale weights — scaleWeights","text":".S (K x K) empirical indicator correlation matrix. .W (J x K) matrix weights.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/scaleWeights.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Internal: Scale weights — scaleWeights","text":"(J x K) matrix scaled weights.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/secondOrderMeasurementEdges.html","id":null,"dir":"Reference","previous_headings":"","what":"Internal: secondOrderMeasurementEdges — secondOrderMeasurementEdges","title":"Internal: secondOrderMeasurementEdges — secondOrderMeasurementEdges","text":"Build measurement edges second–order model.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/secondOrderMeasurementEdges.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Internal: secondOrderMeasurementEdges — secondOrderMeasurementEdges","text":"","code":"secondOrderMeasurementEdges(  construct,  weights_first,  loadings_first,  weight_p_first,  loading_p_first,  weights_second,  loadings_second,  weight_p_second,  loading_p_second,  plot_signif,  plot_labels,  constructTypes,  only_second_stage = FALSE  )"},{"path":"https://floschuberth.github.io/cSEM/reference/secondOrderMeasurementEdges.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Internal: secondOrderMeasurementEdges — secondOrderMeasurementEdges","text":"plot_labels Logical. Whether display edge labels. Defaults TRUE.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/secondOrderMeasurementEdges.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Internal: secondOrderMeasurementEdges — secondOrderMeasurementEdges","text":"Character string.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/setDominantIndicator.html","id":null,"dir":"Reference","previous_headings":"","what":"Internal: Set the dominant indicator — setDominantIndicator","title":"Internal: Set the dominant indicator — setDominantIndicator","text":"Set dominant indicator construct. Since sign weights, thus loadings often determined, dominant indicator can chosen per block. sign weights chosen correlation dominant indicator composite positive.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/setDominantIndicator.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Internal: Set the dominant indicator — setDominantIndicator","text":"","code":"setDominantIndicator(  .W                   = args_default()$.W,  .dominant_indicators = args_default()$.dominant_indicators,   .S                   = args_default()$.S  )"},{"path":"https://floschuberth.github.io/cSEM/reference/setDominantIndicator.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Internal: Set the dominant indicator — setDominantIndicator","text":".W (J x K) matrix weights. .dominant_indicators character vector \"construct_name\" = \"indicator_name\" pairs, \"indicator_name\" character string giving name dominant indicator \"construct_name\" character string corresponding construct name. Dominant indicators may specified subset constructs. Default NULL. .S (K x K) empirical indicator correlation matrix.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/setDominantIndicator.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Internal: Set the dominant indicator — setDominantIndicator","text":"(J x K) matrix weights dominant indicator set.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/setStartingValues.html","id":null,"dir":"Reference","previous_headings":"","what":"Internal: Set starting values — setStartingValues","title":"Internal: Set starting values — setStartingValues","text":"Set starting values.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/setStartingValues.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Internal: Set starting values — setStartingValues","text":"","code":"setStartingValues(   .W               = args_default()$.W,   .starting_values = args_default()$.starting_values   )"},{"path":"https://floschuberth.github.io/cSEM/reference/setStartingValues.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Internal: Set starting values — setStartingValues","text":".W (J x K) matrix weights. .starting_values named list vectors list names construct names whose indicator weights user wishes set. vectors must named vectors \"indicator_name\" = value pairs, value (scaled unscaled) starting weight. Defaults NULL.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/setStartingValues.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Internal: Set starting values — setStartingValues","text":"(J x K) matrix starting values.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/structureTestMGDDecisions.html","id":null,"dir":"Reference","previous_headings":"","what":"Internal: get structured cSEMTestMGD results — structureTestMGDDecisions","title":"Internal: get structured cSEMTestMGD results — structureTestMGDDecisions","text":"Convenience function summarize results tests resulting call testMGD() user-friendly way.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/structureTestMGDDecisions.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Internal: get structured cSEMTestMGD results — structureTestMGDDecisions","text":"","code":"structureTestMGDDecisions(.object)"},{"path":"https://floschuberth.github.io/cSEM/reference/structureTestMGDDecisions.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Internal: get structured cSEMTestMGD results — structureTestMGDDecisions","text":".object R object class cSEMResults resulting call csem().","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/structureTestMGDDecisions.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Internal: get structured cSEMTestMGD results — structureTestMGDDecisions","text":"data.frame.","code":""},{"path":[]},{"path":"https://floschuberth.github.io/cSEM/reference/summarize.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarize model — summarize","text":"","code":"summarize(  .object = NULL,   .alpha  = 0.05,  .ci     = NULL,  ...  )"},{"path":"https://floschuberth.github.io/cSEM/reference/summarize.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summarize model — summarize","text":".object R object class cSEMResults resulting call csem(). .alpha integer numeric vector significance levels. Defaults 0.05. .ci vector character strings naming confidence interval compute. possible choices see infer(). ... arguments summarize(). Currently ignored.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/summarize.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summarize model — summarize","text":"object class cSEMSummarize. cSEMSummarize object structure cSEMResults object couple differences: Elements $Path_estimates, $Loadings_estimates, $Weight_estimates, $Weight_estimates,  $Residual_correlation standardized data frames instead matrices. Data frames $Effect_estimates, $Indicator_correlation, $Exo_construct_correlation added $Estimates. data frame format usually much convenient users intend present results e.g., paper presentation.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/summarize.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Summarize model — summarize","text":"summary mainly focused estimated parameters. quality criteria average variance extracted (AVE), reliability estimates, effect size estimates etc., use assess(). .object contains resamples, standard errors, t-values p-values (assuming estimates standard normally distributed) printed well. default percentile confidence interval given well. confidence intervals use .ci argument. See infer() possible choices description.","code":""},{"path":[]},{"path":"https://floschuberth.github.io/cSEM/reference/summarize.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summarize model — summarize","text":"","code":"## Take a look at the dataset #?threecommonfactors  ## Specify the (correct) model model <- \" # Structural model eta2 ~ eta1 eta3 ~ eta1 + eta2  # (Reflective) measurement model eta1 =~ y11 + y12 + y13 eta2 =~ y21 + y22 + y23 eta3 =~ y31 + y32 + y33 \"  ## Estimate res <- csem(threecommonfactors, model, .resample_method = \"bootstrap\", .R = 40)  ## Postestimation res_summarize <- summarize(res) res_summarize #> ________________________________________________________________________________ #> ----------------------------------- Overview ----------------------------------- #>  #> \tGeneral information: #> \t------------------------ #> \tEstimation status                  = Ok #> \tNumber of observations             = 500 #> \tWeight estimator                   = PLS-PM #> \tInner weighting scheme             = \"path\" #> \tType of indicator correlation      = Pearson #> \tPath model estimator               = OLS #> \tSecond-order approach              = NA #> \tType of path model                 = Linear #> \tDisattenuated                      = Yes (PLSc) #>  #> \tResample information: #> \t--------------------- #> \tResample method                    = \"bootstrap\" #> \tNumber of resamples                = 40 #> \tNumber of admissible results       = 40 #> \tApproach to handle inadmissibles   = \"drop\" #> \tSign change option                 = \"none\" #> \tRandom seed                        = -602767520 #>  #> \tConstruct details: #> \t------------------ #> \tName  Modeled as     Order         Mode       #>  #> \teta1  Common factor  First order   \"modeA\"    #> \teta2  Common factor  First order   \"modeA\"    #> \teta3  Common factor  First order   \"modeA\"    #>  #> ----------------------------------- Estimates ---------------------------------- #>  #> Estimated path coefficients: #> ============================ #>                                                              CI_percentile    #>   Path           Estimate  Std. error   t-stat.   p-value         95%         #>   eta2 ~ eta1      0.6713      0.0519   12.9309    0.0000 [ 0.5692; 0.7558 ]  #>   eta3 ~ eta1      0.4585      0.0829    5.5295    0.0000 [ 0.3415; 0.6295 ]  #>   eta3 ~ eta2      0.3052      0.0857    3.5625    0.0004 [ 0.1345; 0.4206 ]  #>  #> Estimated loadings: #> =================== #>                                                              CI_percentile    #>   Loading        Estimate  Std. error   t-stat.   p-value         95%         #>   eta1 =~ y11      0.6631      0.0290   22.8893    0.0000 [ 0.6162; 0.7301 ]  #>   eta1 =~ y12      0.6493      0.0381   17.0268    0.0000 [ 0.5720; 0.7063 ]  #>   eta1 =~ y13      0.7613      0.0326   23.3871    0.0000 [ 0.7021; 0.8089 ]  #>   eta2 =~ y21      0.5165      0.0581    8.8920    0.0000 [ 0.3735; 0.5861 ]  #>   eta2 =~ y22      0.7554      0.0361   20.9261    0.0000 [ 0.6927; 0.8202 ]  #>   eta2 =~ y23      0.7997      0.0346   23.0986    0.0000 [ 0.7373; 0.8618 ]  #>   eta3 =~ y31      0.8223      0.0315   26.0956    0.0000 [ 0.7520; 0.8691 ]  #>   eta3 =~ y32      0.6581      0.0489   13.4516    0.0000 [ 0.5585; 0.7339 ]  #>   eta3 =~ y33      0.7474      0.0477   15.6739    0.0000 [ 0.6440; 0.8236 ]  #>  #> Estimated weights: #> ================== #>                                                              CI_percentile    #>   Weight         Estimate  Std. error   t-stat.   p-value         95%         #>   eta1 <~ y11      0.3956      0.0197   20.0653    0.0000 [ 0.3676; 0.4369 ]  #>   eta1 <~ y12      0.3873      0.0147   26.3275    0.0000 [ 0.3599; 0.4157 ]  #>   eta1 <~ y13      0.4542      0.0187   24.2284    0.0000 [ 0.4100; 0.4860 ]  #>   eta2 <~ y21      0.3058      0.0305   10.0327    0.0000 [ 0.2255; 0.3406 ]  #>   eta2 <~ y22      0.4473      0.0189   23.7081    0.0000 [ 0.4273; 0.4803 ]  #>   eta2 <~ y23      0.4735      0.0239   19.8352    0.0000 [ 0.4326; 0.5192 ]  #>   eta3 <~ y31      0.4400      0.0233   18.9095    0.0000 [ 0.3864; 0.4785 ]  #>   eta3 <~ y32      0.3521      0.0196   18.0106    0.0000 [ 0.3122; 0.3959 ]  #>   eta3 <~ y33      0.3999      0.0233   17.1858    0.0000 [ 0.3505; 0.4487 ]  #>  #> ------------------------------------ Effects ----------------------------------- #>  #> Estimated total effects: #> ======================== #>                                                               CI_percentile    #>   Total effect    Estimate  Std. error   t-stat.   p-value         95%         #>   eta2 ~ eta1       0.6713      0.0519   12.9309    0.0000 [ 0.5692; 0.7558 ]  #>   eta3 ~ eta1       0.6634      0.0419   15.8453    0.0000 [ 0.5886; 0.7339 ]  #>   eta3 ~ eta2       0.3052      0.0857    3.5625    0.0004 [ 0.1345; 0.4206 ]  #>  #> Estimated indirect effects: #> =========================== #>                                                                  CI_percentile    #>   Indirect effect    Estimate  Std. error   t-stat.   p-value         95%         #>   eta3 ~ eta1          0.2049      0.0574    3.5718    0.0004 [ 0.0916; 0.3061 ]  #> ________________________________________________________________________________  # Extract e.g. the loadings res_summarize$Estimates$Loading_estimates #>          Name Construct_type  Estimate    Std_err    t_stat       p_value #> 1 eta1 =~ y11  Common factor 0.6630699 0.02896850 22.889339 5.933408e-116 #> 2 eta1 =~ y12  Common factor 0.6492779 0.03813279 17.026763  5.200264e-65 #> 3 eta1 =~ y13  Common factor 0.7613458 0.03255407 23.387119 5.779608e-121 #> 4 eta2 =~ y21  Common factor 0.5164548 0.05808096  8.891982  6.002843e-19 #> 5 eta2 =~ y22  Common factor 0.7553877 0.03609784 20.926121  3.096995e-97 #> 6 eta2 =~ y23  Common factor 0.7996637 0.03461955 23.098619 4.780379e-118 #> 7 eta3 =~ y31  Common factor 0.8222773 0.03151014 26.095640 4.085870e-150 #> 8 eta3 =~ y32  Common factor 0.6580689 0.04892138 13.451561  3.014392e-41 #> 9 eta3 =~ y33  Common factor 0.7474241 0.04768603 15.673858  2.282909e-55 #>   CI_percentile.95%L CI_percentile.95%U #> 1          0.6161619          0.7301045 #> 2          0.5719685          0.7063172 #> 3          0.7021251          0.8088675 #> 4          0.3735259          0.5861137 #> 5          0.6927195          0.8201709 #> 6          0.7372719          0.8617874 #> 7          0.7519506          0.8690608 #> 8          0.5584594          0.7338764 #> 9          0.6439522          0.8235972  ## By default only the 95% percentile confidence interval is printed. User ## can have several confidence interval computed, however, only the first ## will be printed.  res_summarize <- summarize(res, .ci = c(\"CI_standard_t\", \"CI_percentile\"),                             .alpha = c(0.05, 0.01)) res_summarize #> ________________________________________________________________________________ #> ----------------------------------- Overview ----------------------------------- #>  #> \tGeneral information: #> \t------------------------ #> \tEstimation status                  = Ok #> \tNumber of observations             = 500 #> \tWeight estimator                   = PLS-PM #> \tInner weighting scheme             = \"path\" #> \tType of indicator correlation      = Pearson #> \tPath model estimator               = OLS #> \tSecond-order approach              = NA #> \tType of path model                 = Linear #> \tDisattenuated                      = Yes (PLSc) #>  #> \tResample information: #> \t--------------------- #> \tResample method                    = \"bootstrap\" #> \tNumber of resamples                = 40 #> \tNumber of admissible results       = 40 #> \tApproach to handle inadmissibles   = \"drop\" #> \tSign change option                 = \"none\" #> \tRandom seed                        = -602767520 #>  #> \tConstruct details: #> \t------------------ #> \tName  Modeled as     Order         Mode       #>  #> \teta1  Common factor  First order   \"modeA\"    #> \teta2  Common factor  First order   \"modeA\"    #> \teta3  Common factor  First order   \"modeA\"    #>  #> ----------------------------------- Estimates ----------------------------------By default, only one confidence interval supplied to `.ci` is printed. #> Use `xxx` to print all confidence intervals (not yet implemented). #>  #>  #>  #> Estimated path coefficients: #> ============================ #>                                                              CI_standard_t    #>   Path           Estimate  Std. error   t-stat.   p-value         99%         #>   eta2 ~ eta1      0.6713      0.0519   12.9309    0.0000 [ 0.5425; 0.8110 ]  #>   eta3 ~ eta1      0.4585      0.0829    5.5295    0.0000 [ 0.2340; 0.6628 ]  #>   eta3 ~ eta2      0.3052      0.0857    3.5625    0.0004 [ 0.0965; 0.5395 ]  #>  #> Estimated loadings: #> =================== #>                                                              CI_standard_t    #>   Loading        Estimate  Std. error   t-stat.   p-value         99%         #>   eta1 =~ y11      0.6631      0.0290   22.8893    0.0000 [ 0.5833; 0.7331 ]  #>   eta1 =~ y12      0.6493      0.0381   17.0268    0.0000 [ 0.5576; 0.7548 ]  #>   eta1 =~ y13      0.7613      0.0326   23.3871    0.0000 [ 0.6793; 0.8476 ]  #>   eta2 =~ y21      0.5165      0.0581    8.8920    0.0000 [ 0.3839; 0.6842 ]  #>   eta2 =~ y22      0.7554      0.0361   20.9261    0.0000 [ 0.6554; 0.8421 ]  #>   eta2 =~ y23      0.7997      0.0346   23.0986    0.0000 [ 0.7163; 0.8953 ]  #>   eta3 =~ y31      0.8223      0.0315   26.0956    0.0000 [ 0.7531; 0.9160 ]  #>   eta3 =~ y32      0.6581      0.0489   13.4516    0.0000 [ 0.5268; 0.7798 ]  #>   eta3 =~ y33      0.7474      0.0477   15.6739    0.0000 [ 0.6292; 0.8758 ]  #>  #> Estimated weights: #> ================== #>                                                              CI_standard_t    #>   Weight         Estimate  Std. error   t-stat.   p-value         99%         #>   eta1 <~ y11      0.3956      0.0197   20.0653    0.0000 [ 0.3404; 0.4424 ]  #>   eta1 <~ y12      0.3873      0.0147   26.3275    0.0000 [ 0.3527; 0.4288 ]  #>   eta1 <~ y13      0.4542      0.0187   24.2284    0.0000 [ 0.4057; 0.5027 ]  #>   eta2 <~ y21      0.3058      0.0305   10.0327    0.0000 [ 0.2351; 0.3927 ]  #>   eta2 <~ y22      0.4473      0.0189   23.7081    0.0000 [ 0.3904; 0.4880 ]  #>   eta2 <~ y23      0.4735      0.0239   19.8352    0.0000 [ 0.4108; 0.5342 ]  #>   eta3 <~ y31      0.4400      0.0233   18.9095    0.0000 [ 0.3823; 0.5027 ]  #>   eta3 <~ y32      0.3521      0.0196   18.0106    0.0000 [ 0.2964; 0.3975 ]  #>   eta3 <~ y33      0.3999      0.0233   17.1858    0.0000 [ 0.3392; 0.4595 ]  #>  #> ------------------------------------ Effects ----------------------------------- #>  #> Estimated total effects: #> ======================== #>                                                               CI_standard_t    #>   Total effect    Estimate  Std. error   t-stat.   p-value         99%         #>   eta2 ~ eta1       0.6713      0.0519   12.9309    0.0000 [ 0.5425; 0.8110 ]  #>   eta3 ~ eta1       0.6634      0.0419   15.8453    0.0000 [ 0.5562; 0.7727 ]  #>   eta3 ~ eta2       0.3052      0.0857    3.5625    0.0004 [ 0.0965; 0.5395 ]  #>  #> Estimated indirect effects: #> =========================== #>                                                                  CI_standard_t    #>   Indirect effect    Estimate  Std. error   t-stat.   p-value         99%         #>   eta3 ~ eta1          0.2049      0.0574    3.5718    0.0004 [ 0.0677; 0.3643 ]  #> ________________________________________________________________________________  # Extract the loading including both confidence intervals res_summarize$Estimates$Path_estimates #>          Name Construct_type  Estimate    Std_err    t_stat      p_value #> 1 eta2 ~ eta1  Common factor 0.6713334 0.05191709 12.930876 3.013671e-38 #> 2 eta3 ~ eta1  Common factor 0.4585068 0.08292029  5.529488 3.211659e-08 #> 3 eta3 ~ eta2  Common factor 0.3051511 0.08565626  3.562508 3.673286e-04 #>   CI_standard_t.99%L CI_standard_t.99%U CI_standard_t.95%L CI_standard_t.95%U #> 1         0.54254865          0.8110345          0.5747886          0.7787946 #> 2         0.23402727          0.6628442          0.2855198          0.6113516 #> 3         0.09649013          0.5394559          0.1496817          0.4862644 #>   CI_percentile.99%L CI_percentile.99%U CI_percentile.95%L CI_percentile.95%U #> 1          0.5628779          0.7725017          0.5691582          0.7558416 #> 2          0.3394982          0.6298116          0.3414924          0.6295352 #> 3          0.1263031          0.4370055          0.1344842          0.4205521"},{"path":[]},{"path":"https://floschuberth.github.io/cSEM/reference/testCVPAT.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Perform a Cross-Validated Predictive Ability Test (CVPAT) — testCVPAT","text":"","code":"testCVPAT( .object1              = NULL, .object2              = NULL, .approach_predict     = c(\"earliest\", \"direct\"), .seed                 = NULL, .cv_folds             = 10, .handle_inadmissibles = c(\"stop\", \"ignore\"), .testtype             = c(\"twosided\", \"onesided\"))"},{"path":"https://floschuberth.github.io/cSEM/reference/testCVPAT.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Perform a Cross-Validated Predictive Ability Test (CVPAT) — testCVPAT","text":".object1 R object class cSEMResults resulting call csem(). .object2 R object class cSEMResults resulting call csem(). .approach_predict Character string. approach used predictions? One \"earliest\" \"direct\". \"earliest\" predictions indicators associated endogenous constructs performed using indicators associated exogenous constructs. \"direct\", predictions indicators associated endogenous constructs based indicators associated direct antecedents. Defaults \"earliest\". .seed Integer NULL. random seed use. Defaults NULL case arbitrary seed chosen. Note scope seed limited body function used . Hence, global seed altered! .cv_folds Integer. number cross-validation folds use. Setting .cv_folds N (number observations) produces leave-one-cross-validation samples. Defaults 10. .handle_inadmissibles Character string. inadmissible results treated? One \"drop\", \"ignore\", \"replace\". \"drop\", replications/resamples yielding inadmissible result dropped (.e. number results returned potentially less .R). \"ignore\" results returned even replications yielded inadmissible results (.e. number results returned equal .R). \"replace\" resampling continues exactly .R admissible solutions. Depending frequency inadmissible solutions may significantly increase computing time. Defaults \"drop\". .testtype Character string. One \"twosided\" (H1: models perform equally predicting indicators belonging endogenous constructs)\" onesided\" (H1: Model 1 performs better predicting indicators belonging endogenous constructs model2). Defaults \"twosided\".","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/testCVPAT.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Perform a Cross-Validated Predictive Ability Test (CVPAT) — testCVPAT","text":"object class cSEMCVPAT print plot methods. Technically, cSEMCVPAT named list containing following list elements: '$Information' Additional information.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/testCVPAT.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Perform a Cross-Validated Predictive Ability Test (CVPAT) — testCVPAT","text":"Perform Cross-Validated Predictive Ability Test (CVPAT) described (Liengaard et al. 2020) . predictive performance two models based dataset compared. , average difference losses predictions compared models.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/testCVPAT.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Perform a Cross-Validated Predictive Ability Test (CVPAT) — testCVPAT","text":"Liengaard BD, Sharma PN, Hult GTM, Jensen MB, Sarstedt M, Hair JF, Ringle CM (2020). “Prediction: Coveted, Yet Forsaken? Introducing Cross-Validated Predictive Ability Test Partial Least Squares Path Modeling.” Decision Sciences, 52(2), 362–392. doi:10.1111/deci.12445 .","code":""},{"path":[]},{"path":"https://floschuberth.github.io/cSEM/reference/testCVPAT.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Perform a Cross-Validated Predictive Ability Test (CVPAT) — testCVPAT","text":"","code":"### Anime example taken from https://github.com/ISS-Analytics/pls-predict/  # Load data data(Anime) # data is similar to the Anime.csv found on              # https://github.com/ISS-Analytics/pls-predict/ but with irrelevant             # columns removed  # Split into training and data the same way as it is done on  # https://github.com/ISS-Analytics/pls-predict/ set.seed(123)  index     <- sample.int(dim(Anime)[1], 83, replace = FALSE) dat_train <- Anime[-index, ] dat_test  <- Anime[index, ]  # Specify model model <- \" # Structural model  ApproachAvoidance ~ PerceivedVisualComplexity + Arousal  # Measurement/composite model  ApproachAvoidance         =~ AA0 + AA1 + AA2 + AA3 PerceivedVisualComplexity <~ VX0 + VX1 + VX2 + VX3 + VX4 Arousal                   <~ Aro1 + Aro2 + Aro3 + Aro4 \"  # Estimate (replicating the results of the `simplePLS()` function) res <- csem(dat_train,              model,              .disattenuate = FALSE, # original PLS             .iter_max = 300,              .tolerance = 1e-07,              .PLS_weight_scheme_inner = \"factorial\" )  # Predict using a user-supplied training data set pp <- predict(res, .test_data = dat_test) #> Warning: The following warning occured in the `predict()` function: #> Disattenuation is not applicable to benchmark `lm` and ignored. pp #> ________________________________________________________________________________ #> ----------------------------------- Overview ----------------------------------- #>  #> \tNumber of obs. training            = 100 #> \tNumber of obs. test                = 83 #> \tNumber of cv folds                 = NA #> \tNumber of repetitions              = 1 #> \tHandle inadmissibles               = stop #> \tEstimator target                   = 'PLS-PM' #> \tEstimator benchmark                = 'lm' #> \tDisattenuation target              = 'FALSE' #> \tDisattenuation benchmark           = 'FALSE' #> \tApproach to predict                = 'earliest' #>  #> ------------------------------ Prediction metrics ------------------------------ #>  #>  #>   Name    MAE target  MAE benchmark  RMSE target RMSE benchmark   Q2_predict #>   AA0         1.2125         1.1621       1.5575         1.5045       0.4625 #>   AA1         1.5319         1.5711       1.9005         1.9829       0.2794 #>   AA2         0.9891         0.9804       1.3993         1.4029       0.4396 #>   AA3         1.0564         1.0472       1.4434         1.4787       0.3656 #> ________________________________________________________________________________  ### Compute prediction metrics  ------------------------------------------------ res2 <- csem(Anime, # whole data set             model,              .disattenuate = FALSE, # original PLS             .iter_max = 300,              .tolerance = 1e-07,              .PLS_weight_scheme_inner = \"factorial\" )  # Predict using 10-fold cross-validation if (FALSE) { # \\dontrun{ pp2 <- predict(res, .benchmark = \"lm\") pp2 ## There is a plot method available plot(pp2)} # }  ### Example using OrdPLScPredict ----------------------------------------------- # Transform the numerical indicators into factors if (FALSE) { # \\dontrun{ data(\"BergamiBagozzi2000\") data_new <- data.frame(cei1    = as.ordered(BergamiBagozzi2000$cei1),                        cei2    = as.ordered(BergamiBagozzi2000$cei2),                        cei3    = as.ordered(BergamiBagozzi2000$cei3),                        cei4    = as.ordered(BergamiBagozzi2000$cei4),                        cei5    = as.ordered(BergamiBagozzi2000$cei5),                        cei6    = as.ordered(BergamiBagozzi2000$cei6),                        cei7    = as.ordered(BergamiBagozzi2000$cei7),                        cei8    = as.ordered(BergamiBagozzi2000$cei8),                        ma1     = as.ordered(BergamiBagozzi2000$ma1),                        ma2     = as.ordered(BergamiBagozzi2000$ma2),                        ma3     = as.ordered(BergamiBagozzi2000$ma3),                        ma4     = as.ordered(BergamiBagozzi2000$ma4),                        ma5     = as.ordered(BergamiBagozzi2000$ma5),                        ma6     = as.ordered(BergamiBagozzi2000$ma6),                        orgcmt1 = as.ordered(BergamiBagozzi2000$orgcmt1),                        orgcmt2 = as.ordered(BergamiBagozzi2000$orgcmt2),                        orgcmt3 = as.ordered(BergamiBagozzi2000$orgcmt3),                        orgcmt5 = as.ordered(BergamiBagozzi2000$orgcmt5),                        orgcmt6 = as.ordered(BergamiBagozzi2000$orgcmt6),                        orgcmt7 = as.ordered(BergamiBagozzi2000$orgcmt7),                        orgcmt8 = as.ordered(BergamiBagozzi2000$orgcmt8))  model <- \" # Measurement models OrgPres =~ cei1 + cei2 + cei3 + cei4 + cei5 + cei6 + cei7 + cei8 OrgIden =~ ma1 + ma2 + ma3 + ma4 + ma5 + ma6 AffJoy  =~ orgcmt1 + orgcmt2 + orgcmt3 + orgcmt7 AffLove =~ orgcmt5 + orgcmt 6 + orgcmt8  # Structural model OrgIden ~ OrgPres AffLove ~ OrgIden AffJoy  ~ OrgIden  \" # Estimate using cSEM; note: the fact that indicators are factors triggers OrdPLSc res <- csem(.model = model, .data = data_new[1:250,]) summarize(res)  # Predict using OrdPLSPredict set.seed(123) pred <- predict(   .object = res,    .benchmark = \"PLS-PM\",   .test_data = data_new[(251):305,],    .treat_as_continuous = TRUE, .approach_score_target = \"median\"   )  pred  round(pred$Prediction_metrics[, -1], 4)} # }"},{"path":[]},{"path":"https://floschuberth.github.io/cSEM/reference/testHausman.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Regression-based Hausman test — testHausman","text":"","code":"testHausman(  .object               = NULL,  .eval_plan            = c(\"sequential\", \"multicore\", \"multisession\"),  .handle_inadmissibles = c(\"drop\", \"ignore\", \"replace\"),  .R                    = 499,  .resample_method      = c(\"bootstrap\", \"jackknife\"),  .seed                 = NULL  )"},{"path":"https://floschuberth.github.io/cSEM/reference/testHausman.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Regression-based Hausman test — testHausman","text":".object R object class cSEMResults resulting call csem(). .eval_plan Character string. evaluation plan use. One \"sequential\", \"multicore\", \"multisession\". two latter cases available cores used. Defaults \"sequential\". .handle_inadmissibles Character string. inadmissible results treated? One \"drop\", \"ignore\", \"replace\". \"drop\", replications/resamples yielding inadmissible result dropped (.e. number results returned potentially less .R). \"ignore\" results returned even replications yielded inadmissible results (.e. number results returned equal .R). \"replace\" resampling continues exactly .R admissible solutions. Depending frequency inadmissible solutions may significantly increase computing time. Defaults \"drop\". .R Integer. number bootstrap replications. Defaults 499. .resample_method Character string. resampling method use. One : \"none\", \"bootstrap\" \"jackknife\". Defaults \"none\". .seed Integer NULL. random seed use. Defaults NULL case arbitrary seed chosen. Note scope seed limited body function used . Hence, global seed altered!","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/testHausman.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Regression-based Hausman test — testHausman","text":"Calculates regression-based Hausman test used compare OLS 2SLS estimates 2SLS 3SLS estimates. See e.g., Wooldridge (2010)  (pages 131 f.) details. function somewhat experimental. use know .","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/testHausman.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Regression-based Hausman test — testHausman","text":"Wooldridge JM (2010). Econometric Analysis Cross Section Panel Data, 2 edition. MIT Press.","code":""},{"path":[]},{"path":"https://floschuberth.github.io/cSEM/reference/testHausman.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Regression-based Hausman test — testHausman","text":"","code":"### Example from Dijkstra & Hensler (2015) ## Prepartion (values are from p. 15-16 of the paper) Lambda <- t(kronecker(diag(6), c(0.7, 0.7, 0.7))) Phi <- matrix(c(1.0000, 0.5000, 0.5000, 0.5000, 0.0500, 0.4000,                  0.5000, 1.0000, 0.5000, 0.5000, 0.5071, 0.6286,                 0.5000, 0.5000, 1.0000, 0.5000, 0.2929, 0.7714,                 0.5000, 0.5000, 0.5000, 1.0000, 0.2571, 0.6286,                 0.0500, 0.5071, 0.2929, 0.2571, 1.0000, sqrt(0.5),                 0.4000, 0.6286, 0.7714, 0.6286, sqrt(0.5), 1.0000),                ncol = 6)  ## Create population indicator covariance matrix Sigma <- t(Lambda) %*% Phi %*% Lambda diag(Sigma) <- 1 dimnames(Sigma) <- list(paste0(\"x\", rep(1:6, each = 3), 1:3),                         paste0(\"x\", rep(1:6, each = 3), 1:3))  ## Generate data dat <- MASS::mvrnorm(n = 500, mu = rep(0, 18), Sigma = Sigma, empirical = TRUE) # empirical = TRUE to show that 2SLS is in fact able to recover the true population # parameters.  ## Model to estimate model <- \" ## Structural model (nonrecurisve) eta5 ~ eta6 + eta1 + eta2 eta6 ~ eta5 + eta3 + eta4  ## Measurement model eta1 =~ x11 + x12 + x13 eta2 =~ x21 + x22 + x23 eta3 =~ x31 + x32 + x33 eta4 =~ x41 + x42 + x43  eta5 =~ x51 + x52 + x53 eta6 =~ x61 + x62 + x63 \"  library(cSEM)  ## Estimate res_ols <- csem(dat, .model = model, .approach_paths = \"OLS\") sum_res_ols <- summarize(res_ols)   # Note: For the example the model-implied indicator correlation is irrelevant #       the warnings can be ignored.  res_2sls <- csem(dat, .model = model, .approach_paths = \"2SLS\",                  .instruments = list(\"eta5\" = c('eta1','eta2','eta3','eta4'),                                       \"eta6\" = c('eta1','eta2','eta3','eta4'))) sum_res_2sls <- summarize(res_2sls) # Note that exogenous constructs are supplied as instruments for themselves!  ## Test for endogeneity test_ha <- testHausman(res_2sls, .R = 200) test_ha #> ________________________________________________________________________________ #> ───────────────────────── Regression-based Hausman test ──────────────────────── #>  #> Null hypothesis: #>  #>    ┌──────────────────────────────────────────────────────────────────────────┐ #>    │                                                                          │ #>    │   H0: Variable(s) suspected to be endogenous are uncorrelated with the   │ #>    │   error term (no endogeneity).                                           │ #>    │                                                                          │ #>    └──────────────────────────────────────────────────────────────────────────┘ #>  #> Regression output:  #>  #> \t #>   Dependent construct: 'eta5' #>  #> \tIndependent construct    Estimate  Std. error   t-stat.   p-value #> \teta1                      -0.3000      0.1165   -2.5760    0.0100 #> \teta2                       0.4999      0.0834    5.9949    0.0000 #> \teta6                       0.2501      0.1411    1.7727    0.0763 #> \tResid_eta6                 0.9784      0.3160    3.0965    0.0020 #>  #>   Dependent construct: 'eta6' #>  #> \tIndependent construct    Estimate  Std. error   t-stat.   p-value #> \teta3                       0.4999      0.0500    9.9961    0.0000 #> \teta4                       0.2501      0.0601    4.1604    0.0000 #> \teta5                       0.5001      0.1103    4.5359    0.0000 #> \tResid_eta5                -0.0056      0.1350   -0.0414    0.9670 #> ________________________________________________________________________________"},{"path":[]},{"path":"https://floschuberth.github.io/cSEM/reference/testMGD.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Tests for multi-group comparisons — testMGD","text":"","code":"testMGD(  .object                = NULL,  .alpha                 = 0.05,  .approach_p_adjust     = \"none\",  .approach_mgd          = c(\"all\", \"Klesel\", \"Chin\", \"Sarstedt\",                              \"Keil\", \"Nitzl\", \"Henseler\", \"CI_para\",\"CI_overlap\"),  .output_type           = c(\"complete\", \"structured\"),  .parameters_to_compare = NULL,  .eval_plan             = c(\"sequential\", \"multicore\", \"multisession\"),                             .handle_inadmissibles  = c(\"replace\", \"drop\", \"ignore\"),  .R_permutation         = 499,  .R_bootstrap           = 499,  .saturated             = FALSE,  .seed                  = NULL,  .type_ci               = \"CI_percentile\",  .type_vcv              = c(\"indicator\", \"construct\"),  .verbose               = TRUE  )"},{"path":"https://floschuberth.github.io/cSEM/reference/testMGD.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Tests for multi-group comparisons — testMGD","text":".object R object class cSEMResults resulting call csem(). .alpha integer numeric vector significance levels. Defaults 0.05. .approach_p_adjust Character string vector character strings. Approach used adjust p-value multiple testing. See methods argument stats::p.adjust() list choices description. Defaults \"none\". .approach_mgd Character string vector character strings. Approach used multi-group comparison. One : \"\", \"Klesel\", \"Chin\", \"Sarstedt\", \"Keil, \"Nitzl\", \"Henseler\", \"CI_para\", \"CI_overlap\". Default \"\" case approaches computed (possible). .output_type Character string. type output return. One \"complete\" \"structured\". See Value section details. Defaults \"complete\". .parameters_to_compare model lavaan model syntax indicating parameters (.e, path (~), loadings (=~), weights (<~), correlations (~~)) compared across groups. Defaults NULL case weights, loadings path coefficients originally specified model compared. .eval_plan Character string. evaluation plan use. One \"sequential\", \"multicore\", \"multisession\". two latter cases available cores used. Defaults \"sequential\". .handle_inadmissibles Character string. inadmissible results treated? One \"drop\", \"ignore\", \"replace\". \"drop\", replications/resamples yielding inadmissible result dropped (.e. number results returned potentially less .R). \"ignore\" results returned even replications yielded inadmissible results (.e. number results returned equal .R). \"replace\" resampling continues exactly .R admissible solutions. Defaults \"replace\" accommodate approaches. .R_permutation Integer. number permutations. Defaults 499 .R_bootstrap Integer. number bootstrap runs. Ignored .object contains resamples. Defaults 499 .saturated Logical. saturated structural model used? Defaults FALSE. .seed Integer NULL. random seed use. Defaults NULL case arbitrary seed chosen. Note scope seed limited body function used . Hence, global seed altered! .type_ci Character string. confidence interval calculated? possible choices, see .quantity argument infer() function. used .approch_mgd one \"CI_para\" \"CI_overlap\". Ignored otherwise. Defaults \"CI_percentile\". .type_vcv Character string. model-implied correlation matrix calculated? One \"indicator\" \"construct\". Defaults \"indicator\". .verbose Logical. information (e.g., progress bar) printed console? Defaults TRUE.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/testMGD.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Tests for multi-group comparisons — testMGD","text":".output_type = \"complete\" list class cSEMTestMGD. Technically, cSEMTestMGD named list containing following list elements: $Information Additional information. $Klesel list elements, Test_statistic, P_value, Decision $Chin list elements, Test_statistic, P_value, Decision, Decision_overall $Sarstedt list elements, Test_statistic, P_value, Decision, Decision_overall $Keil list elements, Test_statistic, P_value, Decision, Decision_overall $Nitzl list elements, Test_statistic, P_value, Decision, Decision_overall $Henseler list elements, Test_statistic, P_value, Decision, Decision_overall $CI_para list elements,  Decision, Decision_overall $CI_overlap list elements,  Decision, Decision_overall .output_type = \"structured\" tibble (data frame) following columns returned. Test name test. Comparision parameter compared across groups. \"overall\" overall fit model compared. alpha% test decision given \"alpha\" level. TRUE null hypotheses rejected; FALSE rejected. p-value_correction p-value correction. CI_type \"CI_para\" \"CI_overlap\" test. confidence interval used. Distance_metric Test = \"Klesel\". distance metric used.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/testMGD.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Tests for multi-group comparisons — testMGD","text":"function performs various tests proposed context multigroup analysis. following tests implemented: .approach_mgd = \"Klesel\": Approach suggested Klesel et al. (2019) model-implied variance-covariance matrix (either indicator (.type_vcv = \"indicator\") construct (.type_vcv = \"construct\")) compared across groups. model-implied indicator construct correlation matrix based saturated structural model compared, set .saturated = TRUE. measure distance model-implied variance-covariance matrices, geodesic distance (dG) squared Euclidean distance (dL) used. two groups compared, average distance groups used. .approach_mgd = \"Sarstedt\": Approach suggested Sarstedt et al. (2011) Groups compared terms parameter differences across groups. Sarstedt et al. (2011)  tests parameter k equal across groups. several parameters tested simultaneously recommended adjust significance  level p-values (cSEM correction done p-value). default multiple testing correction done, however, several common adjustments available via .approach_p_adjust. See stats::p.adjust() details. Note: test severe shortcomings. Use caution. .approach_mgd = \"Chin\": Approach suggested Chin Dibbern (2010) Groups compared terms parameter differences across groups. Chin Dibbern (2010)  tests parameter k equal two groups. two groups tested equality, parameter k compared pairs groups. case, recommended adjust significance  level p-values (cSEM correction done p-value) since essentially multiple testing setup. several parameters tested simultaneously, correction group number parameters. default multiple testing correction done, however, several common adjustments available via .approach_p_adjust. See stats::p.adjust() details. .approach_mgd = \"Keil\": Approach suggested Keil et al. (2000) Groups compared terms parameter differences across groups. Keil et al. (2000)  tests parameter k equal two groups. assumed, standard errors coefficients equal across groups. calculation standard error parameter difference adjusted proposed Henseler et al. (2009) . two groups tested equality, parameter k compared pairs groups. case, recommended adjust significance  level p-values (cSEM correction done p-value) since essentially multiple testing setup. several parameters tested simultaneously, correction group number parameters. default multiple testing correction done, however, several common adjustments available via .approach_p_adjust. See stats::p.adjust() details. .approach_mgd = \"Nitzl\": Approach suggested Nitzl (2010) Groups compared terms parameter differences across groups. Similarly Keil et al. (2000) , single parameter k tested equality two groups. contrast Keil et al. (2000) , assumed, standard errors coefficients unequal across groups (Sarstedt et al. 2011) . two groups tested equality, parameter k compared pairs groups. case, recommended adjust significance  level p-values (cSEM correction done p-value) since essentially multiple testing setup. several parameters tested simultaneously, correction group number parameters. default multiple testing correction done, however, several common adjustments available via .approach_p_adjust. See stats::p.adjust() details. .approach_mgd = \"Henseler\": Approach suggested Henseler (2007) Groups compared terms parameter differences across groups. , bootstrap estimates one parameter compared across groups. literature, approach also known PLS-MGA. Originally, test proposed one-sided test. function perform left-sided right-sided test investigate whether parameter differs across two groups. , significance level divided 2 compared p-value left right-sided test. Moreover, .approach_p_adjust ignored overall decision returned. detailed description, see also Henseler et al. (2009) . .approach_mgd = \"CI_param\": Approach mentioned Sarstedt et al. (2011) approach based confidence intervals constructed around parameter estimates two groups. parameter one group falls within confidence interval group /vice versa, can concluded group difference. Since based confidence intervals .approach_p_adjust ignored. .approach_mgd = \"CI_overlap\": Approach mentioned Sarstedt et al. (2011) approach based confidence intervals (CIs) constructed around parameter estimates two groups. two CIs overlap, can concluded group difference. Since based confidence intervals .approach_p_adjust ignored. Use .approach_mgd choose approach. default approaches computed (.approach_mgd = \"\"). convenience, two types output available. See \"Value\" section . default, approaches based parameter differences across groups compare parameters (.parameters_to_compare = NULL). compare subset parameters provide parameters lavaan model syntax  just like model estimate. Take simple model: path eta1 eta3 loadings eta1 compared across groups, write: Note \"model\" provided .parameters_to_compare need estimable model! Note also compared functions cSEM using argument, .handle_inadmissibles defaults \"replace\" accommodate Sarstedt et al. (2011) approach. Argument .R_permuation ignored \"Nitzl\" \"Keil\" approach. .R_bootstrap ignored  .object already contains resamples, .e. class cSEMResults_resampled \"Klesel\" \"Chin\" approach used. argument .saturated used \"Klesel\" . .saturated = TRUE original structural model ignored replaced saturated model, .e. model constructs allowed correlate freely. useful test differences measurement models groups isolation.","code":"model_to_estimate <- \" Structural model eta2 ~ eta1 eta3 ~ eta1 + eta2  # Each concept os measured by 3 indicators, i.e., modeled as latent variable eta1 =~ y11 + y12 + y13 eta2 =~ y21 + y22 + y23 eta3 =~ y31 + y32 + y33 \" to_compare <- \" Structural parameters to compare eta3 ~ eta1  # Loadings to compare eta1 =~ y11 + y12 + y13 \""},{"path":"https://floschuberth.github.io/cSEM/reference/testMGD.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Tests for multi-group comparisons — testMGD","text":"Chin WW, Dibbern J (2010). “Introduction Permutation Based Procedure Multi-Group PLS Analysis: Results Tests Differences Simulated Data Cross Cultural Analysis Sourcing Information System Services Germany USA.” Handbook Partial Least Squares, 171–193. Springer Berlin Heidelberg. doi:10.1007/978-3-540-32827-8_8 . Henseler J (2007). “new simple approach multi-group analysis partial least squares path modeling.” Martens H, Næ s T (eds.), Proceedings PLS'07 - 5th International Symposium PLS Related Methods, 104–107. PLS, Norway: Matforsk, . Henseler J, Ringle CM, Sinkovics RR (2009). “use partial least squares path modeling international marketing.” Advances International Marketing, 20, 277–320. doi:10.1108/S1474-7979(2009)0000020014 . Keil M, Tan BC, Wei K, Saarinen T, Tuunainen V, Wassenaar (2000). “cross-cultural study escalation commitment behavior software projects.” MIS Quarterly, 24(2), 299–325. Klesel M, Schuberth F, Henseler J, Niehaves B (2019). “Test Multigroup Comparison Using Partial Least Squares Path Modeling.” Internet Research, 29(3), 464–477. doi:10.1108/intr-11-2017-0418 . Nitzl C (2010). “Eine anwenderorientierte Einfuehrung die Partial Least Square (PLS)-Methode.” Arbeitspapier,  number 21. Universitaet Hamburg, Institut fuer Industrielles Management, Hamburg. Sarstedt M, Henseler J, Ringle CM (2011). “Multigroup Analysis Partial Least Squares (PLS) Path Modeling: Alternative Methods Empirical Results.” Advances International Marketing, 195–218. Emerald Group Publishing Limited. doi:10.1108/s1474-7979(2011)0000022012 .","code":""},{"path":[]},{"path":"https://floschuberth.github.io/cSEM/reference/testMGD.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Tests for multi-group comparisons — testMGD","text":"","code":"if (FALSE) { # \\dontrun{ # =========================================================================== # Basic usage # =========================================================================== model <- \" # Structural model QUAL ~ EXPE EXPE ~ IMAG SAT  ~ IMAG + EXPE + QUAL + VAL LOY  ~ IMAG + SAT VAL  ~ EXPE + QUAL  # Measurement model  EXPE <~ expe1 + expe2 + expe3 + expe4 + expe5 IMAG <~ imag1 + imag2 + imag3 + imag4 + imag5 LOY  =~ loy1  + loy2  + loy3  + loy4 QUAL =~ qual1 + qual2 + qual3 + qual4 + qual5 SAT  <~ sat1  + sat2  + sat3  + sat4 VAL  <~ val1  + val2  + val3  + val4 \"  ## Create list of virtually identical data sets dat <- list(satisfaction[-3,], satisfaction[-5, ], satisfaction[-10, ]) out <- csem(dat, model, .resample_method = \"bootstrap\", .R = 40)   ## Test  testMGD(out, .R_permutation = 40,.verbose = FALSE)  # Notes:  #  1. .R_permutation (and .R in the call to csem) is small to make examples run quicker;  #     should be higher in real applications. #  2. Test will not reject their respective H0s since the groups are virtually #     identical. #  3. Only exception is the approach suggested by Sarstedt et al. (2011), a #     sign that the test is unreliable. #  4. As opposed to other functions involving the argument,  #     '.handle_inadmissibles' the default is \"replace\" as this is #     required by Sarstedt et al. (2011)'s approach.  # =========================================================================== # Extended usage # =========================================================================== ### Test only a subset ------------------------------------------------------ # By default all parameters are compared. Select a subset by providing a  # model in lavaan model syntax:  to_compare <- \" # Path coefficients QUAL ~ EXPE  # Loadings EXPE <~ expe1 + expe2 + expe3 + expe4 + expe5 \"  ## Test  testMGD(out, .parameters_to_compare = to_compare, .R_permutation = 20,          .R_bootstrap = 20, .verbose = FALSE)  ### Different p_adjustments -------------------------------------------------- # To adjust p-values to accommodate multiple testing use .approach_p_adjust.  # The number of tests to use for adjusting depends on the approach chosen. For # the Chin approach for example it is the number of parameters to test times the # number of possible group comparisons. To compare the results for different # adjustments, a vector of p-adjustments may be chosen.  ## Test  testMGD(out, .parameters_to_compare = to_compare,          .approach_p_adjust = c(\"none\", \"bonferroni\"),         .R_permutation = 20, .R_bootstrap = 20, .verbose = FALSE) } # }"},{"path":[]},{"path":"https://floschuberth.github.io/cSEM/reference/testMICOM.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Test measurement invariance of composites — testMICOM","text":"","code":"testMICOM(  .object               = NULL,  .approach_p_adjust    = \"none\",  .handle_inadmissibles = c(\"drop\", \"ignore\", \"replace\"),   .R                    = 499,  .seed                 = NULL,  .verbose              = TRUE  )"},{"path":"https://floschuberth.github.io/cSEM/reference/testMICOM.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Test measurement invariance of composites — testMICOM","text":".object R object class cSEMResults resulting call csem(). .approach_p_adjust Character string vector character strings. Approach used adjust p-value multiple testing. See methods argument stats::p.adjust() list choices description. Defaults \"none\". .handle_inadmissibles Character string. inadmissible results treated? One \"drop\", \"ignore\", \"replace\". \"drop\", replications/resamples yielding inadmissible result dropped (.e. number results returned potentially less .R). \"ignore\" results returned even replications yielded inadmissible results (.e. number results returned equal .R). \"replace\" resampling continues exactly .R admissible solutions. Depending frequency inadmissible solutions may significantly increase computing time. Defaults \"drop\". .R Integer. number bootstrap replications. Defaults 499. .seed Integer NULL. random seed use. Defaults NULL case arbitrary seed chosen. Note scope seed limited body function used . Hence, global seed altered! .verbose Logical. information (e.g., progress bar) printed console? Defaults TRUE.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/testMICOM.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Test measurement invariance of composites — testMICOM","text":"named list class cSEMTestMICOM containing following list element: $Step2 list containing results test compositional invariance (Step 2). $Step3 list containing results test mean variance equality (Step 3). $Information list additional information test.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/testMICOM.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Test measurement invariance of composites — testMICOM","text":"functions performs permutation-based test measurement invariance composites across groups proposed Henseler et al. (2016) . According authors assessing measurement invariance composite models can assessed three-step procedure. first two steps involve assessment configural compositional invariance. third steps involves mean variance comparisons across groups. Assessment configural invariance qualitative nature hence assessed testMICOM() function. testMICOM() requires least two groups, .object must class cSEMResults_multi. version 0.2.0 package, testMICOM() support models containing second-order constructs. possible compare two groups, however, multiple-testing issues arise case. adjust p-values case several p-value adjustments available via approach_p_adjust argument. remaining arguments set number permutation runs conduct (.R), random number seed (.seed), instructions inadmissible results handled (handle_inadmissibles), whether function verbose sense progress printed console. number permutation runs defaults args_default()$.R performance reasons. According Henseler et al. (2016)  number permutations least 5000 assessment sufficiently reliable.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/testMICOM.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Test measurement invariance of composites — testMICOM","text":"Henseler J, Ringle CM, Sarstedt M (2016). “Testing Measurement Invariance Composites Using Partial Least Squares.” International Marketing Review, 33(3), 405–431. doi:10.1108/imr-09-2014-0304 .","code":""},{"path":[]},{"path":"https://floschuberth.github.io/cSEM/reference/testMICOM.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Test measurement invariance of composites — testMICOM","text":"","code":"if (FALSE) { # \\dontrun{ # NOTE: to run the example. Download and load the newst version of cSEM.DGP # from GitHub using devtools::install_github(\"M-E-Rademaker/cSEM.DGP\").  # Create two data generating processes (DGPs) that only differ in how the composite # X is build. Hence, the two groups are not compositionally invariant. dgp1 <- \" # Structural model Y ~ 0.6*X  # Measurement model Y =~ 1*y1 X <~ 0.4*x1 + 0.8*x2  x1 ~~ 0.3125*x2 \"  dgp2 <- \" # Structural model Y ~ 0.6*X  # Measurement model Y =~ 1*y1 X <~ 0.8*x1 + 0.4*x2  x1 ~~ 0.3125*x2 \"  g1 <- generateData(dgp1, .N = 399, .empirical = TRUE) # requires cSEM.DGP  g2 <- generateData(dgp2, .N = 200, .empirical = TRUE) # requires cSEM.DGP  # Model is the same for both DGPs model <- \" # Structural model Y ~ X  # Measurement model Y =~ y1 X <~ x1 + x2 \"  # Estimate csem_results <- csem(.data = list(\"group1\" = g1, \"group2\" = g2), model)  # Test testMICOM(csem_results, .R = 50, .alpha = c(0.01, 0.05), .seed = 1987) } # }"},{"path":[]},{"path":"https://floschuberth.github.io/cSEM/reference/testOMF.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Test for overall model fit — testOMF","text":"","code":"testOMF(  .object                = NULL,   .alpha                 = 0.05,  .fit_measures          = FALSE,  .handle_inadmissibles  = c(\"drop\", \"ignore\", \"replace\"),   .R                     = 499,   .saturated             = FALSE,  .seed                  = NULL,  ... )"},{"path":"https://floschuberth.github.io/cSEM/reference/testOMF.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Test for overall model fit — testOMF","text":".object R object class cSEMResults resulting call csem(). .alpha integer numeric vector significance levels. Defaults 0.05. .fit_measures Logical. (EXPERIMENTAL) additional fit measures included? Defaults FALSE. .handle_inadmissibles Character string. inadmissible results treated? One \"drop\", \"ignore\", \"replace\". \"drop\", replications/resamples yielding inadmissible result dropped (.e. number results returned potentially less .R). \"ignore\" results returned even replications yielded inadmissible results (.e. number results returned equal .R). \"replace\" resampling continues exactly .R admissible solutions. Depending frequency inadmissible solutions may significantly increase computing time. Defaults \"drop\". .R Integer. number bootstrap replications. Defaults 499. .saturated Logical. saturated structural model used? Defaults FALSE. .seed Integer NULL. random seed use. Defaults NULL case arbitrary seed chosen. Note scope seed limited body function used . Hence, global seed altered! ... Can used determine fitting function used calculateGFI function.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/testOMF.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Test for overall model fit — testOMF","text":"list class cSEMTestOMF containing following list elements: $Test_statistic value test statistics. $Critical_value corresponding  critical values obtained bootstrap. $Decision test decision. One : FALSE (Reject) TRUE (reject). $Information .R bootstrap values; number admissible results; seed used number total runs.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/testOMF.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Test for overall model fit — testOMF","text":"Bootstrap-based test overall model fit originally proposed Beran Srivastava (1985) . See also Dijkstra Henseler (2015)  first suggested test context PLS-PM. default, testOMF() tests null hypothesis population indicator correlation matrix equals population model-implied indicator correlation matrix. Several discrepancy measures may used. default, testOMF() uses four distance measures assess distance sample indicator correlation matrix estimated model-implied indicator correlation matrix, namely geodesic distance, squared Euclidean distance, standardized root mean square residual (SRMR), distance based maximum likelihood fit function. reference distribution test statistic obtained bootstrap proposed Beran Srivastava (1985) . possible perform bootstrap-based test using fit measures CFI, RMSEA GFI .fit_measures = TRUE. experimental. best knowledge applicability usefulness fit measures model fit assessment formally (statistically) assessed yet. Theoretically, logic test applies fit indices well. Hence, applicability theoretically justified. use know . .saturated = TRUE original structural model ignored replaced saturated model, .e., model constructs allowed correlate freely. useful test misspecification measurement model isolation.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/testOMF.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Test for overall model fit — testOMF","text":"Beran R, Srivastava MS (1985). “Bootstrap Tests Confidence Regions Functions Covariance Matrix.” Annals Statistics, 13(1), 95–115. doi:10.1214/aos/1176346579 . Dijkstra TK, Henseler J (2015). “Consistent Asymptotically Normal PLS Estimators Linear Structural Equations.” Computational Statistics & Data Analysis, 81, 10–23.","code":""},{"path":[]},{"path":"https://floschuberth.github.io/cSEM/reference/testOMF.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Test for overall model fit — testOMF","text":"","code":"# =========================================================================== # Basic usage # =========================================================================== model <- \" # Structural model eta2 ~ eta1 eta3 ~ eta1 + eta2  # (Reflective) measurement model eta1 =~ y11 + y12 + y13 eta2 =~ y21 + y22 + y23 eta3 =~ y31 + y32 + y33 \"  ## Estimate out <- csem(threecommonfactors, model, .approach_weights = \"PLS-PM\")  ## Test testOMF(out, .R = 50, .seed = 320) #> ________________________________________________________________________________ #> --------- Test for overall model fit based on Beran & Srivastava (1985) -------- #>  #> Null hypothesis: #>  #>        ┌──────────────────────────────────────────────────────────────────┐ #>        │                                                                  │ #>        │   H0: The model-implied indicator covariance matrix equals the   │ #>        │   population indicator covariance matrix.                        │ #>        │                                                                  │ #>        └──────────────────────────────────────────────────────────────────┘ #>  #> Test statistic and critical value:  #>  #> \t                                  \tCritical value #> \tDistance measure    Test statistic\t  95% \t #> \tdG                      0.0060    \t0.0192\t #> \tSRMR                    0.0158    \t0.0272\t #> \tdL                      0.0112    \t0.0333\t #> \tdML                     0.0320    \t0.1027\t #> \t #>  #> Decision:  #>  #> \t                    \tSignificance level #> \tDistance measure    \t     95%     \t #> \tdG                  \tDo not reject\t #> \tSRMR                \tDo not reject\t #> \tdL                  \tDo not reject\t #> \tdML                 \tDo not reject\t #> \t #> Additional information: #>  #> \tOut of 50 bootstrap replications 50 are admissible. #> \tSee ?verify() for what constitutes an inadmissible result. #>  #> \tThe seed used was: 320 #> ________________________________________________________________________________"},{"path":"https://floschuberth.github.io/cSEM/reference/threecommonfactors.html","id":null,"dir":"Reference","previous_headings":"","what":"Data: threecommonfactors — threecommonfactors","title":"Data: threecommonfactors — threecommonfactors","text":"dataset containing 500 standardized observations 9 indicator generated population model three concepts modeled common factors.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/threecommonfactors.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Data: threecommonfactors — threecommonfactors","text":"","code":"threecommonfactors"},{"path":"https://floschuberth.github.io/cSEM/reference/threecommonfactors.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Data: threecommonfactors — threecommonfactors","text":"matrix 500 rows 9 variables: y11-y13 Indicators attached first common factor (eta1). Population loadings : 0.7; 0.7; 0.7 y21-y23 Indicators attached second common factor (eta2). Population loadings : 0.5; 0.7; 0.8 y31-y33 Indicators attached third common factor (eta3). Population loadings : 0.8; 0.75; 0.7 model : $$`eta2` = gamma1 * `eta1` + zeta1$$ $$`eta3` = gamma2 * `eta1` + beta * `eta2` + zeta2$$ population values gamma1 = 0.6, gamma2 = 0.4 beta = 0.35.","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/threecommonfactors.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Data: threecommonfactors — threecommonfactors","text":"","code":"#============================================================================ # Correct model (the model used to generate the data) #============================================================================ model_correct <- \" # Structural model eta2 ~ eta1 eta3 ~ eta1 + eta2  # Measurement model eta1 =~ y11 + y12 + y13 eta2 =~ y21 + y22 + y23 eta3 =~ y31 + y32 + y33  \"  a <- csem(threecommonfactors, model_correct)  ## The overall model fit is evidently almost perfect: testOMF(a, .R = 30) # .R = 30 to speed up the example #> ________________________________________________________________________________ #> --------- Test for overall model fit based on Beran & Srivastava (1985) -------- #>  #> Null hypothesis: #>  #>        ┌──────────────────────────────────────────────────────────────────┐ #>        │                                                                  │ #>        │   H0: The model-implied indicator covariance matrix equals the   │ #>        │   population indicator covariance matrix.                        │ #>        │                                                                  │ #>        └──────────────────────────────────────────────────────────────────┘ #>  #> Test statistic and critical value:  #>  #> \t                                  \tCritical value #> \tDistance measure    Test statistic\t  95% \t #> \tdG                      0.0060    \t0.0179\t #> \tSRMR                    0.0158    \t0.0265\t #> \tdL                      0.0112    \t0.0316\t #> \tdML                     0.0320    \t0.0939\t #> \t #>  #> Decision:  #>  #> \t                    \tSignificance level #> \tDistance measure    \t     95%     \t #> \tdG                  \tDo not reject\t #> \tSRMR                \tDo not reject\t #> \tdL                  \tDo not reject\t #> \tdML                 \tDo not reject\t #> \t #> Additional information: #>  #> \tOut of 30 bootstrap replications 30 are admissible. #> \tSee ?verify() for what constitutes an inadmissible result. #>  #> \tThe seed used was: -1740813494 #> ________________________________________________________________________________"},{"path":[]},{"path":"https://floschuberth.github.io/cSEM/reference/verify.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Verify admissibility — verify","text":"","code":"verify(.object)"},{"path":"https://floschuberth.github.io/cSEM/reference/verify.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Verify admissibility — verify","text":".object R object class cSEMResults resulting call csem().","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/verify.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Verify admissibility — verify","text":"logical vector indicating () problem occurred. FALSE indicates specific problem occurred. models containing second-order constructs estimated two/three-stage approach, list two vectors (one first one second stage) returned. Status codes : 1: algorithm converged. 2: absolute standardized loading estimates smaller equal 1. violation implies either negative variance measurement error correlation larger 1. 3: construct VCV positive semi-definite. 4: reliability estimates smaller equal 1. 5: model-implied indicator VCV positive semi-definite. checked linear models (including models containing second-order constructs).","code":""},{"path":"https://floschuberth.github.io/cSEM/reference/verify.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Verify admissibility — verify","text":"Verify admissibility results obtained using csem(). Results exhibiting one following defects deemed inadmissible: non-convergence algorithm used obtain weights, loadings /(congeneric) reliabilities larger 1, construct variance-covariance (VCV) /model-implied VCV matrix positive semi-definite. .object class cSEMResults_2ndorder (.e., estimates based model containing second-order constructs) first second stage checked separately. Currently, model-implied indicator VCV matrix nonlinear model available. verify() therefore skips check positive definiteness model-implied indicator VCV matrix nonlinear models returns \"ok\".","code":""},{"path":[]},{"path":"https://floschuberth.github.io/cSEM/reference/verify.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Verify admissibility — verify","text":"","code":"### Without higher order constructs -------------------------------------------- model <- \" # Structural model eta2 ~ eta1 eta3 ~ eta1 + eta2  # (Reflective) measurement model eta1 =~ y11 + y12 + y13 eta2 =~ y21 + y22 + y23 eta3 =~ y31 + y32 + y33 \"    # Estimate out <- csem(threecommonfactors, model)    # Check admissibility verify(out) # ok! #> ________________________________________________________________________________ #>  #> Verify admissibility: #>  #> \t admissible #>  #> Details: #>  #>   Code   Status    Description #>   1      ok        Convergence achieved                                    #>   2      ok        All absolute standardized loading estimates <= 1        #>   3      ok        Construct VCV is positive semi-definite                 #>   4      ok        All reliability estimates <= 1                          #>   5      ok        Model-implied indicator VCV is positive semi-definite   #> ________________________________________________________________________________  ## Examine the structure of a cSEMVerify object str(verify(out)) #>  'cSEMVerify' Named logi [1:5] FALSE FALSE FALSE FALSE FALSE #>  - attr(*, \"names\")= chr [1:5] \"1\" \"2\" \"3\" \"4\" ...  ### With higher order constructs ----------------------------------------------- # If the model containes higher order constructs both the first and the second- # stage estimates estimates are checked for admissibility  if (FALSE) { # \\dontrun{ require(cSEM.DGP) # download from https://m-e-rademaker.github.io/cSEM.DGP/    # Create DGP with 2nd order construct. Loading for indicator y51 is set to 1.1 # to produce a failing first stage model    dgp_2ndorder <- \" ## Path model / Regressions eta2 ~ 0.5*eta1 eta3 ~ 0.35*eta1 + 0.4*eta2  ## Composite model eta1 =~ 0.8*y41 + 0.6*y42 + 0.6*y43 eta2 =~ 1.1*y51 + 0.7*y52 + 0.7*y53 c1   =~ 0.8*y11 + 0.4*y12 c2   =~ 0.5*y21 + 0.3*y22  ## Higher order composite eta3 =~ 0.4*c1 + 0.4*c2 \"    dat <- generateData(dgp_2ndorder) # requires the cSEM.DGP package out <- csem(dat, .model = dgp_2ndorder)  verify(out) # not ok } # }"},{"path":[]},{"path":[]},{"path":"https://floschuberth.github.io/cSEM/news/index.html","id":"csem-061-1","dir":"Changelog","previous_headings":"","what":"cSEM 0.6.1","title":"cSEM 0.6.1","text":"Adjust description file, .e., NeedsCompilation: ","code":""},{"path":"https://floschuberth.github.io/cSEM/news/index.html","id":"csem-060-2025-02-24","dir":"Changelog","previous_headings":"","what":"cSEM 0.6.0 (2025-02-24)","title":"cSEM 0.6.0 (2025-02-24)","text":"CRAN release: 2025-02-25 Implement plot() function visualizes cSEM models. Thanks Nguyen Huu Phuc contribution (#430). Bug fix predict function model contains single categorical indicator. Bug fix case second-order composite formed one common factor. Implement calculateRelativeGoF. Now relative GoF can obtained. Bug fix calculateGoF. Now single-indicator constructs excluded. Thanks Mehmet Mehmetoglu Sergio Venturini. Bug fix calculateEffects(). Now distinguished recursive non-recursive models. recursive models rounding longer necessary. Bug fix calculateReliabilities(). Now correction attenuation correctly done PLS-PM Mode B.","code":""},{"path":"https://floschuberth.github.io/cSEM/news/index.html","id":"csem-050-2022-05-09","dir":"Changelog","previous_headings":"","what":"cSEM 0.5.0 (2022-05-09)","title":"cSEM 0.5.0 (2022-05-09)","text":"CRAN release: 2022-11-24 Bug fix testOMF(). Now saturated argument passed discrepancy/fit measures. Bug fix .resampleData() crossvalidation used. Empty datasets possible anymore. Implemented several prediction metrics. Bug fix: Revision predict metrics predict function. Update .eval_plan argument since multiprocess argument future package deprecated. Now multisession multicore need used. Note multicore work Windows machines. Bug fix: Calculation R2 adjR2 print function assess function Revise description two-stage approach csem help file (#418) Bug fix: fix print method summarize() disattenuate set TRUE internally. Now disattenuate treated csem reported value provided user. (#419) Use singular value decomposition GSCAm deal large datasets (#444) Bug fix: GSCAm (.e., .approach_weights = \"GSCA\" constructs modeled common factors) longer fails single indicator construct supplied (#441) default value argument .r (number repetitions) predict() changed 10 1 since one repetition hardly ever necessary. predict() now able predict categorical indicators (procedure known OrdPLScPredict). predict() therefore gains number new arguments, namely: .approach_score_target, .sim_points, .treat_as_continuous, .approach_score_benchmark. Removed argument .verbose testOMF() effect (#445). Bug fix: GSCAm (.e., .approach_weights = \"GSCA\" constructs modeled common factors) longer fails single indicator construct supplied (#441) Bug fix: predict() longer fails LOOCV used (#337) Bug fix: fix print method summarize() resampling constant values (weights loadings) conducted. standard error, t-value, p-value CI properly set NA now. (#433) postestimate_test_CVPAT(): Perform Cross-Validated Predictive Ability Test (CVPAT) compare predictive performance two models (#455) predict() now able perform predictions either based earliest antecedents, .e., values indicators associated exogenous constructs based direct antecedents, .e., based values predictions associated direct antecedents (3485) predict() variety prediction metrics added","code":""},{"path":"https://floschuberth.github.io/cSEM/news/index.html","id":"csem-040-2021-04-20","dir":"Changelog","previous_headings":"","what":"cSEM 0.4.0 (2021-04-20)","title":"cSEM 0.4.0 (2021-04-20)","text":"CRAN release: 2021-04-19","code":""},{"path":"https://floschuberth.github.io/cSEM/news/index.html","id":"major-changes-0-4-0","dir":"Changelog","previous_headings":"","what":"Major changes","title":"cSEM 0.4.0 (2021-04-20)","text":"New function exportToExcel(). function conveniently exports results assess(), predict(), summarize() testOMF() .xlsx file.","code":""},{"path":"https://floschuberth.github.io/cSEM/news/index.html","id":"bug-fixes-0-4-0","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"cSEM 0.4.0 (2021-04-20)","text":"Critical bug fix: calculateVifModeB() calculate VIFs modeB constructs correctly bug calculation R^2. PLEASE REVIEW CALCULATIONS cSEM version < 0.3.1:9000! (thanks @Benjamin Liengaard pointing ). Bug fix: predict() longer silently returns empty predictions .test_data contain rownames. Bug fix: calculation MSE modelSelectionCriteria() resulted vector incorrect length. cases affected computation “GM” “Mallows_cp”.","code":""},{"path":"https://floschuberth.github.io/cSEM/news/index.html","id":"csem-031-2021-02-14","dir":"Changelog","previous_headings":"","what":"cSEM 0.3.1 (2021-02-14)","title":"cSEM 0.3.1 (2021-02-14)","text":"CRAN release: 2021-02-14 Bug fix: summarize() longer fails .object class cSEMResults_2ndorder contains indirect effects. Add argument type_htmt calculateHTMT(). type_htmt = \"htmt2\" calculates consistent estimator congeneric measurement models.","code":""},{"path":"https://floschuberth.github.io/cSEM/news/index.html","id":"csem-030-2020-12-10","dir":"Changelog","previous_headings":"","what":"cSEM 0.3.0 (2020-12-10)","title":"cSEM 0.3.0 (2020-12-10)","text":"CRAN release: 2020-10-12 Add lifecylce badges postestimation functions.(#376) arguments accepted assess()’s ... argument documented properly. fixed. See args_assess_dotdotdot complete list available arguments. calculateHTMT() now allows users chose type confidence interval use computing critical (1-alpha)% quantile HTMT values (#379) testMGD() gains new .output_type argument. default (.output_type = \"structured\"), standard output returned. .output_type = \"structured\", however, tibble (data frame) summarizing test decisions user-friendly way returned. (#398) Remove warning fit() polychoric polyserial indicator correlation used estimation. (#413) print.cSEMAssess() longer prints zero VIF values constructs part particular structural equation. print.cSEMAssess() now prints results calculateVIFModeB(). missing previous releases. (#384) Breaking: calculateVIFModeB() now returns matrix dependent construct rows VIFs coresponding weights columns. Previously, output list. Add model selection criteria. See calculateModelSelectionCriteria() function details. usual, criteria available via assess(). (#412) Combine functions surface, floodlight simple effects analysis doNonlinearEffectsAnalysis() function; Breaking: functions doFloodlightAnalysis() doSurfaceAnalysis() removed! Progress bars now supported every function resampling. Progress bars fully customizable via progressr framework created Note: suppress progress bar use progressr::handlers(\"void\") run csem commands. (#359) Fix bug computation Bc Bca interval. Computation failed models indirect effects. List element “reliability” assess() changed “Reliability” consistent naming scheme list elements. infer() automatically computes bootstrap resamples now default .object class cSEMResults_resampled already. (#389) Remove .alpha argument testMICOM(). argument longer required decisions made via (possibly adjusted) p-values. (#393) Add checks plot methods predict(), doFloodlightAnalysis, , doFloodlightAnalysis. Several documentation updates typo corrections. Fornell-Larcker criterion now computed function calculateFLCriterion(). Previously, available via assess(). (#387) Implement importance-performance matrix analysis via doIPMA(). corresponding plot method also available.","code":""},{"path":"https://floschuberth.github.io/cSEM/news/index.html","id":"csem-020-30032020","dir":"Changelog","previous_headings":"","what":"cSEM 0.2.0 (30.03.2020)","title":"cSEM 0.2.0 (30.03.2020)","text":"CRAN release: 2020-03-29","code":""},{"path":"https://floschuberth.github.io/cSEM/news/index.html","id":"major-changes-0-2-0","dir":"Changelog","previous_headings":"","what":"Major changes","title":"cSEM 0.2.0 (30.03.2020)","text":"testMICOM() gains .approach_p_adjust argument. argument takes single character string vector character strings naming p-value adjustment multiple comparisons. (#138) Review calculateHTMT(). 1.) Add inference; 2) fix wrong handling single-indicator constructs (#351); 3) Remove warning produced calculateHTMT() estimated model contains less 2 common factors. (#325) Breaking: Rename argument doFloodlightAnalysis(). (#343) New function doSurfaceAnalysis(). See ?doSurfaceAnalysis()(#349) Implement degrees freedom calculation second-order constructs. Add new function getConstructScores(). function returns standardized unstandardized construct scores. Requires cSEMResults object input. (#340) Fix bug doFloodlightAnalysis(). internal bug. Earlier versions returned wrong direct effect. used doFloodlightAnalysis() cSEM v. 0.1.0 results likely wrong. Export plot method cSEMFloodlight objects. Allow users specify lavaan model without structural model. Now, users can specify model several measurement equations (via <~ =~) structural equations. Instead correlations ! constructs must given. Failing causes error.","code":""},{"path":"https://floschuberth.github.io/cSEM/news/index.html","id":"new-example-data-0-2-0","dir":"Changelog","previous_headings":"Major changes","what":"New example data","title":"cSEM 0.2.0 (30.03.2020)","text":"Add indicator correlation matrix modified version Summers (1965) model. See ?Sigma_Summers_composites Add example data sets used Henseler (2020). See ?BergamiBagozzi2000, ?ITFlex, ?LancelotMiltgenetal2016, ?Russett, ?Switching, ?Yooetal2000.","code":""},{"path":"https://floschuberth.github.io/cSEM/news/index.html","id":"assess-0-2-0","dir":"Changelog","previous_headings":"Major changes","what":"assess()","title":"cSEM 0.2.0 (30.03.2020)","text":"Update documentation vignettes following functions called assess() now exported support cSEM’s native classes (#357, #369): calculateAVE() calculateDf() calculateGoF() calculateHTMT() (support models containing second-order constructs) calculateRhoT() calculateRhoT() calculatef2() calculateDML() calculateDG() calculateDL() calculateChiSquare() calculateChiSquareDf() calculateGFI() calculateNFI() calculateNNFI() calculateIFI() calculateCFI() calculateSRMR() calculateRMSEA() calculateRMSTheta() calculateVIFModeB() assess() now supports cSEM’s native classes. (#323) assess() now also computes prints total indirect effects variable often used model assessment may thus considered quality criteria. addition, variance accounted (VAF) computed printed well. (#335) Breaking: change name quality criterion “effect size (f2)” esize f2 corresponding function calculateEffectSize() calculatef2()common. (#336) Add Chi_square statistic Chi_square statistic divided degrees freedom list fit indices. See: ?calculateChiSquare() ?calculateChiSquareDf() Fix bug calculatef2()/assess() one equations structural model one explanatory variable. Fix bug related dotdotdot arguments incorrectly passed functions supplied .user_funs resampling. Add additional example assess() illustrating use .user_funs arguments given multiple functions. (#334) Remove warning produced printing cSEMAssess object based model containing constructs modeled composites.","code":""},{"path":"https://floschuberth.github.io/cSEM/news/index.html","id":"predict-0-2-0","dir":"Changelog","previous_headings":"Major changes","what":"predict()","title":"cSEM 0.2.0 (30.03.2020)","text":"Update documentation predict(). Integrate document cSEMPredict method generic function plot(). Now users may call plot() object created predict(). (#337) Add density residuals plot plot.cSEMPredict(). (#337) Remove argument .only_common_factors postestimation function predict(). Now predict() returns predictions composite models well. break existing code uses predict(..., .only_common_factors = ...). get unused argument (.only_common_factors = FALSE) error. Simply remove argument fix . (#330) Fixed error predict() dataset used obtain .object contained character column. (#345)","code":""},{"path":"https://floschuberth.github.io/cSEM/news/index.html","id":"experimental-features-0-2-0","dir":"Changelog","previous_headings":"Major changes","what":"Experimental features","title":"cSEM 0.2.0 (30.03.2020)","text":"Add .fit_measures argument testOMF(). Now fit measures RMSEA GFI can used test statistic. rather experimental feature may removed future versions.","code":""},{"path":"https://floschuberth.github.io/cSEM/news/index.html","id":"minor-changes-and-bug-fixes-0-2-0","dir":"Changelog","previous_headings":"","what":"Minor changes and bug fixes","title":"cSEM 0.2.0 (30.03.2020)","text":"Using .approach_weights = \"GSCA\" models containing nonlinear terms gives meaningful error message. (#342) print.cSEMTestMICOM() longer prints decision additional bootstrap information. (parts: #339) weighting scheme \"PLS-PM\" .disattenuate = TRUE, dissatenuation longer applied constructs using modes “modeA”” “modeB”. (#352) Model-implied indicator correlation matrix non-recursive models now calculated correctly. (#264) calculatef2() gives error path model estimator “OLS”. (#360, #370) Add .type argument calculateGFI(). Now GFI based ML ULS fitting function can computed. (#371) csem() gives meaningful error structural model contains second-order constructs (#366) Fix bug testMICOM(). Function produced error data set provided contained columns indicators used model used csem(). (#355) Fix bug testMICOM(). Function produced error data set provided contained id-column even id-column correctly supplied csem(). (#344, #338) calculating HTMT via assess() geometric mean average monotrait−heteromethod correlation construct eta_i average monotrait−heteromethod correlation constructs can negative. NaNs produced produced case HTMT printed. Added warning forced printing NaNs well. (#346) Add CITATION file (#331) Add informative error message .data contains missing values. Update vignettes csem-notation","code":""},{"path":"https://floschuberth.github.io/cSEM/news/index.html","id":"initial-release-csem-010-07012020","dir":"Changelog","previous_headings":"","what":"Initial release: cSEM 0.1.0 (07.01.2020)","title":"Initial release: cSEM 0.1.0 (07.01.2020)","text":"CRAN release: 2020-01-13","code":""}]
