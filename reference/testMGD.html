<!-- Generated by pkgdown: do not edit by hand -->
<!DOCTYPE html>
<html lang="en">
  <head>
  <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<title>Tests for multi-group comparisons — testMGD • cSEM</title>


<!-- jquery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script>
<!-- Bootstrap -->
<link href="https://cdnjs.cloudflare.com/ajax/libs/bootswatch/3.4.0/flatly/bootstrap.min.css" rel="stylesheet" crossorigin="anonymous" />


<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script>

<!-- bootstrap-toc -->
<link rel="stylesheet" href="../bootstrap-toc.css">
<script src="../bootstrap-toc.js"></script>

<!-- Font Awesome icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous" />

<!-- clipboard.js -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script>

<!-- headroom.js -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script>

<!-- pkgdown -->
<link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script>




<meta property="og:title" content="Tests for multi-group comparisons — testMGD" />
<meta property="og:description" content="" />






<!-- mathjax -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script>

<!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->


<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-156347841-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-156347841-1');
</script>


<!-- dependencies from examples -->


  

  

  </head>

  <body data-spy="scroll" data-target="#toc">
    

    <div class="container template-reference-topic">
      <header>
      <div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">cSEM</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="Released version">0.3.2</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="../articles/cSEM.html">Get started</a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="../articles/Notation.html">Notation</a>
    </li>
    <li>
      <a href="../articles/Terminology.html">Terminology</a>
    </li>
    <li>
      <a href="../articles/Using-assess.html">Postestimation: Assessing a model</a>
    </li>
  </ul>
</li>
<li>
  <a href="../news/index.html">Changelog</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://github.com/M-E-Rademaker/cSEM/">
    <span class="fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
      
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

      

      </header>

<div class="row">
  <div class="col-md-9 contents">
    <div class="page-header">
    <h1>Tests for multi-group comparisons</h1>
    <small class="dont-index">Source: <a href='https://github.com/M-E-Rademaker/cSEM/blob/master/R/postestimate_test_MGD.R'><code>R/postestimate_test_MGD.R</code></a></small>
    <div class="hidden name"><code>testMGD.Rd</code></div>
    </div>

    <div class="ref-description">
    <p><a href='https://lifecycle.r-lib.org/articles/stages.html#stable'><img src='figures/lifecycle-stable.svg' alt='[Stable]' /></a></p>
    </div>

    <pre class="usage"><span class='fu'>testMGD</span><span class='op'>(</span>
 .object                <span class='op'>=</span> <span class='cn'>NULL</span>,
 .alpha                 <span class='op'>=</span> <span class='fl'>0.05</span>,
 .approach_p_adjust     <span class='op'>=</span> <span class='st'>"none"</span>,
 .approach_mgd          <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='st'>"all"</span>, <span class='st'>"Klesel"</span>, <span class='st'>"Chin"</span>, <span class='st'>"Sarstedt"</span>, 
                            <span class='st'>"Keil"</span>, <span class='st'>"Nitzl"</span>, <span class='st'>"Henseler"</span>, <span class='st'>"CI_para"</span>,<span class='st'>"CI_overlap"</span><span class='op'>)</span>,
 .output_type           <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='st'>"complete"</span>, <span class='st'>"structured"</span><span class='op'>)</span>,
 .parameters_to_compare <span class='op'>=</span> <span class='cn'>NULL</span>,
 .eval_plan             <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='st'>"sequential"</span>, <span class='st'>"multiprocess"</span><span class='op'>)</span>,                           
 .handle_inadmissibles  <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='st'>"replace"</span>, <span class='st'>"drop"</span>, <span class='st'>"ignore"</span><span class='op'>)</span>,
 .R_permutation         <span class='op'>=</span> <span class='fl'>499</span>,
 .R_bootstrap           <span class='op'>=</span> <span class='fl'>499</span>,
 .saturated             <span class='op'>=</span> <span class='cn'>FALSE</span>,
 .seed                  <span class='op'>=</span> <span class='cn'>NULL</span>,
 .type_ci               <span class='op'>=</span> <span class='st'>"CI_percentile"</span>,
 .type_vcv              <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='st'>"indicator"</span>, <span class='st'>"construct"</span><span class='op'>)</span>,
 .verbose               <span class='op'>=</span> <span class='cn'>TRUE</span>
 <span class='op'>)</span></pre>

    <h2 class="hasAnchor" id="arguments"><a class="anchor" href="#arguments"></a>Arguments</h2>
    <table class="ref-arguments">
    <colgroup><col class="name" /><col class="desc" /></colgroup>
    <tr>
      <th>.object</th>
      <td><p>An R object of class <a href='csem_results.html'>cSEMResults</a> resulting from a call to <code><a href='csem.html'>csem()</a></code>.</p></td>
    </tr>
    <tr>
      <th>.alpha</th>
      <td><p>An integer or a numeric vector of significance levels.
Defaults to <code>0.05</code>.</p></td>
    </tr>
    <tr>
      <th>.approach_p_adjust</th>
      <td><p>Character string or a vector of character strings.
Approach used to adjust the p-value for multiple testing.
See the <code>methods</code> argument of <code><a href='https://rdrr.io/r/stats/p.adjust.html'>stats::p.adjust()</a></code> for a list of choices and
their description. Defaults to "<em>none</em>".</p></td>
    </tr>
    <tr>
      <th>.approach_mgd</th>
      <td><p>Character string or a vector of character strings.
Approach used for the multi-group comparison. One of: "<em>all</em>", "<em>Klesel</em>", "<em>Chin</em>",
"<em>Sarstedt</em>", "<em>Keil</em>, "<em>Nitzl</em>", "<em>Henseler</em>", "<em>CI_para</em>", or "<em>CI_overlap</em>".
Default to "<em>all</em>" in which case all approaches are computed (if possible).</p></td>
    </tr>
    <tr>
      <th>.output_type</th>
      <td><p>Character string. The type of output to return. One of
"<em>complete</em>" or "<em>structured</em>". See the Value section for details. Defaults to
"<em>complete</em>".</p></td>
    </tr>
    <tr>
      <th>.parameters_to_compare</th>
      <td><p>A model in <a href='https://rdrr.io/pkg/lavaan/man/model.syntax.html'>lavaan model syntax</a> indicating which
parameters (i.e, path (<code><a href='https://rdrr.io/r/base/tilde.html'>~</a></code>), loadings (<code>=~</code>), weights (<code>&lt;~</code>), or correlations (<code>~~</code>)) should be
compared across groups. Defaults to <code>NULL</code> in which case all weights, loadings and
path coefficients of the originally specified model are compared.</p></td>
    </tr>
    <tr>
      <th>.eval_plan</th>
      <td><p>Character string. The evaluation plan to use. One of
"<em>sequential</em>" or "<em>multiprocess</em>". In the latter case
all available cores will be used. Defaults to "<em>sequential</em>".</p></td>
    </tr>
    <tr>
      <th>.handle_inadmissibles</th>
      <td><p>Character string. How should inadmissible results
be treated? One of "<em>drop</em>", "<em>ignore</em>", or "<em>replace</em>". If "<em>drop</em>", all
replications/resamples yielding an inadmissible result will be dropped
(i.e. the number of results returned will potentially be less than <code>.R</code>).
For "<em>ignore</em>" all results are returned even if all or some of the replications
yielded inadmissible results (i.e. number of results returned is equal to <code>.R</code>).
For "<em>replace</em>" resampling continues until there are exactly <code>.R</code> admissible solutions.
Defaults to "<em>replace</em>" to accommodate all approaches.</p></td>
    </tr>
    <tr>
      <th>.R_permutation</th>
      <td><p>Integer. The number of permutations. Defaults to <code>499</code></p></td>
    </tr>
    <tr>
      <th>.R_bootstrap</th>
      <td><p>Integer. The number of bootstrap runs. Ignored if <code>.object</code>
contains resamples. Defaults to <code>499</code></p></td>
    </tr>
    <tr>
      <th>.saturated</th>
      <td><p>Logical. Should a saturated structural model be used?
Defaults to <code>FALSE</code>.</p></td>
    </tr>
    <tr>
      <th>.seed</th>
      <td><p>Integer or <code>NULL</code>. The random seed to use. Defaults to <code>NULL</code> in which
case an arbitrary seed is chosen. Note that the scope of the seed is limited
to the body of the function it is used in. Hence, the global seed will
not be altered!</p></td>
    </tr>
    <tr>
      <th>.type_ci</th>
      <td><p>Character string. Which confidence interval should be calculated?
For possible choices, see the <code>.quantity</code> argument of the <code><a href='infer.html'>infer()</a></code> function.
Only used if <code>.approch_mgd</code> is one of "<em>CI_para</em>" or "<em>CI_overlap</em>". Ignored otherwise.
Defaults to "<em>CI_percentile</em>".</p></td>
    </tr>
    <tr>
      <th>.type_vcv</th>
      <td><p>Character string. Which model-implied correlation
matrix should be calculated?
One of "<em>indicator</em>" or "<em>construct</em>". Defaults to "<em>indicator</em>".</p></td>
    </tr>
    <tr>
      <th>.verbose</th>
      <td><p>Logical. Should information (e.g., progress bar) be printed
to the console? Defaults to <code>TRUE</code>.</p></td>
    </tr>
    </table>

    <h2 class="hasAnchor" id="value"><a class="anchor" href="#value"></a>Value</h2>

    <p>If <code>.output_type = "complete"</code> a list of class <code>cSEMTestMGD</code>. Technically, <code>cSEMTestMGD</code> is a
named list containing the following list elements:</p>
<dl>
<dt><code>$Information</code></dt><dd><p>Additional information.</p></dd>
<dt><code>$Klesel</code></dt><dd><p>A list with elements, <code>Test_statistic</code>, <code>P_value</code>, and <code>Decision</code></p></dd>
<dt><code>$Chin</code></dt><dd><p>A list with elements, <code>Test_statistic</code>, <code>P_value</code>, <code>Decision</code>, and <code>Decision_overall</code></p></dd>
<dt><code>$Sarstedt</code></dt><dd><p>A list with elements, <code>Test_statistic</code>, <code>P_value</code>, <code>Decision</code>, and <code>Decision_overall</code></p></dd>
<dt><code>$Keil</code></dt><dd><p>A list with elements, <code>Test_statistic</code>, <code>P_value</code>, <code>Decision</code>, and <code>Decision_overall</code></p></dd>
<dt><code>$Nitzl</code></dt><dd><p>A list with elements, <code>Test_statistic</code>, <code>P_value</code>, <code>Decision</code>, and <code>Decision_overall</code></p></dd>
<dt><code>$Henseler</code></dt><dd><p>A list with elements, <code>Test_statistic</code>, <code>P_value</code>, <code>Decision</code>, and <code>Decision_overall</code></p></dd>
<dt><code>$CI_para</code></dt><dd><p>A list with elements,  <code>Decision</code>, and <code>Decision_overall</code></p></dd>
<dt><code>$CI_overlap</code></dt><dd><p>A list with elements,  <code>Decision</code>, and <code>Decision_overall</code></p></dd>

</dl>

<p>If <code>.output_type = "structured"</code> a tibble (data frame) with the following columns
is returned.</p>
<dl>
<dt><code>Test</code></dt><dd><p>The name of the test.</p></dd>
<dt><code>Comparision</code></dt><dd><p>The parameter that was compared across groups. If "overall"
the overall fit of the model was compared.</p></dd>
<dt><code>alpha%</code></dt><dd><p>The test decision for a given "alpha" level. If <code>TRUE</code> the null
hypotheses was rejected; if FALSE it was not rejected.</p></dd>
<dt><code>p-value_correction</code></dt><dd><p>The p-value correction.</p></dd>
<dt><code>CI_type</code></dt><dd><p>Only for the "CI_para" and the "CI_overlap" test. Which confidence interval was used.</p></dd>
<dt><code>Distance_metric</code></dt><dd><p>Only for Test = "Klesel". Which distance metric was used.</p></dd>

</dl>

    <h2 class="hasAnchor" id="details"><a class="anchor" href="#details"></a>Details</h2>

    <p>This function performs various tests proposed in the context of multigroup analysis.</p>
<p>The following tests are implemented:</p><dl>
<dt><code>.approach_mgd = "Klesel"</code>: Approach suggested by Klesel et al. (2019)
</dt><dd><p>The model-implied variance-covariance matrix (either indicator
(<code>.type_vcv = "indicator"</code>) or construct (<code>.type_vcv = "construct"</code>))
is compared across groups. If the model-implied indicator or construct correlation
matrix based on a saturated structural model should be compared, set <code>.saturated = TRUE</code>.
To measure the distance between the model-implied variance-covariance matrices,
the geodesic distance (dG) and the squared Euclidean distance (dL) are used.
If more than two groups are compared, the average distance over all groups
is used.</p></dd>
<dt><code>.approach_mgd = "Sarstedt"</code>: Approach suggested by Sarstedt et al. (2011)
</dt><dd><p>Groups are compared in terms of parameter differences across groups.
Sarstedt et al. (2011)
 tests if parameter k is equal
across all groups. If several parameters are tested simultaneously
it is recommended to adjust the significance  level or the p-values (in <span class="pkg">cSEM</span> correction is
done by p-value). By default
no multiple testing correction is done, however, several common
adjustments are available via <code>.approach_p_adjust</code>. See
<code><a href='https://rdrr.io/r/stats/p.adjust.html'>stats::p.adjust()</a></code> for details. Note: the
test has some severe shortcomings. Use with caution.</p></dd>
<dt><code>.approach_mgd = "Chin"</code>: Approach suggested by Chin and Dibbern (2010)
</dt><dd><p>Groups are compared in terms of parameter differences across groups.
Chin and Dibbern (2010)
 tests if parameter k is equal
between two groups. If more than two groups are tested for equality, parameter
k is compared between all pairs of groups. In this case, it is recommended
to adjust the significance  level or the p-values (in <span class="pkg">cSEM</span> correction is
done by p-value) since this is essentially a multiple testing setup.
If several parameters are tested simultaneously, correction is by group
and number of parameters. By default
no multiple testing correction is done, however, several common
adjustments are available via <code>.approach_p_adjust</code>. See
<code><a href='https://rdrr.io/r/stats/p.adjust.html'>stats::p.adjust()</a></code> for details.</p></dd>
<dt><code>.approach_mgd = "Keil"</code>: Approach suggested by Keil et al. (2000)
</dt><dd><p>Groups are compared in terms of parameter differences across groups.
Keil et al. (2000)
 tests if parameter k is equal
between two groups. It is assumed, that the standard errors of the coefficients are
equal across groups. The calculation of the standard error of the parameter
difference is adjusted as proposed by Henseler et al. (2009)
.
If more than two groups are tested for equality, parameter k is compared
between all pairs of groups. In this case, it is recommended
to adjust the significance  level or the p-values (in <span class="pkg">cSEM</span> correction is
done by p-value) since this is essentially a multiple testing setup.
If several parameters are tested simultaneously, correction
is by group and number of parameters. By default
no multiple testing correction is done, however, several common
adjustments are available via <code>.approach_p_adjust</code>. See
<code><a href='https://rdrr.io/r/stats/p.adjust.html'>stats::p.adjust()</a></code> for details.</p></dd>
<dt><code>.approach_mgd = "Nitzl"</code>: Approach suggested by Nitzl (2010)
</dt><dd><p>Groups are compared in terms of parameter differences across groups.
Similarly to Keil et al. (2000)
, a single parameter k is tested
for equality between two groups. In contrast to Keil et al. (2000)
,
it is assumed, that the standard errors of the coefficients are
unequal across groups (Sarstedt et al. 2011)
.
If more than two groups are tested for equality, parameter k is compared
between all pairs of groups. In this case, it is recommended
to adjust the significance  level or the p-values (in <span class="pkg">cSEM</span> correction is
done by p-value) since this is essentially a multiple testing setup.
If several parameters are tested simultaneously, correction
is by group and number of parameters. By default
no multiple testing correction is done, however, several common
adjustments are available via <code>.approach_p_adjust</code>. See
<code><a href='https://rdrr.io/r/stats/p.adjust.html'>stats::p.adjust()</a></code> for details.</p></dd>
<dt><code>.approach_mgd = "Henseler"</code>: Approach suggested by Henseler (2007)
</dt><dd><p>Groups are compared in terms of parameter differences across groups.
In doing so, the bootstrap estimates of one parameter are compared across groups.
In the literature, this approach is also known as PLS-MGA.
Originally, this test was proposed as an one-sided test.
In this function we perform a left-sided and a right-sided test
to investigate whether a parameter differs across two groups. In doing so, the significance
level is divided by 2 and compared to p-value of the left and right-sided test.
Moreover, <code>.approach_p_adjust</code> is ignored and no overall decision
is returned.
For a more detailed description, see also Henseler et al. (2009)
.</p></dd>
<dt><code>.approach_mgd = "CI_param"</code>: Approach mentioned in Sarstedt et al. (2011)
</dt><dd><p>This approach is based on the confidence intervals constructed around the
parameter estimates of the two groups. If the parameter of one group falls within
the confidence interval of the other group and/or vice versa, it can be concluded
that there is no group difference.
Since it is based on the confidence intervals <code>.approach_p_adjust</code> is ignored.</p></dd>
<dt><code>.approach_mgd = "CI_overlap"</code>: Approach mentioned in Sarstedt et al. (2011)
</dt><dd><p>This approach is based on the confidence intervals (CIs) constructed around the
parameter estimates of the two groups. If the two CIs overlap, it can be concluded
that there is no group difference.
Since it is based on the confidence intervals <code>.approach_p_adjust</code> is ignored.</p></dd>

</dl>

<p>Use <code>.approach_mgd</code> to choose the approach. By default all approaches are computed
(<code>.approach_mgd = "all"</code>).</p>
<p>For convenience, two types of output are available. See the "Value" section below.</p>
<p>By default, approaches based on parameter differences across groups compare
all parameters (<code>.parameters_to_compare = NULL</code>). To compare only
a subset of parameters provide the parameters in <a href='https://rdrr.io/pkg/lavaan/man/model.syntax.html'>lavaan model syntax</a>  just like
the model to estimate. Take the simple model:</p>
<pre>
<span class='va'>model_to_estimate</span> <span class='op'>&lt;-</span> <span class='st'>"
Structural model
eta2 ~ eta1
eta3 ~ eta1 + eta2

# Each concept os measured by 3 indicators, i.e., modeled as latent variable
eta1 =~ y11 + y12 + y13
eta2 =~ y21 + y22 + y23
eta3 =~ y31 + y32 + y33
"</span>
</pre><p>If only the path from eta1 to eta3 and the loadings of eta1 are to be compared
across groups, write:</p><pre>
<span class='va'>to_compare</span> <span class='op'>&lt;-</span> <span class='st'>"
Structural parameters to compare
eta3 ~ eta1

# Loadings to compare
eta1 =~ y11 + y12 + y13
"</span>
</pre><p>Note that the "model" provided to <code>.parameters_to_compare</code>
does not need to be an estimable model!</p>
<p>Note also that compared to all other functions in <span class="pkg">cSEM</span> using the argument,
<code>.handle_inadmissibles</code> defaults to <code>"replace"</code> to accomdate the Sarstedt et al. (2011) approach.</p>
<p>Argument <code>.R_permuation</code> is ignored for the <code>"Nitzl"</code> and the <code>"Keil"</code> approach.
<code>.R_bootstrap</code> is ignored if  <code>.object</code> already contains resamples,
i.e. has class <code>cSEMResults_resampled</code> and if only the <code>"Klesel"</code> or the <code>"Chin"</code>
approach are used.</p>
<p>The argument <code>.saturated</code> is used by <code>"Klesel"</code> only. If <code>.saturated = TRUE</code>
the original structural model is ignored and replaced by a saturated model,
i.e. a model in which all constructs are allowed to correlate freely.
This is useful to test differences in the measurement models between groups
in isolation.</p>
    <h2 class="hasAnchor" id="references"><a class="anchor" href="#references"></a>References</h2>

    <p>Chin WW, Dibbern J (2010).
&#8220;An Introduction to a Permutation Based Procedure for Multi-Group PLS Analysis: Results of Tests of Differences on Simulated Data and a Cross Cultural Analysis of the Sourcing of Information System Services Between Germany and the USA.&#8221;
In <em>Handbook of Partial Least Squares</em>, 171--193.
Springer Berlin Heidelberg.
doi: <a href='https://doi.org/10.1007/978-3-540-32827-8_8'>10.1007/978-3-540-32827-8_8</a>
, <a href='https://doi.org/10.1007/978-3-540-32827-8_8'>https://doi.org/10.1007/978-3-540-32827-8_8</a>.<br /><br /> Henseler J (2007).
&#8220;A new and simple approach to multi-group analysis in partial least squares path modeling.&#8221;
In Martens H, Næ s T (eds.), <em>Proceedings of PLS'07 - The 5th International Symposium on PLS and Related Methods</em>, 104--107.
PLS, Norway: Matforsk, As.<br /><br /> Henseler J, Ringle CM, Sinkovics RR (2009).
&#8220;The use of partial least squares path modeling in international marketing.&#8221;
<em>Advances in International Marketing</em>, <b>20</b>, 277--320.
doi: <a href='https://doi.org/10.1108/S1474-7979(2009)0000020014'>10.1108/S1474-7979(2009)0000020014</a>
, <a href='https://doi.org/10.1108/S1474-7979(2009)0000020014'>https://doi.org/10.1108/S1474-7979(2009)0000020014</a>.<br /><br /> Keil M, Tan BC, Wei K, Saarinen T, Tuunainen V, Wassenaar A (2000).
&#8220;A cross-cultural study on escalation of commitment behavior in software projects.&#8221;
<em>MIS Quarterly</em>, <b>24</b>(2), 299--325.<br /><br /> Klesel M, Schuberth F, Henseler J, Niehaves B (2019).
&#8220;A Test for Multigroup Comparison Using Partial Least Squares Path Modeling.&#8221;
<em>Internet Research</em>, <b>29</b>(3), 464--477.
doi: <a href='https://doi.org/10.1108/intr-11-2017-0418'>10.1108/intr-11-2017-0418</a>
, <a href='https://doi.org/10.1108/intr-11-2017-0418'>https://doi.org/10.1108/intr-11-2017-0418</a>.<br /><br /> Nitzl C (2010).
&#8220;Eine anwenderorientierte Einfuehrung in die Partial Least Square (PLS)-Methode.&#8221;
In <em>Arbeitspapier</em>,  number 21.
Universitaet Hamburg, Institut fuer Industrielles Management, Hamburg.<br /><br /> Sarstedt M, Henseler J, Ringle CM (2011).
&#8220;Multigroup Analysis in Partial Least Squares (PLS) Path Modeling: Alternative Methods and Empirical Results.&#8221;
In <em>Advances in International Marketing</em>, 195--218.
Emerald Group Publishing Limited.
doi: <a href='https://doi.org/10.1108/s1474-7979(2011)0000022012'>10.1108/s1474-7979(2011)0000022012</a>
, <a href='https://doi.org/10.1108/s1474-7979(2011)0000022012'>https://doi.org/10.1108/s1474-7979(2011)0000022012</a>.</p>
    <h2 class="hasAnchor" id="see-also"><a class="anchor" href="#see-also"></a>See also</h2>

    <div class='dont-index'><p><code><a href='csem.html'>csem()</a></code>, <a href='csem_results.html'>cSEMResults</a>, <code><a href='testMICOM.html'>testMICOM()</a></code>, <code><a href='testOMF.html'>testOMF()</a></code></p></div>

    <h2 class="hasAnchor" id="examples"><a class="anchor" href="#examples"></a>Examples</h2>
    <pre class="examples"><div class='input'><span class='kw'>if</span> <span class='op'>(</span><span class='cn'>FALSE</span><span class='op'>)</span> <span class='op'>{</span>
<span class='co'># ===========================================================================</span>
<span class='co'># Basic usage</span>
<span class='co'># ===========================================================================</span>
<span class='va'>model</span> <span class='op'>&lt;-</span> <span class='st'>"
# Structural model
QUAL ~ EXPE
EXPE ~ IMAG
SAT  ~ IMAG + EXPE + QUAL + VAL
LOY  ~ IMAG + SAT
VAL  ~ EXPE + QUAL

# Measurement model

EXPE &lt;~ expe1 + expe2 + expe3 + expe4 + expe5
IMAG &lt;~ imag1 + imag2 + imag3 + imag4 + imag5
LOY  =~ loy1  + loy2  + loy3  + loy4
QUAL =~ qual1 + qual2 + qual3 + qual4 + qual5
SAT  &lt;~ sat1  + sat2  + sat3  + sat4
VAL  &lt;~ val1  + val2  + val3  + val4
"</span>

<span class='co'>## Create list of virtually identical data sets</span>
<span class='va'>dat</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/list.html'>list</a></span><span class='op'>(</span><span class='va'>satisfaction</span><span class='op'>[</span><span class='op'>-</span><span class='fl'>3</span>,<span class='op'>]</span>, <span class='va'>satisfaction</span><span class='op'>[</span><span class='op'>-</span><span class='fl'>5</span>, <span class='op'>]</span>, <span class='va'>satisfaction</span><span class='op'>[</span><span class='op'>-</span><span class='fl'>10</span>, <span class='op'>]</span><span class='op'>)</span>
<span class='va'>out</span> <span class='op'>&lt;-</span> <span class='fu'><a href='csem.html'>csem</a></span><span class='op'>(</span><span class='va'>dat</span>, <span class='va'>model</span>, .resample_method <span class='op'>=</span> <span class='st'>"bootstrap"</span>, .R <span class='op'>=</span> <span class='fl'>40</span><span class='op'>)</span> 

<span class='co'>## Test </span>
<span class='fu'>testMGD</span><span class='op'>(</span><span class='va'>out</span>, .R_permutation <span class='op'>=</span> <span class='fl'>40</span>,.verbose <span class='op'>=</span> <span class='cn'>FALSE</span><span class='op'>)</span>

<span class='co'># Notes: </span>
<span class='co'>#  1. .R_permutation (and .R in the call to csem) is small to make examples run quicker; </span>
<span class='co'>#     should be higher in real applications.</span>
<span class='co'>#  2. Test will not reject their respective H0s since the groups are virtually</span>
<span class='co'>#     identical.</span>
<span class='co'>#  3. Only exception is the approach suggested by Sarstedt et al. (2011), a</span>
<span class='co'>#     sign that the test is unreliable.</span>
<span class='co'>#  4. As opposed to other functions involving the argument, </span>
<span class='co'>#     '.handle_inadmissibles' the default is "replace" as this is</span>
<span class='co'>#     required by Sarstedt et al. (2011)'s approach.</span>

<span class='co'># ===========================================================================</span>
<span class='co'># Extended usage</span>
<span class='co'># ===========================================================================</span>
<span class='co'>### Test only a subset ------------------------------------------------------</span>
<span class='co'># By default all parameters are compared. Select a subset by providing a </span>
<span class='co'># model in lavaan model syntax:</span>

<span class='va'>to_compare</span> <span class='op'>&lt;-</span> <span class='st'>"
# Path coefficients
QUAL ~ EXPE

# Loadings
EXPE &lt;~ expe1 + expe2 + expe3 + expe4 + expe5
"</span>

<span class='co'>## Test </span>
<span class='fu'>testMGD</span><span class='op'>(</span><span class='va'>out</span>, .parameters_to_compare <span class='op'>=</span> <span class='va'>to_compare</span>, .R_permutation <span class='op'>=</span> <span class='fl'>20</span>, 
        .R_bootstrap <span class='op'>=</span> <span class='fl'>20</span>, .verbose <span class='op'>=</span> <span class='cn'>FALSE</span><span class='op'>)</span>

<span class='co'>### Different p_adjustments --------------------------------------------------</span>
<span class='co'># To adjust p-values to accommodate multiple testing use .approach_p_adjust. </span>
<span class='co'># The number of tests to use for adjusting depends on the approach chosen. For</span>
<span class='co'># the Chin approach for example it is the number of parameters to test times the</span>
<span class='co'># number of possible group comparisons. To compare the results for different</span>
<span class='co'># adjustments, a vector of p-adjustments may be chosen.</span>

<span class='co'>## Test </span>
<span class='fu'>testMGD</span><span class='op'>(</span><span class='va'>out</span>, .parameters_to_compare <span class='op'>=</span> <span class='va'>to_compare</span>, 
        .approach_p_adjust <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='st'>"none"</span>, <span class='st'>"bonferroni"</span><span class='op'>)</span>,
        .R_permutation <span class='op'>=</span> <span class='fl'>20</span>, .R_bootstrap <span class='op'>=</span> <span class='fl'>20</span>, .verbose <span class='op'>=</span> <span class='cn'>FALSE</span><span class='op'>)</span>
<span class='op'>}</span>
</div></pre>
  </div>
  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">
    <nav id="toc" data-toggle="toc" class="sticky-top">
      <h2 data-toc-skip>Contents</h2>
    </nav>
  </div>
</div>


      <footer>
      <div class="copyright">
  <p><p>Developed by Manuel E. Rademaker, Florian Schuberth.</p></p>
</div>

<div class="pkgdown">
  <p><p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 1.6.1.9001.</p></p>
</div>

      </footer>
   </div>

  


  

  </body>
</html>


